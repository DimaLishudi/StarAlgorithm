{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ9KxWEOQa8V"
   },
   "source": [
    "# Вводная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "KC1buI2cG8Wl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R59EYNJ1QnXi"
   },
   "source": [
    "# Классы моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1P9GoDNehJsO"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.start = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2), # 32 -> 16\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2), # 16 -> 8\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), \n",
    "            nn.MaxPool2d(2), # 8 -> 4\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(32*2*2, 100),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        x = self.start(images)\n",
    "        x = x + self.conv1(x)\n",
    "        x = x + self.conv2(x)\n",
    "\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.flatten(1)\n",
    "        logits = self.head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z6HC6ziHUnnZ"
   },
   "outputs": [],
   "source": [
    "class StarRegression(nn.Module):\n",
    "    def __init__(self, trained_list, BaseClass, warmup=None, *args, **kwargs):\n",
    "        '''\n",
    "        Constructs Star aggregation of models\n",
    "        uses segments from empirical minimizers (trained models) via sigmoid\n",
    "\n",
    "        args:\n",
    "            trained_list - list of trained models (will be copied)\n",
    "            BaseClass - class of new model,\n",
    "                        which will be connected with trained_model\n",
    "                        and trained alongside weights of models (self.l)\n",
    "            *args, **kwargs - arguments for BaseClass initialization \n",
    "        '''\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.trained_models = nn.ModuleList()\n",
    "        for model in trained_list:\n",
    "            self.trained_models.append(copy.deepcopy(model))\n",
    "            for p in self.trained_models[-1].parameters():\n",
    "                p.requires_grad = False\n",
    "        if warmup is not None:\n",
    "            self.training_model = copy.deepcopy(warmup)\n",
    "            for p in self.training_model.parameters():\n",
    "                p.requires_grad = True\n",
    "        else:\n",
    "            self.training_model = BaseClass(*args, **kwargs)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.zeros(len(trained_list)+1))\n",
    "        self.weights.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for model in self.trained_models:\n",
    "            outs.append(model(x))\n",
    "        outs.append(self.training_model(x))\n",
    "        return torch.stack(outs, -1) @ nn.functional.softmax(self.weights, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EDfBPBcJaucA"
   },
   "outputs": [],
   "source": [
    "class ParallelRegression(nn.Module):\n",
    "    def __init__(self, BaseClass, model_num=2, *args, **kwargs):\n",
    "        '''\n",
    "        args:\n",
    "            BaseClass - class of models,\n",
    "                        which will be connected similarly to SegmentStarRegression\n",
    "                        but trained in parallel\n",
    "            model_num - number of base models\n",
    "            *args, **kwargs - arguments for BaseClass initialization\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.models = nn.ModuleList()\n",
    "        for _ in range(model_num):\n",
    "            self.models.append(BaseClass(*args, **kwargs))\n",
    "        self.linear = nn.Linear(model_num, 1, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for model in self.models:\n",
    "            outs.append(model(x))\n",
    "        return self.linear(torch.stack(outs, -1)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSgCxezhQd1V"
   },
   "source": [
    "# Подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/YearPredictionMSD.txt', header=None)\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "train_size = 463715\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DU_Yy26pPiHS"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "26b6a0c77af942eaaa746801fb3a566c",
      "56eecab378904496a0f39a4a0575a886",
      "78abf27d5e4643c6ba2bf0e4570c9ae1",
      "81da4bd986974a4583fc795fdca1afcc",
      "e1c5ace95b7549f3a3a6be4af3335441",
      "06ffe57a2c7840bfab7736754b1f00d6",
      "6b7c6cbb6381475a9888d83d7e402120",
      "a73c3cbe46814ec487d56935bde31aef",
      "4d0650ade7a342b9967dbae6a1fcd815",
      "985178ddc2204e32b763061205accb8e",
      "80e7e4a83ee14ac2b96ee970119b5278"
     ]
    },
    "id": "f_e_TyPZ-GbE",
    "outputId": "319e1676-c762-4945-8f75-c0a8d11a1d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010), inplace=True),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010), inplace=True),\n",
    "])\n",
    "\n",
    "\n",
    "orig_train_set = CIFAR10('CIFAR10', train=True, download=True)\n",
    "orig_test_set  = CIFAR10('CIFAR10', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.transform = transform\n",
    "        self.obj_num = len(dataset)\n",
    "\n",
    "        self.objects = np.empty((self.obj_num, 32, 32, 3), dtype=np.uint8)\n",
    "        self.classes = torch.empty((self.obj_num), dtype=torch.long)\n",
    "\n",
    "        for i in range(self.obj_num):\n",
    "            self.objects[i] = np.asarray(dataset[i][0].convert('RGB'))\n",
    "            self.classes[i] = dataset[i][1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.objects[idx]), self.classes[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.obj_num\n",
    "    \n",
    "fast_train_set = FastDataset(orig_train_set, train_transform)\n",
    "fast_test_set = FastDataset(orig_test_set, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "# VALID_PROP = 0.1\n",
    "# valid_len = round(VALID_PROP * len(fast_test_set))\n",
    "\n",
    "# test_len = len(fast_test_set) - valid_len\n",
    "# test_set, valid_set = random_split(fast_test_set,\n",
    "#                                     [test_len, valid_len],\n",
    "#                                     generator=torch.Generator().manual_seed(SEED)\n",
    "# )\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(fast_train_set, batch_size=batch_size, num_workers=0, pin_memory=True, shuffle=True)\n",
    "# valid_dataloader = DataLoader(valid_set, batch_size=batch_size, num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(fast_test_set, batch_size=batch_size, num_workers=0, pin_memory=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "x2FpGzZkauj3"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * y.shape[0]\n",
    "        acc_sum += (y_pred.argmax(dim=-1) == y).sum().item()\n",
    "        total += y.shape[0]\n",
    "\n",
    "    return loss_sum / total, acc_sum / total\n",
    "\n",
    "\n",
    "def evaluate_one_epoch(model_list, dataloader, criterion, device='cpu'):\n",
    "    if not isinstance(model_list, list):\n",
    "        model_list = [model_list]\n",
    "    for model in model_list:\n",
    "        model.eval()\n",
    "\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model_list[0](x)\n",
    "            for model in model_list[1:]:\n",
    "                y_pred += model(x)\n",
    "            y_pred /= len(model_list)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss_sum += loss.item() * y.shape[0]\n",
    "            acc_sum += (y_pred.argmax(dim=-1) == y).sum().item()\n",
    "            total += y.shape[0]\n",
    "    return loss_sum / total, acc_sum / total\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, epoch_num, optimizer, \n",
    "          device='cpu', eval_freq=2, plot_freq=2,name=None):\n",
    "    '''\n",
    "    args:\n",
    "        model - model to be trained\n",
    "        train_dataloader - dataloader of training dataset\n",
    "        valid_dataloader - dataloader of validation dataset\n",
    "        epoch_num - amount of epoches to train\n",
    "        optimizer - optimizer\n",
    "        scheduler - optimizer scheduler\n",
    "        device - device to compute on\n",
    "        tol - tolerance of loss, if difference is < tol, training is stopped\n",
    "        eval_freq - every eval_freq epoches loss on validation dataset is calculated\n",
    "        plot_graph - if true, then real time graph is shown, else loss is printed\n",
    "        scale - scale by which you should multiply loss\n",
    "        name - name of model\n",
    "    \n",
    "    returns:\n",
    "        losses - list of avg loss on training dataset per every test_freq epoches\n",
    "    '''\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        loss, acc = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "        train_losses += [loss]\n",
    "        train_accs += [acc]\n",
    "            \n",
    "        if epoch % eval_freq == eval_freq-1:\n",
    "            loss, acc = evaluate_one_epoch([model], test_dataloader, criterion, device)\n",
    "            test_losses += [loss]\n",
    "            test_accs += [acc]\n",
    "\n",
    "        if epoch % plot_freq == plot_freq-1:\n",
    "            fig, axs = plt.subplots(figsize=(14, 7), ncols=2)\n",
    "            axs[0].plot(range(len(train_losses)), train_losses, label='train')\n",
    "            axs[0].plot(range(eval_freq-1, len(test_losses)*eval_freq, eval_freq), test_losses, label='test')\n",
    "            axs[0].set(ylabel = 'Cross Entropy Loss', xlabel='Epoch', title='Training Loss')\n",
    "            axs[0].legend()\n",
    "\n",
    "            axs[1].plot(range(len(train_accs)), train_accs, label='train')\n",
    "            axs[1].plot(range(eval_freq-1, len(test_accs)*eval_freq, eval_freq), test_accs, label='test')\n",
    "            axs[1].set(ylabel = 'Accuracy', xlabel='Epoch', title='Training Accuracy')\n",
    "            axs[1].legend()\n",
    "            \n",
    "            clear_output()\n",
    "            plt.show()\n",
    "            print(name, 'epoch number ', epoch, '\\n')\n",
    "            print('time training:', round(time.time() - start_time, 1), 'sec')\n",
    "            print('train acc:', train_accs[-1])\n",
    "            print('test acc:',  test_accs[-1], '\\n\\n')\n",
    "\n",
    "    training_time = round(time.time() - start_time, 1)\n",
    "    print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "    return train_losses, train_accs, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyf1vuUPQvNx"
   },
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "juditG5HsunV"
   },
   "outputs": [],
   "source": [
    "def add_res(results, name, add_row):\n",
    "    '''\n",
    "    Adds new row with index \"name\" to DataFrame\n",
    "    Args:\n",
    "        results -  pd.DataFrame containing results for all models\n",
    "        name - name of new row\n",
    "        add_row - row which will be added\n",
    "    '''\n",
    "    if name not in results.index:\n",
    "        results.loc[name] = add_row\n",
    "        return\n",
    "\n",
    "    res_row = []\n",
    "    for i, col in enumerate(results):\n",
    "        res_row += [results.loc[name,col] + add_row[i]]\n",
    "    results.loc[name] = res_row\n",
    "\n",
    "\n",
    "def make_experiment(results, model_class=ResNet9, epoches=10, base_am=3, warmup_epoches=3):\n",
    "    '''\n",
    "    Args:\n",
    "        results - pd.DataFrame containing results for all models\n",
    "        model_class - Class for each base block\n",
    "        epoches - total number of epoches for each step of algorithm\n",
    "        base_am - maximum d (there will be total of base_am + 1 blocks)\n",
    "    returns:\n",
    "        results - changed pd.DataFrame containing old and new results\n",
    "    '''\n",
    "\n",
    "#     bases = []\n",
    "    \n",
    "#     ensemble_times = []\n",
    "#     scheduler = None\n",
    "    \n",
    "#     for i in range(base_am+1):\n",
    "#         bases.append(model_class())\n",
    "#         bases[i].to(device)\n",
    "\n",
    "#         optimizer = torch.optim.Adam(bases[i].parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "#         losses, accs, time = train(bases[i], train_dataloader, test_dataloader, epoches,\n",
    "#                              optimizer, device=device, name=\"base model \" + str(i+1))\n",
    "    \n",
    "#         if len(ensemble_times):\n",
    "#             ensemble_times += [ensemble_times[-1] + time]\n",
    "#         else:\n",
    "#             ensemble_times += [time]\n",
    "\n",
    "#         loss, acc = evaluate_one_epoch(bases[i], test_dataloader, criterion, device)\n",
    "#         train_loss, train_acc = evaluate_one_epoch(bases[i], train_dataloader, criterion, device)\n",
    "        \n",
    "#         add_res(results, 'Big NN 0', [[loss], [acc], [train_loss], [train_acc], [time]])\n",
    "    \n",
    "#     # ensemble -----------------------------------------------------------------\n",
    "\n",
    "#     for i in range(base_am):\n",
    "#         loss, acc = evaluate_one_epoch(bases[:i+2], test_dataloader, criterion, device)\n",
    "#         train_loss, train_acc = evaluate_one_epoch(bases[:i+2], train_dataloader, criterion, device)\n",
    "            \n",
    "#         add_res(results, 'Ensemble ' + str(i+1), [[loss], [acc], [train_loss], [train_acc], [ensemble_times[i+1]]])\n",
    "\n",
    "#     # star ---------------------------------------------------------------------\n",
    "\n",
    "#     star_models = []\n",
    "\n",
    "#     for i in range(base_am):\n",
    "#         name = 'Classic Star (no warm-up) ' + str(i+1)\n",
    "#         star = StarRegression(bases[:i+1], model_class).to(device)\n",
    "#         optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "#         losses, accs, time = train(star, train_dataloader, test_dataloader, epoches, optimizer, device=device, name=name)\n",
    "\n",
    "#         loss, acc = evaluate_one_epoch(star, test_dataloader, criterion, device)\n",
    "#         train_loss, train_acc = evaluate_one_epoch(star, train_dataloader, criterion, device)\n",
    "            \n",
    "#         add_res(results, name, [[loss], [acc], [train_loss], [train_acc], [time + ensemble_times[i]]])\n",
    "  \n",
    "\n",
    "#     # warmup star ---------------------------------------------------------------------\n",
    "\n",
    "#     warmed = model_class().to(device)\n",
    "\n",
    "#     optimizer = torch.optim.Adam(warmed.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "#     _, _, warmup_time = train(warmed, train_dataloader, test_dataloader, warmup_epoches,\n",
    "#                            optimizer, device=device, name='warmup')\n",
    "\n",
    "#     for i in range(base_am):\n",
    "#         name = 'Classic Star (new warm-up) ' + str(i+1)\n",
    "#         star = StarRegression(bases[:i+1], model_class, warmup=warmed).to(device)\n",
    "#         optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "#         losses, accs, time = train(star, train_dataloader, test_dataloader, epoches - warmup_epoches, optimizer, device=device, name=name)\n",
    "\n",
    "#         loss, acc = evaluate_one_epoch(star, test_dataloader, criterion, device)\n",
    "#         train_loss, train_acc = evaluate_one_epoch(star, train_dataloader, criterion, device)\n",
    "            \n",
    "#         add_res(results, name, [[loss], [acc], [train_loss], [train_acc], [time + warmup_time + ensemble_times[i]]])\n",
    "\n",
    "\n",
    "#     parallel -----------------------------------------------------------------\n",
    "\n",
    "    parallel_models = []\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Big NN ' + str(i+1)\n",
    "        parallel_model = ParallelRegression(model_class, i+2).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(parallel_model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "        losses, accs, time = train(parallel_model, train_dataloader, test_dataloader, epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        loss, acc = evaluate_one_epoch(parallel_model, test_dataloader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_one_epoch(parallel_model, train_dataloader, criterion, device)\n",
    "        \n",
    "        add_res(results, name, [[loss], [acc], [train_loss], [train_acc], [time]])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "apoiJUvUyBns",
    "outputId": "f88ffdcd-05de-4465-a79a-e8f17c363975",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Loss' : [], 'Accuracy' : [], 'Train Loss' : [], 'Train Accuracy' : [], 'Time' : []})\n",
    "NUM_EXPERIMENTS = 3\n",
    "set_random_seed(0)\n",
    "for i in range(NUM_EXPERIMENTS):\n",
    "    results = make_experiment(results, model_class=ResNet9, epoches=10, warmup_epoches=2) #, base_am=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic Star (new warm-up) 3 epoch number  7 \n",
      "\n",
      "time training: 1046.1 sec\n",
      "train acc: 0.9268\n",
      "test acc: 0.9013 \n",
      "\n",
      "\n",
      "Training time: 1046.1 seconds\n"
     ]
    }
   ],
   "source": [
    "results = make_experiment(results, model_class=ResNet9, base_am=3, epoches=10, warmup_epoches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Big NN 0</th>\n",
       "      <td>[0.4001814534187317, 0.4599046495437622, 0.511...</td>\n",
       "      <td>[0.8677, 0.8436, 0.8244, 0.8457, 0.839, 0.8444...</td>\n",
       "      <td>[0.35745231853961945, 0.40198987390518187, 0.4...</td>\n",
       "      <td>[0.88476, 0.86182, 0.83478, 0.86832, 0.85316, ...</td>\n",
       "      <td>[900.5, 782.8, 757.3, 758.1, 757.5, 758.5, 776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 1</th>\n",
       "      <td>[0.3430506531238556, 0.36581522212028506, 0.37...</td>\n",
       "      <td>[0.8861, 0.8734, 0.8727]</td>\n",
       "      <td>[0.297635410490036, 0.3075022952079773, 0.3049...</td>\n",
       "      <td>[0.90502, 0.898, 0.89716]</td>\n",
       "      <td>[1683.3, 1740.5, 1557.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 2</th>\n",
       "      <td>[0.3155895233631134, 0.3319969253540039, 0.328...</td>\n",
       "      <td>[0.8969, 0.8877, 0.8877]</td>\n",
       "      <td>[0.27331409185409544, 0.2809423043346405, 0.26...</td>\n",
       "      <td>[0.91764, 0.9113, 0.91328]</td>\n",
       "      <td>[2440.6, 2581.6, 2327.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 3</th>\n",
       "      <td>[0.29925513768196105, 0.32006648807525634, 0.3...</td>\n",
       "      <td>[0.9023, 0.893, 0.8891]</td>\n",
       "      <td>[0.24825520288467406, 0.2674123253154755, 0.25...</td>\n",
       "      <td>[0.92596, 0.91692, 0.91746]</td>\n",
       "      <td>[3198.7, 3398.3, 3085.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 4</th>\n",
       "      <td>[0.29681019439697265, 0.31858636384010314]</td>\n",
       "      <td>[0.9025, 0.8912]</td>\n",
       "      <td>[0.24506483757019043, 0.2651513268852234]</td>\n",
       "      <td>[0.9272, 0.91612]</td>\n",
       "      <td>[3956.2, 4177.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 5</th>\n",
       "      <td>[0.28771511678695677, 0.2946513738632202]</td>\n",
       "      <td>[0.9046, 0.9023]</td>\n",
       "      <td>[0.23841904188156127, 0.24606001117229462]</td>\n",
       "      <td>[0.93086, 0.92656]</td>\n",
       "      <td>[4714.7, 4934.400000000001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 1</th>\n",
       "      <td>[0.3582811215400696, 0.35210523896217344, 0.35...</td>\n",
       "      <td>[0.8821, 0.8789, 0.8819]</td>\n",
       "      <td>[0.3135467227077484, 0.3146791537570953, 0.296...</td>\n",
       "      <td>[0.90172, 0.9019, 0.90802]</td>\n",
       "      <td>[1830.3, 1707.2, 1724.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 2</th>\n",
       "      <td>[0.3108438994407654, 0.3160343985557556, 0.313...</td>\n",
       "      <td>[0.898, 0.8933, 0.8964]</td>\n",
       "      <td>[0.2569754233264923, 0.26269870041847226, 0.25...</td>\n",
       "      <td>[0.92332, 0.92038, 0.9201]</td>\n",
       "      <td>[2788.0, 2844.2, 2663.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 3</th>\n",
       "      <td>[0.292877231502533, 0.29854049582481385, 0.294...</td>\n",
       "      <td>[0.9029, 0.9034, 0.9023]</td>\n",
       "      <td>[0.23867048714160918, 0.24337536680221558, 0.2...</td>\n",
       "      <td>[0.92846, 0.92708, 0.92818]</td>\n",
       "      <td>[3718.5, 3858.3999999999996, 3652.1000000000004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 4</th>\n",
       "      <td>[0.2845957246303558, 0.2913079014778137]</td>\n",
       "      <td>[0.9071, 0.9047]</td>\n",
       "      <td>[0.22883741600513458, 0.23787778925895692]</td>\n",
       "      <td>[0.93162, 0.9294]</td>\n",
       "      <td>[4650.299999999999, 4848.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 5</th>\n",
       "      <td>[0.2813127546310425, 0.2817422402858734]</td>\n",
       "      <td>[0.9073, 0.9079]</td>\n",
       "      <td>[0.2240297388410568, 0.2283222034025192]</td>\n",
       "      <td>[0.93344, 0.93348]</td>\n",
       "      <td>[5581.4, 5802.400000000001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 1</th>\n",
       "      <td>[0.35132595133781436, 0.34671875286102294, 0.3...</td>\n",
       "      <td>[0.8842, 0.8817, 0.8829]</td>\n",
       "      <td>[0.3053761303329468, 0.308457942943573, 0.2924...</td>\n",
       "      <td>[0.90642, 0.9049, 0.90828]</td>\n",
       "      <td>[1796.2, 1705.0, 1725.6999999999998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 2</th>\n",
       "      <td>[0.31103485140800474, 0.3120883293628693, 0.31...</td>\n",
       "      <td>[0.898, 0.8964, 0.8957]</td>\n",
       "      <td>[0.259398263630867, 0.2600865338802338, 0.2583...</td>\n",
       "      <td>[0.9229, 0.92116, 0.92064]</td>\n",
       "      <td>[2717.8, 2797.6000000000004, 2669.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 3</th>\n",
       "      <td>[0.29291184635162354, 0.2992772318840027, 0.29...</td>\n",
       "      <td>[0.9029, 0.9035, 0.9013]</td>\n",
       "      <td>[0.2408954661655426, 0.24411217144966124, 0.24...</td>\n",
       "      <td>[0.92776, 0.92746, 0.92738]</td>\n",
       "      <td>[3613.5, 3839.7, 3534.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 4</th>\n",
       "      <td>[0.2841888794898987, 0.29394576539993283]</td>\n",
       "      <td>[0.9077, 0.9037]</td>\n",
       "      <td>[0.22986062653541564, 0.2401577792072296]</td>\n",
       "      <td>[0.93208, 0.92888]</td>\n",
       "      <td>[4511.7, 4757.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 5</th>\n",
       "      <td>[0.28236348452568055]</td>\n",
       "      <td>[0.907]</td>\n",
       "      <td>[0.22618704151153565]</td>\n",
       "      <td>[0.9337]</td>\n",
       "      <td>[5409.799999999999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           Loss  \\\n",
       "Big NN 0                      [0.4001814534187317, 0.4599046495437622, 0.511...   \n",
       "Ensemble 1                    [0.3430506531238556, 0.36581522212028506, 0.37...   \n",
       "Ensemble 2                    [0.3155895233631134, 0.3319969253540039, 0.328...   \n",
       "Ensemble 3                    [0.29925513768196105, 0.32006648807525634, 0.3...   \n",
       "Ensemble 4                           [0.29681019439697265, 0.31858636384010314]   \n",
       "Ensemble 5                            [0.28771511678695677, 0.2946513738632202]   \n",
       "Classic Star (no warm-up) 1   [0.3582811215400696, 0.35210523896217344, 0.35...   \n",
       "Classic Star (no warm-up) 2   [0.3108438994407654, 0.3160343985557556, 0.313...   \n",
       "Classic Star (no warm-up) 3   [0.292877231502533, 0.29854049582481385, 0.294...   \n",
       "Classic Star (no warm-up) 4            [0.2845957246303558, 0.2913079014778137]   \n",
       "Classic Star (no warm-up) 5            [0.2813127546310425, 0.2817422402858734]   \n",
       "Classic Star (new warm-up) 1  [0.35132595133781436, 0.34671875286102294, 0.3...   \n",
       "Classic Star (new warm-up) 2  [0.31103485140800474, 0.3120883293628693, 0.31...   \n",
       "Classic Star (new warm-up) 3  [0.29291184635162354, 0.2992772318840027, 0.29...   \n",
       "Classic Star (new warm-up) 4          [0.2841888794898987, 0.29394576539993283]   \n",
       "Classic Star (new warm-up) 5                              [0.28236348452568055]   \n",
       "\n",
       "                                                                       Accuracy  \\\n",
       "Big NN 0                      [0.8677, 0.8436, 0.8244, 0.8457, 0.839, 0.8444...   \n",
       "Ensemble 1                                             [0.8861, 0.8734, 0.8727]   \n",
       "Ensemble 2                                             [0.8969, 0.8877, 0.8877]   \n",
       "Ensemble 3                                              [0.9023, 0.893, 0.8891]   \n",
       "Ensemble 4                                                     [0.9025, 0.8912]   \n",
       "Ensemble 5                                                     [0.9046, 0.9023]   \n",
       "Classic Star (no warm-up) 1                            [0.8821, 0.8789, 0.8819]   \n",
       "Classic Star (no warm-up) 2                             [0.898, 0.8933, 0.8964]   \n",
       "Classic Star (no warm-up) 3                            [0.9029, 0.9034, 0.9023]   \n",
       "Classic Star (no warm-up) 4                                    [0.9071, 0.9047]   \n",
       "Classic Star (no warm-up) 5                                    [0.9073, 0.9079]   \n",
       "Classic Star (new warm-up) 1                           [0.8842, 0.8817, 0.8829]   \n",
       "Classic Star (new warm-up) 2                            [0.898, 0.8964, 0.8957]   \n",
       "Classic Star (new warm-up) 3                           [0.9029, 0.9035, 0.9013]   \n",
       "Classic Star (new warm-up) 4                                   [0.9077, 0.9037]   \n",
       "Classic Star (new warm-up) 5                                            [0.907]   \n",
       "\n",
       "                                                                     Train Loss  \\\n",
       "Big NN 0                      [0.35745231853961945, 0.40198987390518187, 0.4...   \n",
       "Ensemble 1                    [0.297635410490036, 0.3075022952079773, 0.3049...   \n",
       "Ensemble 2                    [0.27331409185409544, 0.2809423043346405, 0.26...   \n",
       "Ensemble 3                    [0.24825520288467406, 0.2674123253154755, 0.25...   \n",
       "Ensemble 4                            [0.24506483757019043, 0.2651513268852234]   \n",
       "Ensemble 5                           [0.23841904188156127, 0.24606001117229462]   \n",
       "Classic Star (no warm-up) 1   [0.3135467227077484, 0.3146791537570953, 0.296...   \n",
       "Classic Star (no warm-up) 2   [0.2569754233264923, 0.26269870041847226, 0.25...   \n",
       "Classic Star (no warm-up) 3   [0.23867048714160918, 0.24337536680221558, 0.2...   \n",
       "Classic Star (no warm-up) 4          [0.22883741600513458, 0.23787778925895692]   \n",
       "Classic Star (no warm-up) 5            [0.2240297388410568, 0.2283222034025192]   \n",
       "Classic Star (new warm-up) 1  [0.3053761303329468, 0.308457942943573, 0.2924...   \n",
       "Classic Star (new warm-up) 2  [0.259398263630867, 0.2600865338802338, 0.2583...   \n",
       "Classic Star (new warm-up) 3  [0.2408954661655426, 0.24411217144966124, 0.24...   \n",
       "Classic Star (new warm-up) 4          [0.22986062653541564, 0.2401577792072296]   \n",
       "Classic Star (new warm-up) 5                              [0.22618704151153565]   \n",
       "\n",
       "                                                                 Train Accuracy  \\\n",
       "Big NN 0                      [0.88476, 0.86182, 0.83478, 0.86832, 0.85316, ...   \n",
       "Ensemble 1                                            [0.90502, 0.898, 0.89716]   \n",
       "Ensemble 2                                           [0.91764, 0.9113, 0.91328]   \n",
       "Ensemble 3                                          [0.92596, 0.91692, 0.91746]   \n",
       "Ensemble 4                                                    [0.9272, 0.91612]   \n",
       "Ensemble 5                                                   [0.93086, 0.92656]   \n",
       "Classic Star (no warm-up) 1                          [0.90172, 0.9019, 0.90802]   \n",
       "Classic Star (no warm-up) 2                          [0.92332, 0.92038, 0.9201]   \n",
       "Classic Star (no warm-up) 3                         [0.92846, 0.92708, 0.92818]   \n",
       "Classic Star (no warm-up) 4                                   [0.93162, 0.9294]   \n",
       "Classic Star (no warm-up) 5                                  [0.93344, 0.93348]   \n",
       "Classic Star (new warm-up) 1                         [0.90642, 0.9049, 0.90828]   \n",
       "Classic Star (new warm-up) 2                         [0.9229, 0.92116, 0.92064]   \n",
       "Classic Star (new warm-up) 3                        [0.92776, 0.92746, 0.92738]   \n",
       "Classic Star (new warm-up) 4                                 [0.93208, 0.92888]   \n",
       "Classic Star (new warm-up) 5                                           [0.9337]   \n",
       "\n",
       "                                                                           Time  \n",
       "Big NN 0                      [900.5, 782.8, 757.3, 758.1, 757.5, 758.5, 776...  \n",
       "Ensemble 1                                             [1683.3, 1740.5, 1557.6]  \n",
       "Ensemble 2                                             [2440.6, 2581.6, 2327.8]  \n",
       "Ensemble 3                                             [3198.7, 3398.3, 3085.9]  \n",
       "Ensemble 4                                                     [3956.2, 4177.6]  \n",
       "Ensemble 5                                          [4714.7, 4934.400000000001]  \n",
       "Classic Star (no warm-up) 1                            [1830.3, 1707.2, 1724.8]  \n",
       "Classic Star (no warm-up) 2                            [2788.0, 2844.2, 2663.1]  \n",
       "Classic Star (no warm-up) 3    [3718.5, 3858.3999999999996, 3652.1000000000004]  \n",
       "Classic Star (no warm-up) 4                         [4650.299999999999, 4848.8]  \n",
       "Classic Star (no warm-up) 5                         [5581.4, 5802.400000000001]  \n",
       "Classic Star (new warm-up) 1               [1796.2, 1705.0, 1725.6999999999998]  \n",
       "Classic Star (new warm-up) 2               [2717.8, 2797.6000000000004, 2669.2]  \n",
       "Classic Star (new warm-up) 3                           [3613.5, 3839.7, 3534.5]  \n",
       "Classic Star (new warm-up) 4                                   [4511.7, 4757.5]  \n",
       "Classic Star (new warm-up) 5                                [5409.799999999999]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv('results/first сifar results.csv')\n",
    "saved = results.copy()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_train_one_epoch(model, train_dataloader, criterion, optimizer, scheduler=None, device='cpu'):\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * y.shape[0]\n",
    "        acc_sum += (y_pred.argmax(dim=-1) == y).sum().item()\n",
    "        total += y.shape[0]\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return loss_sum / total, acc_sum / total\n",
    "\n",
    "\n",
    "\n",
    "def snapshot_train(model, train_dataloader, test_dataloader, epoch_num,\n",
    "                   device='cpu', snap_freq=10, eval_freq=2, plot_freq=2, name=None):\n",
    "    '''\n",
    "    args:\n",
    "        model - model to be trained\n",
    "        train_dataloader - dataloader of training dataset\n",
    "        valid_dataloader - dataloader of validation dataset\n",
    "        epoch_num - amount of epoches to train\n",
    "        optimizer - optimizer\n",
    "        device - device to compute on\n",
    "        tol - tolerance of loss, if difference is < tol, training is stopped\n",
    "        eval_freq - every eval_freq epoches loss on validation dataset is calculated\n",
    "        plot_graph - if true, then real time graph is shown, else loss is printed\n",
    "        scale - scale by which you should multiply loss\n",
    "        name - name of model\n",
    "    \n",
    "    returns:\n",
    "        losses - list of avg loss on training dataset per every test_freq epoches\n",
    "    '''\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    snapshots = []\n",
    "    snap_times = []\n",
    "    \n",
    "    \n",
    "    snapshots = []\n",
    "    snap_times = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader) * snap_freq)\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        loss, acc = snap_train_one_epoch(model, train_dataloader, criterion, optimizer, scheduler, device)\n",
    "        train_losses += [loss]\n",
    "        train_accs += [acc]\n",
    "            \n",
    "        if eval_freq is not None and epoch % eval_freq == eval_freq-1:\n",
    "            loss, acc = evaluate_one_epoch([model], test_dataloader, criterion, device)\n",
    "            test_losses += [loss]\n",
    "            test_accs += [acc]\n",
    "            \n",
    "        if epoch % snap_freq == snap_freq - 1:\n",
    "            snapshots += [copy.deepcopy(model)]\n",
    "            snap_times += [round(time.time() - start_time)]\n",
    "\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader) * snap_freq)\n",
    "\n",
    "\n",
    "        if epoch % plot_freq == plot_freq-1:\n",
    "            fig, axs = plt.subplots(figsize=(14, 7), ncols=2)\n",
    "            axs[0].plot(range(len(train_losses)), train_losses, label='train')\n",
    "            if eval_freq is not None:\n",
    "                axs[0].plot(range(eval_freq-1, len(test_losses)*eval_freq, eval_freq), test_losses, label='test')\n",
    "            axs[0].set(ylabel = 'Cross Entropy Loss', xlabel='Epoch', title='Training Loss')\n",
    "            axs[0].legend()\n",
    "        \n",
    "            axs[1].plot(range(len(train_accs)), train_accs, label='train')\n",
    "            if eval_freq is not None:\n",
    "                axs[1].plot(range(eval_freq-1, len(test_accs)*eval_freq, eval_freq), test_accs, label='test')\n",
    "            axs[1].set(ylabel = 'Accuracy', xlabel='Epoch', title='Training Accuracy')\n",
    "            axs[1].legend()\n",
    "            \n",
    "            clear_output()\n",
    "            plt.show()\n",
    "            print(name, 'epoch number ', epoch, '\\n')\n",
    "            print('time training:', round(time.time() - start_time, 1), 'sec')\n",
    "            print('train acc:', train_accs[-1])\n",
    "            print('test acc:',  test_accs[-1], '\\n\\n')\n",
    "\n",
    "    return snapshots, train_losses, np.array(snap_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_snapshot_experiment(results, model_class=ResNet9, epoches=10, base_am=3, warmup_epoches=2):\n",
    "    base = model_class().to(device)\n",
    "    snapshots, losses, cum_times = snapshot_train(base, train_dataloader, test_dataloader, epoches*(base_am+1),\n",
    "                                                  device=device, snap_freq=epoches, name='snapshot')\n",
    "    \n",
    "    snap_times = cum_times.copy()\n",
    "    snap_times[1:] = np.diff(cum_times)\n",
    "        \n",
    "    for i in range(len(snapshots)):\n",
    "        snapshots[i].to(device)\n",
    "        loss, acc = evaluate_one_epoch(snapshots[i], test_dataloader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_one_epoch(snapshots[i], train_dataloader, criterion, device)\n",
    "        add_res(results, 'Snapshot', [[loss], [acc], [train_loss], [train_acc], [snap_times[i]]])    \n",
    "    \n",
    "\n",
    "    # ensemble -----------------------------------------------------------------\n",
    "    \n",
    "    for i in range(base_am):\n",
    "        loss, acc = evaluate_one_epoch(snapshots[:i+2], test_dataloader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_one_epoch(snapshots[:i+2], train_dataloader, criterion, device)\n",
    "        \n",
    "        add_res(results, 'Snap Ensemble ' + str(i+1), [[loss], [acc], [train_loss], [train_acc], [cum_times[i+1]]])\n",
    "\n",
    "    # star ---------------------------------------------------------------------\n",
    "\n",
    "    star_models = []\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Snap Star (no warm-up) ' + str(i+1)\n",
    "        star = StarRegression(snapshots[:i+1], model_class).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "        losses, accs, time = train(star, train_dataloader, test_dataloader, epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        loss, acc = evaluate_one_epoch(star, test_dataloader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_one_epoch(star, train_dataloader, criterion, device)\n",
    "            \n",
    "        add_res(results, name, [[loss], [acc], [train_loss], [train_acc], [time + cum_times[i]]])\n",
    "\n",
    "\n",
    "    # warmup star ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    warmed = model_class().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(warmed.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "    _, _, warmup_time = train(warmed, train_dataloader, test_dataloader, warmup_epoches,\n",
    "                             optimizer, device=device, name='warmup')\n",
    "\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Snap Star (new warm-up) ' + str(i+1)\n",
    "        star = StarRegression(snapshots[:i+1], model_class, warmup=warmed).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        scheduler=None\n",
    "        \n",
    "        losses, accs, time = train(star, train_dataloader, test_dataloader, epoches - warmup_epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        loss, acc = evaluate_one_epoch(star, test_dataloader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_one_epoch(star, train_dataloader, criterion, device)\n",
    "            \n",
    "        add_res(results, name, [[loss], [acc], [train_loss], [train_acc], [time + warmup_time + cum_times[i]]])\n",
    "\n",
    "\n",
    "    # snap warmup star ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(base_am):\n",
    "        warmed = copy.deepcopy(snapshots[i])\n",
    "\n",
    "        optimizer = torch.optim.Adam(warmed.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        _, _, warmup_time = snapshot_train(warmed, train_dataloader, test_dataloader, warmup_epoches,\n",
    "                                           device=device, snap_freq=warmup_epoches, name='warmup')\n",
    "\n",
    "        name = 'Snap Star (shot warm-up) ' + str(i+1)\n",
    "        star = StarRegression(snapshots[:i+1], model_class, warmup=warmed).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        scheduler=None\n",
    "        \n",
    "        losses, accs, time = train(star, train_dataloader, test_dataloader, epoches - warmup_epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        loss, acc = evaluate_one_epoch(star, test_dataloader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_one_epoch(star, train_dataloader, criterion, device)\n",
    "            \n",
    "        add_res(results, name, [[loss], [acc], [train_loss], [train_acc], [time + warmup_time + cum_times[i]]])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snap Star (shot warm-up) 3 epoch number  7 \n",
      "\n",
      "time training: 1021.7 sec\n",
      "train acc: 0.89138\n",
      "test acc: 0.8521 \n",
      "\n",
      "\n",
      "Training time: 1021.7 seconds\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "NUM_EXPERIMENTS=3\n",
    "for i in range(NUM_EXPERIMENTS):\n",
    "    results = make_snapshot_experiment(results, epoches=10, warmup_epoches=2, base_am=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('results/cifar results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Time</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Big NN 0</th>\n",
       "      <td>[0.4001814534187317, 0.4599046495437622, 0.511...</td>\n",
       "      <td>[0.8677, 0.8436, 0.8244, 0.8457, 0.839, 0.8444...</td>\n",
       "      <td>[0.35745231853961945, 0.40198987390518187, 0.4...</td>\n",
       "      <td>[0.88476, 0.86182, 0.83478, 0.86832, 0.85316, ...</td>\n",
       "      <td>[900.5, 782.8, 757.3, 758.1, 757.5, 758.5, 776...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 1</th>\n",
       "      <td>[0.3430506531238556, 0.36581522212028506, 0.37...</td>\n",
       "      <td>[0.8861, 0.8734, 0.8727]</td>\n",
       "      <td>[0.297635410490036, 0.3075022952079773, 0.3049...</td>\n",
       "      <td>[0.90502, 0.898, 0.89716]</td>\n",
       "      <td>[1683.3, 1740.5, 1557.6]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 2</th>\n",
       "      <td>[0.3155895233631134, 0.3319969253540039, 0.328...</td>\n",
       "      <td>[0.8969, 0.8877, 0.8877]</td>\n",
       "      <td>[0.27331409185409544, 0.2809423043346405, 0.26...</td>\n",
       "      <td>[0.91764, 0.9113, 0.91328]</td>\n",
       "      <td>[2440.6, 2581.6, 2327.8]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 3</th>\n",
       "      <td>[0.29925513768196105, 0.32006648807525634, 0.3...</td>\n",
       "      <td>[0.9023, 0.893, 0.8891]</td>\n",
       "      <td>[0.24825520288467406, 0.2674123253154755, 0.25...</td>\n",
       "      <td>[0.92596, 0.91692, 0.91746]</td>\n",
       "      <td>[3198.7, 3398.3, 3085.9]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 4</th>\n",
       "      <td>[0.29681019439697265, 0.31858636384010314]</td>\n",
       "      <td>[0.9025, 0.8912]</td>\n",
       "      <td>[0.24506483757019043, 0.2651513268852234]</td>\n",
       "      <td>[0.9272, 0.91612]</td>\n",
       "      <td>[3956.2, 4177.6]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 5</th>\n",
       "      <td>[0.28771511678695677, 0.2946513738632202]</td>\n",
       "      <td>[0.9046, 0.9023]</td>\n",
       "      <td>[0.23841904188156127, 0.24606001117229462]</td>\n",
       "      <td>[0.93086, 0.92656]</td>\n",
       "      <td>[4714.7, 4934.400000000001]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 1</th>\n",
       "      <td>[0.3582811215400696, 0.35210523896217344, 0.35...</td>\n",
       "      <td>[0.8821, 0.8789, 0.8819]</td>\n",
       "      <td>[0.3135467227077484, 0.3146791537570953, 0.296...</td>\n",
       "      <td>[0.90172, 0.9019, 0.90802]</td>\n",
       "      <td>[1830.3, 1707.2, 1724.8]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 2</th>\n",
       "      <td>[0.3108438994407654, 0.3160343985557556, 0.313...</td>\n",
       "      <td>[0.898, 0.8933, 0.8964]</td>\n",
       "      <td>[0.2569754233264923, 0.26269870041847226, 0.25...</td>\n",
       "      <td>[0.92332, 0.92038, 0.9201]</td>\n",
       "      <td>[2788.0, 2844.2, 2663.1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 3</th>\n",
       "      <td>[0.292877231502533, 0.29854049582481385, 0.294...</td>\n",
       "      <td>[0.9029, 0.9034, 0.9023]</td>\n",
       "      <td>[0.23867048714160918, 0.24337536680221558, 0.2...</td>\n",
       "      <td>[0.92846, 0.92708, 0.92818]</td>\n",
       "      <td>[3718.5, 3858.3999999999996, 3652.1000000000004]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 4</th>\n",
       "      <td>[0.2845957246303558, 0.2913079014778137]</td>\n",
       "      <td>[0.9071, 0.9047]</td>\n",
       "      <td>[0.22883741600513458, 0.23787778925895692]</td>\n",
       "      <td>[0.93162, 0.9294]</td>\n",
       "      <td>[4650.299999999999, 4848.8]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 5</th>\n",
       "      <td>[0.2813127546310425, 0.2817422402858734]</td>\n",
       "      <td>[0.9073, 0.9079]</td>\n",
       "      <td>[0.2240297388410568, 0.2283222034025192]</td>\n",
       "      <td>[0.93344, 0.93348]</td>\n",
       "      <td>[5581.4, 5802.400000000001]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 1</th>\n",
       "      <td>[0.35132595133781436, 0.34671875286102294, 0.3...</td>\n",
       "      <td>[0.8842, 0.8817, 0.8829]</td>\n",
       "      <td>[0.3053761303329468, 0.308457942943573, 0.2924...</td>\n",
       "      <td>[0.90642, 0.9049, 0.90828]</td>\n",
       "      <td>[1796.2, 1705.0, 1725.6999999999998]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 2</th>\n",
       "      <td>[0.31103485140800474, 0.3120883293628693, 0.31...</td>\n",
       "      <td>[0.898, 0.8964, 0.8957]</td>\n",
       "      <td>[0.259398263630867, 0.2600865338802338, 0.2583...</td>\n",
       "      <td>[0.9229, 0.92116, 0.92064]</td>\n",
       "      <td>[2717.8, 2797.6000000000004, 2669.2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 3</th>\n",
       "      <td>[0.29291184635162354, 0.2992772318840027, 0.29...</td>\n",
       "      <td>[0.9029, 0.9035, 0.9013]</td>\n",
       "      <td>[0.2408954661655426, 0.24411217144966124, 0.24...</td>\n",
       "      <td>[0.92776, 0.92746, 0.92738]</td>\n",
       "      <td>[3613.5, 3839.7, 3534.5]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 4</th>\n",
       "      <td>[0.2841888794898987, 0.29394576539993283]</td>\n",
       "      <td>[0.9077, 0.9037]</td>\n",
       "      <td>[0.22986062653541564, 0.2401577792072296]</td>\n",
       "      <td>[0.93208, 0.92888]</td>\n",
       "      <td>[4511.7, 4757.5]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 5</th>\n",
       "      <td>[0.28236348452568055]</td>\n",
       "      <td>[0.907]</td>\n",
       "      <td>[0.22618704151153565]</td>\n",
       "      <td>[0.9337]</td>\n",
       "      <td>[5409.799999999999]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snapshot</th>\n",
       "      <td>[0.660176691532135, 0.483404047870636, 0.41702...</td>\n",
       "      <td>[0.7658, 0.8325, 0.8575, 0.8724, 0.7634, 0.829...</td>\n",
       "      <td>[0.6468640182304383, 0.41987566924095154, 0.30...</td>\n",
       "      <td>[0.77524, 0.85684, 0.89956, 0.92578, 0.77066, ...</td>\n",
       "      <td>[812, 752, 753, 752, 749, 749, 749, 749, 749, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Ensemble 1</th>\n",
       "      <td>[0.5351601425170899, 0.5457236451148987, 0.535...</td>\n",
       "      <td>[0.8137, 0.812, 0.8144]</td>\n",
       "      <td>[0.49334480310440065, 0.5022271536636352, 0.49...</td>\n",
       "      <td>[0.83272, 0.83134, 0.83308]</td>\n",
       "      <td>[1564, 1498, 1498]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Ensemble 2</th>\n",
       "      <td>[0.46871138772964477, 0.4763269818305969, 0.47...</td>\n",
       "      <td>[0.8365, 0.8363, 0.8367]</td>\n",
       "      <td>[0.3997778698539734, 0.40787676519393923, 0.39...</td>\n",
       "      <td>[0.86728, 0.8644, 0.86936]</td>\n",
       "      <td>[2317, 2247, 2249]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Ensemble 3</th>\n",
       "      <td>[0.4258124871253967, 0.4315573698043823, 0.429...</td>\n",
       "      <td>[0.8529, 0.8491, 0.8534]</td>\n",
       "      <td>[0.3325387121105194, 0.3359697277069092, 0.332...</td>\n",
       "      <td>[0.8913, 0.89048, 0.89156]</td>\n",
       "      <td>[3069, 2996, 2998]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (no warm-up)1</th>\n",
       "      <td>[0.45964179887771606, 0.5201472127437592, 0.51...</td>\n",
       "      <td>[0.8382, 0.8208, 0.8327]</td>\n",
       "      <td>[0.4475654913520813, 0.48220178679466247, 0.49...</td>\n",
       "      <td>[0.845, 0.83366, 0.83646]</td>\n",
       "      <td>[1741.6, 1679.0, 1679.0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (no warm-up)2</th>\n",
       "      <td>[0.4907514078140259, 0.5038101556301117, 0.496...</td>\n",
       "      <td>[0.8331, 0.828, 0.8288]</td>\n",
       "      <td>[0.4394539219093323, 0.4453655867576599, 0.433...</td>\n",
       "      <td>[0.85376, 0.85372, 0.85782]</td>\n",
       "      <td>[2667.7, 2602.4, 2601.7]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (no warm-up)3</th>\n",
       "      <td>[0.42059751143455504, 0.42719009923934936, 0.4...</td>\n",
       "      <td>[0.856, 0.8498, 0.8528]</td>\n",
       "      <td>[0.3246989821195602, 0.329093617811203, 0.3229...</td>\n",
       "      <td>[0.8955, 0.89338, 0.89542]</td>\n",
       "      <td>[3595.0, 3523.9, 3526.7]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (new warm-up) 1</th>\n",
       "      <td>[0.45103696627616885, 0.41390582637786866, 0.4...</td>\n",
       "      <td>[0.8462, 0.8598, 0.8604]</td>\n",
       "      <td>[0.3360528066158295, 0.3347944870185852, 0.325...</td>\n",
       "      <td>[0.88186, 0.8836, 0.88568]</td>\n",
       "      <td>[1708.5, 1644.3, 1644.3]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (new warm-up) 2</th>\n",
       "      <td>[0.4539941235780716, 0.4137339750766754, 0.506...</td>\n",
       "      <td>[0.8474, 0.8547, 0.8401]</td>\n",
       "      <td>[0.3770606425380707, 0.34675657097816465, 0.39...</td>\n",
       "      <td>[0.86656, 0.87774, 0.86016]</td>\n",
       "      <td>[2598.8, 2532.0, 2532.0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (new warm-up) 3</th>\n",
       "      <td>[0.38316862828731535, 0.38378507661819455, 0.3...</td>\n",
       "      <td>[0.8673, 0.8677, 0.8767]</td>\n",
       "      <td>[0.29372046738624574, 0.2988890048599243, 0.27...</td>\n",
       "      <td>[0.9014, 0.89728, 0.91402]</td>\n",
       "      <td>[3492.3, 3419.4, 3422.0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (shot warm-up) 1</th>\n",
       "      <td>[0.3558272723197937, 0.44945554895401, 0.49928...</td>\n",
       "      <td>[0.8766, 0.8453, 0.8386]</td>\n",
       "      <td>[0.2766768713569641, 0.3772724753379822, 0.412...</td>\n",
       "      <td>[0.90558, 0.8666, 0.85998]</td>\n",
       "      <td>[[1706.5], [1642.0], [1643.2]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (shot warm-up) 2</th>\n",
       "      <td>[0.4631200907707214, 0.4953668309211731, 0.455...</td>\n",
       "      <td>[0.838, 0.8296, 0.844]</td>\n",
       "      <td>[0.4140836661148071, 0.4394523384666443, 0.401...</td>\n",
       "      <td>[0.86056, 0.85448, 0.86434]</td>\n",
       "      <td>[[2597.7], [2531.3], [2530.1]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (shot warm-up) 3</th>\n",
       "      <td>[0.4247462708950043, 0.43244167037010195, 0.43...</td>\n",
       "      <td>[0.8544, 0.8493, 0.8521]</td>\n",
       "      <td>[0.33427501532554627, 0.33958159380912784, 0.3...</td>\n",
       "      <td>[0.89284, 0.89122, 0.89288]</td>\n",
       "      <td>[[3490.0], [3417.1], [3420.7]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big NN 1</th>\n",
       "      <td>[0.4449742022037506]</td>\n",
       "      <td>[0.8472]</td>\n",
       "      <td>[0.38053372703552246]</td>\n",
       "      <td>[0.87012]</td>\n",
       "      <td>[1598.9]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big NN 2</th>\n",
       "      <td>[0.5283780077934265]</td>\n",
       "      <td>[0.8284]</td>\n",
       "      <td>[0.458850551776886]</td>\n",
       "      <td>[0.84428]</td>\n",
       "      <td>[2308.1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big NN 3</th>\n",
       "      <td>[0.40379435081481935]</td>\n",
       "      <td>[0.8641]</td>\n",
       "      <td>[0.34096638934135437]</td>\n",
       "      <td>[0.8831]</td>\n",
       "      <td>[3019.5]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           Loss  \\\n",
       "Big NN 0                      [0.4001814534187317, 0.4599046495437622, 0.511...   \n",
       "Ensemble 1                    [0.3430506531238556, 0.36581522212028506, 0.37...   \n",
       "Ensemble 2                    [0.3155895233631134, 0.3319969253540039, 0.328...   \n",
       "Ensemble 3                    [0.29925513768196105, 0.32006648807525634, 0.3...   \n",
       "Ensemble 4                           [0.29681019439697265, 0.31858636384010314]   \n",
       "Ensemble 5                            [0.28771511678695677, 0.2946513738632202]   \n",
       "Classic Star (no warm-up) 1   [0.3582811215400696, 0.35210523896217344, 0.35...   \n",
       "Classic Star (no warm-up) 2   [0.3108438994407654, 0.3160343985557556, 0.313...   \n",
       "Classic Star (no warm-up) 3   [0.292877231502533, 0.29854049582481385, 0.294...   \n",
       "Classic Star (no warm-up) 4            [0.2845957246303558, 0.2913079014778137]   \n",
       "Classic Star (no warm-up) 5            [0.2813127546310425, 0.2817422402858734]   \n",
       "Classic Star (new warm-up) 1  [0.35132595133781436, 0.34671875286102294, 0.3...   \n",
       "Classic Star (new warm-up) 2  [0.31103485140800474, 0.3120883293628693, 0.31...   \n",
       "Classic Star (new warm-up) 3  [0.29291184635162354, 0.2992772318840027, 0.29...   \n",
       "Classic Star (new warm-up) 4          [0.2841888794898987, 0.29394576539993283]   \n",
       "Classic Star (new warm-up) 5                              [0.28236348452568055]   \n",
       "Snapshot                      [0.660176691532135, 0.483404047870636, 0.41702...   \n",
       "Snap Ensemble 1               [0.5351601425170899, 0.5457236451148987, 0.535...   \n",
       "Snap Ensemble 2               [0.46871138772964477, 0.4763269818305969, 0.47...   \n",
       "Snap Ensemble 3               [0.4258124871253967, 0.4315573698043823, 0.429...   \n",
       "Snap Star (no warm-up)1       [0.45964179887771606, 0.5201472127437592, 0.51...   \n",
       "Snap Star (no warm-up)2       [0.4907514078140259, 0.5038101556301117, 0.496...   \n",
       "Snap Star (no warm-up)3       [0.42059751143455504, 0.42719009923934936, 0.4...   \n",
       "Snap Star (new warm-up) 1     [0.45103696627616885, 0.41390582637786866, 0.4...   \n",
       "Snap Star (new warm-up) 2     [0.4539941235780716, 0.4137339750766754, 0.506...   \n",
       "Snap Star (new warm-up) 3     [0.38316862828731535, 0.38378507661819455, 0.3...   \n",
       "Snap Star (shot warm-up) 1    [0.3558272723197937, 0.44945554895401, 0.49928...   \n",
       "Snap Star (shot warm-up) 2    [0.4631200907707214, 0.4953668309211731, 0.455...   \n",
       "Snap Star (shot warm-up) 3    [0.4247462708950043, 0.43244167037010195, 0.43...   \n",
       "Big NN 1                                                   [0.4449742022037506]   \n",
       "Big NN 2                                                   [0.5283780077934265]   \n",
       "Big NN 3                                                  [0.40379435081481935]   \n",
       "\n",
       "                                                                       Accuracy  \\\n",
       "Big NN 0                      [0.8677, 0.8436, 0.8244, 0.8457, 0.839, 0.8444...   \n",
       "Ensemble 1                                             [0.8861, 0.8734, 0.8727]   \n",
       "Ensemble 2                                             [0.8969, 0.8877, 0.8877]   \n",
       "Ensemble 3                                              [0.9023, 0.893, 0.8891]   \n",
       "Ensemble 4                                                     [0.9025, 0.8912]   \n",
       "Ensemble 5                                                     [0.9046, 0.9023]   \n",
       "Classic Star (no warm-up) 1                            [0.8821, 0.8789, 0.8819]   \n",
       "Classic Star (no warm-up) 2                             [0.898, 0.8933, 0.8964]   \n",
       "Classic Star (no warm-up) 3                            [0.9029, 0.9034, 0.9023]   \n",
       "Classic Star (no warm-up) 4                                    [0.9071, 0.9047]   \n",
       "Classic Star (no warm-up) 5                                    [0.9073, 0.9079]   \n",
       "Classic Star (new warm-up) 1                           [0.8842, 0.8817, 0.8829]   \n",
       "Classic Star (new warm-up) 2                            [0.898, 0.8964, 0.8957]   \n",
       "Classic Star (new warm-up) 3                           [0.9029, 0.9035, 0.9013]   \n",
       "Classic Star (new warm-up) 4                                   [0.9077, 0.9037]   \n",
       "Classic Star (new warm-up) 5                                            [0.907]   \n",
       "Snapshot                      [0.7658, 0.8325, 0.8575, 0.8724, 0.7634, 0.829...   \n",
       "Snap Ensemble 1                                         [0.8137, 0.812, 0.8144]   \n",
       "Snap Ensemble 2                                        [0.8365, 0.8363, 0.8367]   \n",
       "Snap Ensemble 3                                        [0.8529, 0.8491, 0.8534]   \n",
       "Snap Star (no warm-up)1                                [0.8382, 0.8208, 0.8327]   \n",
       "Snap Star (no warm-up)2                                 [0.8331, 0.828, 0.8288]   \n",
       "Snap Star (no warm-up)3                                 [0.856, 0.8498, 0.8528]   \n",
       "Snap Star (new warm-up) 1                              [0.8462, 0.8598, 0.8604]   \n",
       "Snap Star (new warm-up) 2                              [0.8474, 0.8547, 0.8401]   \n",
       "Snap Star (new warm-up) 3                              [0.8673, 0.8677, 0.8767]   \n",
       "Snap Star (shot warm-up) 1                             [0.8766, 0.8453, 0.8386]   \n",
       "Snap Star (shot warm-up) 2                               [0.838, 0.8296, 0.844]   \n",
       "Snap Star (shot warm-up) 3                             [0.8544, 0.8493, 0.8521]   \n",
       "Big NN 1                                                               [0.8472]   \n",
       "Big NN 2                                                               [0.8284]   \n",
       "Big NN 3                                                               [0.8641]   \n",
       "\n",
       "                                                                     Train Loss  \\\n",
       "Big NN 0                      [0.35745231853961945, 0.40198987390518187, 0.4...   \n",
       "Ensemble 1                    [0.297635410490036, 0.3075022952079773, 0.3049...   \n",
       "Ensemble 2                    [0.27331409185409544, 0.2809423043346405, 0.26...   \n",
       "Ensemble 3                    [0.24825520288467406, 0.2674123253154755, 0.25...   \n",
       "Ensemble 4                            [0.24506483757019043, 0.2651513268852234]   \n",
       "Ensemble 5                           [0.23841904188156127, 0.24606001117229462]   \n",
       "Classic Star (no warm-up) 1   [0.3135467227077484, 0.3146791537570953, 0.296...   \n",
       "Classic Star (no warm-up) 2   [0.2569754233264923, 0.26269870041847226, 0.25...   \n",
       "Classic Star (no warm-up) 3   [0.23867048714160918, 0.24337536680221558, 0.2...   \n",
       "Classic Star (no warm-up) 4          [0.22883741600513458, 0.23787778925895692]   \n",
       "Classic Star (no warm-up) 5            [0.2240297388410568, 0.2283222034025192]   \n",
       "Classic Star (new warm-up) 1  [0.3053761303329468, 0.308457942943573, 0.2924...   \n",
       "Classic Star (new warm-up) 2  [0.259398263630867, 0.2600865338802338, 0.2583...   \n",
       "Classic Star (new warm-up) 3  [0.2408954661655426, 0.24411217144966124, 0.24...   \n",
       "Classic Star (new warm-up) 4          [0.22986062653541564, 0.2401577792072296]   \n",
       "Classic Star (new warm-up) 5                              [0.22618704151153565]   \n",
       "Snapshot                      [0.6468640182304383, 0.41987566924095154, 0.30...   \n",
       "Snap Ensemble 1               [0.49334480310440065, 0.5022271536636352, 0.49...   \n",
       "Snap Ensemble 2               [0.3997778698539734, 0.40787676519393923, 0.39...   \n",
       "Snap Ensemble 3               [0.3325387121105194, 0.3359697277069092, 0.332...   \n",
       "Snap Star (no warm-up)1       [0.4475654913520813, 0.48220178679466247, 0.49...   \n",
       "Snap Star (no warm-up)2       [0.4394539219093323, 0.4453655867576599, 0.433...   \n",
       "Snap Star (no warm-up)3       [0.3246989821195602, 0.329093617811203, 0.3229...   \n",
       "Snap Star (new warm-up) 1     [0.3360528066158295, 0.3347944870185852, 0.325...   \n",
       "Snap Star (new warm-up) 2     [0.3770606425380707, 0.34675657097816465, 0.39...   \n",
       "Snap Star (new warm-up) 3     [0.29372046738624574, 0.2988890048599243, 0.27...   \n",
       "Snap Star (shot warm-up) 1    [0.2766768713569641, 0.3772724753379822, 0.412...   \n",
       "Snap Star (shot warm-up) 2    [0.4140836661148071, 0.4394523384666443, 0.401...   \n",
       "Snap Star (shot warm-up) 3    [0.33427501532554627, 0.33958159380912784, 0.3...   \n",
       "Big NN 1                                                  [0.38053372703552246]   \n",
       "Big NN 2                                                    [0.458850551776886]   \n",
       "Big NN 3                                                  [0.34096638934135437]   \n",
       "\n",
       "                                                                 Train Accuracy  \\\n",
       "Big NN 0                      [0.88476, 0.86182, 0.83478, 0.86832, 0.85316, ...   \n",
       "Ensemble 1                                            [0.90502, 0.898, 0.89716]   \n",
       "Ensemble 2                                           [0.91764, 0.9113, 0.91328]   \n",
       "Ensemble 3                                          [0.92596, 0.91692, 0.91746]   \n",
       "Ensemble 4                                                    [0.9272, 0.91612]   \n",
       "Ensemble 5                                                   [0.93086, 0.92656]   \n",
       "Classic Star (no warm-up) 1                          [0.90172, 0.9019, 0.90802]   \n",
       "Classic Star (no warm-up) 2                          [0.92332, 0.92038, 0.9201]   \n",
       "Classic Star (no warm-up) 3                         [0.92846, 0.92708, 0.92818]   \n",
       "Classic Star (no warm-up) 4                                   [0.93162, 0.9294]   \n",
       "Classic Star (no warm-up) 5                                  [0.93344, 0.93348]   \n",
       "Classic Star (new warm-up) 1                         [0.90642, 0.9049, 0.90828]   \n",
       "Classic Star (new warm-up) 2                         [0.9229, 0.92116, 0.92064]   \n",
       "Classic Star (new warm-up) 3                        [0.92776, 0.92746, 0.92738]   \n",
       "Classic Star (new warm-up) 4                                 [0.93208, 0.92888]   \n",
       "Classic Star (new warm-up) 5                                           [0.9337]   \n",
       "Snapshot                      [0.77524, 0.85684, 0.89956, 0.92578, 0.77066, ...   \n",
       "Snap Ensemble 1                                     [0.83272, 0.83134, 0.83308]   \n",
       "Snap Ensemble 2                                      [0.86728, 0.8644, 0.86936]   \n",
       "Snap Ensemble 3                                      [0.8913, 0.89048, 0.89156]   \n",
       "Snap Star (no warm-up)1                               [0.845, 0.83366, 0.83646]   \n",
       "Snap Star (no warm-up)2                             [0.85376, 0.85372, 0.85782]   \n",
       "Snap Star (no warm-up)3                              [0.8955, 0.89338, 0.89542]   \n",
       "Snap Star (new warm-up) 1                            [0.88186, 0.8836, 0.88568]   \n",
       "Snap Star (new warm-up) 2                           [0.86656, 0.87774, 0.86016]   \n",
       "Snap Star (new warm-up) 3                            [0.9014, 0.89728, 0.91402]   \n",
       "Snap Star (shot warm-up) 1                           [0.90558, 0.8666, 0.85998]   \n",
       "Snap Star (shot warm-up) 2                          [0.86056, 0.85448, 0.86434]   \n",
       "Snap Star (shot warm-up) 3                          [0.89284, 0.89122, 0.89288]   \n",
       "Big NN 1                                                              [0.87012]   \n",
       "Big NN 2                                                              [0.84428]   \n",
       "Big NN 3                                                               [0.8831]   \n",
       "\n",
       "                                                                           Time  \\\n",
       "Big NN 0                      [900.5, 782.8, 757.3, 758.1, 757.5, 758.5, 776...   \n",
       "Ensemble 1                                             [1683.3, 1740.5, 1557.6]   \n",
       "Ensemble 2                                             [2440.6, 2581.6, 2327.8]   \n",
       "Ensemble 3                                             [3198.7, 3398.3, 3085.9]   \n",
       "Ensemble 4                                                     [3956.2, 4177.6]   \n",
       "Ensemble 5                                          [4714.7, 4934.400000000001]   \n",
       "Classic Star (no warm-up) 1                            [1830.3, 1707.2, 1724.8]   \n",
       "Classic Star (no warm-up) 2                            [2788.0, 2844.2, 2663.1]   \n",
       "Classic Star (no warm-up) 3    [3718.5, 3858.3999999999996, 3652.1000000000004]   \n",
       "Classic Star (no warm-up) 4                         [4650.299999999999, 4848.8]   \n",
       "Classic Star (no warm-up) 5                         [5581.4, 5802.400000000001]   \n",
       "Classic Star (new warm-up) 1               [1796.2, 1705.0, 1725.6999999999998]   \n",
       "Classic Star (new warm-up) 2               [2717.8, 2797.6000000000004, 2669.2]   \n",
       "Classic Star (new warm-up) 3                           [3613.5, 3839.7, 3534.5]   \n",
       "Classic Star (new warm-up) 4                                   [4511.7, 4757.5]   \n",
       "Classic Star (new warm-up) 5                                [5409.799999999999]   \n",
       "Snapshot                      [812, 752, 753, 752, 749, 749, 749, 749, 749, ...   \n",
       "Snap Ensemble 1                                              [1564, 1498, 1498]   \n",
       "Snap Ensemble 2                                              [2317, 2247, 2249]   \n",
       "Snap Ensemble 3                                              [3069, 2996, 2998]   \n",
       "Snap Star (no warm-up)1                                [1741.6, 1679.0, 1679.0]   \n",
       "Snap Star (no warm-up)2                                [2667.7, 2602.4, 2601.7]   \n",
       "Snap Star (no warm-up)3                                [3595.0, 3523.9, 3526.7]   \n",
       "Snap Star (new warm-up) 1                              [1708.5, 1644.3, 1644.3]   \n",
       "Snap Star (new warm-up) 2                              [2598.8, 2532.0, 2532.0]   \n",
       "Snap Star (new warm-up) 3                              [3492.3, 3419.4, 3422.0]   \n",
       "Snap Star (shot warm-up) 1                       [[1706.5], [1642.0], [1643.2]]   \n",
       "Snap Star (shot warm-up) 2                       [[2597.7], [2531.3], [2530.1]]   \n",
       "Snap Star (shot warm-up) 3                       [[3490.0], [3417.1], [3420.7]]   \n",
       "Big NN 1                                                               [1598.9]   \n",
       "Big NN 2                                                               [2308.1]   \n",
       "Big NN 3                                                               [3019.5]   \n",
       "\n",
       "                                d  \n",
       "Big NN 0                        0  \n",
       "Ensemble 1                      1  \n",
       "Ensemble 2                      2  \n",
       "Ensemble 3                      3  \n",
       "Ensemble 4                      4  \n",
       "Ensemble 5                      5  \n",
       "Classic Star (no warm-up) 1     1  \n",
       "Classic Star (no warm-up) 2     2  \n",
       "Classic Star (no warm-up) 3     3  \n",
       "Classic Star (no warm-up) 4     4  \n",
       "Classic Star (no warm-up) 5     5  \n",
       "Classic Star (new warm-up) 1    1  \n",
       "Classic Star (new warm-up) 2    2  \n",
       "Classic Star (new warm-up) 3    3  \n",
       "Classic Star (new warm-up) 4    4  \n",
       "Classic Star (new warm-up) 5    5  \n",
       "Snapshot                      NaN  \n",
       "Snap Ensemble 1               NaN  \n",
       "Snap Ensemble 2               NaN  \n",
       "Snap Ensemble 3               NaN  \n",
       "Snap Star (no warm-up)1       NaN  \n",
       "Snap Star (no warm-up)2       NaN  \n",
       "Snap Star (no warm-up)3       NaN  \n",
       "Snap Star (new warm-up) 1     NaN  \n",
       "Snap Star (new warm-up) 2     NaN  \n",
       "Snap Star (new warm-up) 3     NaN  \n",
       "Snap Star (shot warm-up) 1    NaN  \n",
       "Snap Star (shot warm-up) 2    NaN  \n",
       "Snap Star (shot warm-up) 3    NaN  \n",
       "Big NN 1                      NaN  \n",
       "Big NN 2                      NaN  \n",
       "Big NN 3                      NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = copy_res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop([\n",
    "    'Ensemble 4', 'Ensemble 5',\n",
    "    'Classic Star (no warm-up) 4', 'Classic Star (no warm-up) 5',\n",
    "    'Classic Star (new warm-up) 4', 'Classic Star (new warm-up) 5'\n",
    "                       \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Time</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Big NN 0</th>\n",
       "      <td>[0.4001814534187317, 0.4599046495437622, 0.511...</td>\n",
       "      <td>[0.8677, 0.8436, 0.8244, 0.8457, 0.839, 0.8444...</td>\n",
       "      <td>[0.35745231853961945, 0.40198987390518187, 0.4...</td>\n",
       "      <td>[0.88476, 0.86182, 0.83478, 0.86832, 0.85316, ...</td>\n",
       "      <td>[900.5, 782.8, 757.3, 758.1, 757.5, 758.5, 776...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 1</th>\n",
       "      <td>[0.3430506531238556, 0.36581522212028506, 0.37...</td>\n",
       "      <td>[0.8861, 0.8734, 0.8727]</td>\n",
       "      <td>[0.297635410490036, 0.3075022952079773, 0.3049...</td>\n",
       "      <td>[0.90502, 0.898, 0.89716]</td>\n",
       "      <td>[1683.3, 1740.5, 1557.6]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 2</th>\n",
       "      <td>[0.3155895233631134, 0.3319969253540039, 0.328...</td>\n",
       "      <td>[0.8969, 0.8877, 0.8877]</td>\n",
       "      <td>[0.27331409185409544, 0.2809423043346405, 0.26...</td>\n",
       "      <td>[0.91764, 0.9113, 0.91328]</td>\n",
       "      <td>[2440.6, 2581.6, 2327.8]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 3</th>\n",
       "      <td>[0.29925513768196105, 0.32006648807525634, 0.3...</td>\n",
       "      <td>[0.9023, 0.893, 0.8891]</td>\n",
       "      <td>[0.24825520288467406, 0.2674123253154755, 0.25...</td>\n",
       "      <td>[0.92596, 0.91692, 0.91746]</td>\n",
       "      <td>[3198.7, 3398.3, 3085.9]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 1</th>\n",
       "      <td>[0.3582811215400696, 0.35210523896217344, 0.35...</td>\n",
       "      <td>[0.8821, 0.8789, 0.8819]</td>\n",
       "      <td>[0.3135467227077484, 0.3146791537570953, 0.296...</td>\n",
       "      <td>[0.90172, 0.9019, 0.90802]</td>\n",
       "      <td>[1830.3, 1707.2, 1724.8]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 2</th>\n",
       "      <td>[0.3108438994407654, 0.3160343985557556, 0.313...</td>\n",
       "      <td>[0.898, 0.8933, 0.8964]</td>\n",
       "      <td>[0.2569754233264923, 0.26269870041847226, 0.25...</td>\n",
       "      <td>[0.92332, 0.92038, 0.9201]</td>\n",
       "      <td>[2788.0, 2844.2, 2663.1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (no warm-up) 3</th>\n",
       "      <td>[0.292877231502533, 0.29854049582481385, 0.294...</td>\n",
       "      <td>[0.9029, 0.9034, 0.9023]</td>\n",
       "      <td>[0.23867048714160918, 0.24337536680221558, 0.2...</td>\n",
       "      <td>[0.92846, 0.92708, 0.92818]</td>\n",
       "      <td>[3718.5, 3858.3999999999996, 3652.1000000000004]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 1</th>\n",
       "      <td>[0.35132595133781436, 0.34671875286102294, 0.3...</td>\n",
       "      <td>[0.8842, 0.8817, 0.8829]</td>\n",
       "      <td>[0.3053761303329468, 0.308457942943573, 0.2924...</td>\n",
       "      <td>[0.90642, 0.9049, 0.90828]</td>\n",
       "      <td>[1796.2, 1705.0, 1725.6999999999998]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 2</th>\n",
       "      <td>[0.31103485140800474, 0.3120883293628693, 0.31...</td>\n",
       "      <td>[0.898, 0.8964, 0.8957]</td>\n",
       "      <td>[0.259398263630867, 0.2600865338802338, 0.2583...</td>\n",
       "      <td>[0.9229, 0.92116, 0.92064]</td>\n",
       "      <td>[2717.8, 2797.6000000000004, 2669.2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Star (new warm-up) 3</th>\n",
       "      <td>[0.29291184635162354, 0.2992772318840027, 0.29...</td>\n",
       "      <td>[0.9029, 0.9035, 0.9013]</td>\n",
       "      <td>[0.2408954661655426, 0.24411217144966124, 0.24...</td>\n",
       "      <td>[0.92776, 0.92746, 0.92738]</td>\n",
       "      <td>[3613.5, 3839.7, 3534.5]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snapshot 0</th>\n",
       "      <td>[0.660176691532135, 0.483404047870636, 0.41702...</td>\n",
       "      <td>[0.7658, 0.8325, 0.8575, 0.8724, 0.7634, 0.829...</td>\n",
       "      <td>[0.6468640182304383, 0.41987566924095154, 0.30...</td>\n",
       "      <td>[0.77524, 0.85684, 0.89956, 0.92578, 0.77066, ...</td>\n",
       "      <td>[812, 752, 753, 752, 749, 749, 749, 749, 749, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Ensemble 1</th>\n",
       "      <td>[0.5351601425170899, 0.5457236451148987, 0.535...</td>\n",
       "      <td>[0.8137, 0.812, 0.8144]</td>\n",
       "      <td>[0.49334480310440065, 0.5022271536636352, 0.49...</td>\n",
       "      <td>[0.83272, 0.83134, 0.83308]</td>\n",
       "      <td>[1564, 1498, 1498]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Ensemble 2</th>\n",
       "      <td>[0.46871138772964477, 0.4763269818305969, 0.47...</td>\n",
       "      <td>[0.8365, 0.8363, 0.8367]</td>\n",
       "      <td>[0.3997778698539734, 0.40787676519393923, 0.39...</td>\n",
       "      <td>[0.86728, 0.8644, 0.86936]</td>\n",
       "      <td>[2317, 2247, 2249]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Ensemble 3</th>\n",
       "      <td>[0.4258124871253967, 0.4315573698043823, 0.429...</td>\n",
       "      <td>[0.8529, 0.8491, 0.8534]</td>\n",
       "      <td>[0.3325387121105194, 0.3359697277069092, 0.332...</td>\n",
       "      <td>[0.8913, 0.89048, 0.89156]</td>\n",
       "      <td>[3069, 2996, 2998]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (no warm-up) 1</th>\n",
       "      <td>[0.45964179887771606, 0.5201472127437592, 0.51...</td>\n",
       "      <td>[0.8382, 0.8208, 0.8327]</td>\n",
       "      <td>[0.4475654913520813, 0.48220178679466247, 0.49...</td>\n",
       "      <td>[0.845, 0.83366, 0.83646]</td>\n",
       "      <td>[1741.6, 1679.0, 1679.0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (no warm-up) 2</th>\n",
       "      <td>[0.4907514078140259, 0.5038101556301117, 0.496...</td>\n",
       "      <td>[0.8331, 0.828, 0.8288]</td>\n",
       "      <td>[0.4394539219093323, 0.4453655867576599, 0.433...</td>\n",
       "      <td>[0.85376, 0.85372, 0.85782]</td>\n",
       "      <td>[2667.7, 2602.4, 2601.7]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (no warm-up) 3</th>\n",
       "      <td>[0.42059751143455504, 0.42719009923934936, 0.4...</td>\n",
       "      <td>[0.856, 0.8498, 0.8528]</td>\n",
       "      <td>[0.3246989821195602, 0.329093617811203, 0.3229...</td>\n",
       "      <td>[0.8955, 0.89338, 0.89542]</td>\n",
       "      <td>[3595.0, 3523.9, 3526.7]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (new warm-up) 1</th>\n",
       "      <td>[0.45103696627616885, 0.41390582637786866, 0.4...</td>\n",
       "      <td>[0.8462, 0.8598, 0.8604]</td>\n",
       "      <td>[0.3360528066158295, 0.3347944870185852, 0.325...</td>\n",
       "      <td>[0.88186, 0.8836, 0.88568]</td>\n",
       "      <td>[1708.5, 1644.3, 1644.3]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (new warm-up) 2</th>\n",
       "      <td>[0.4539941235780716, 0.4137339750766754, 0.506...</td>\n",
       "      <td>[0.8474, 0.8547, 0.8401]</td>\n",
       "      <td>[0.3770606425380707, 0.34675657097816465, 0.39...</td>\n",
       "      <td>[0.86656, 0.87774, 0.86016]</td>\n",
       "      <td>[2598.8, 2532.0, 2532.0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (new warm-up) 3</th>\n",
       "      <td>[0.38316862828731535, 0.38378507661819455, 0.3...</td>\n",
       "      <td>[0.8673, 0.8677, 0.8767]</td>\n",
       "      <td>[0.29372046738624574, 0.2988890048599243, 0.27...</td>\n",
       "      <td>[0.9014, 0.89728, 0.91402]</td>\n",
       "      <td>[3492.3, 3419.4, 3422.0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (shot warm-up) 1</th>\n",
       "      <td>[0.3558272723197937, 0.44945554895401, 0.49928...</td>\n",
       "      <td>[0.8766, 0.8453, 0.8386]</td>\n",
       "      <td>[0.2766768713569641, 0.3772724753379822, 0.412...</td>\n",
       "      <td>[0.90558, 0.8666, 0.85998]</td>\n",
       "      <td>[[1706.5], [1642.0], [1643.2]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (shot warm-up) 2</th>\n",
       "      <td>[0.4631200907707214, 0.4953668309211731, 0.455...</td>\n",
       "      <td>[0.838, 0.8296, 0.844]</td>\n",
       "      <td>[0.4140836661148071, 0.4394523384666443, 0.401...</td>\n",
       "      <td>[0.86056, 0.85448, 0.86434]</td>\n",
       "      <td>[[2597.7], [2531.3], [2530.1]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snap Star (shot warm-up) 3</th>\n",
       "      <td>[0.4247462708950043, 0.43244167037010195, 0.43...</td>\n",
       "      <td>[0.8544, 0.8493, 0.8521]</td>\n",
       "      <td>[0.33427501532554627, 0.33958159380912784, 0.3...</td>\n",
       "      <td>[0.89284, 0.89122, 0.89288]</td>\n",
       "      <td>[[3490.0], [3417.1], [3420.7]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big NN 1</th>\n",
       "      <td>[0.4449742022037506]</td>\n",
       "      <td>[0.8472]</td>\n",
       "      <td>[0.38053372703552246]</td>\n",
       "      <td>[0.87012]</td>\n",
       "      <td>[1598.9]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big NN 2</th>\n",
       "      <td>[0.5283780077934265]</td>\n",
       "      <td>[0.8284]</td>\n",
       "      <td>[0.458850551776886]</td>\n",
       "      <td>[0.84428]</td>\n",
       "      <td>[2308.1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big NN 3</th>\n",
       "      <td>[0.40379435081481935]</td>\n",
       "      <td>[0.8641]</td>\n",
       "      <td>[0.34096638934135437]</td>\n",
       "      <td>[0.8831]</td>\n",
       "      <td>[3019.5]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           Loss  \\\n",
       "Big NN 0                      [0.4001814534187317, 0.4599046495437622, 0.511...   \n",
       "Ensemble 1                    [0.3430506531238556, 0.36581522212028506, 0.37...   \n",
       "Ensemble 2                    [0.3155895233631134, 0.3319969253540039, 0.328...   \n",
       "Ensemble 3                    [0.29925513768196105, 0.32006648807525634, 0.3...   \n",
       "Classic Star (no warm-up) 1   [0.3582811215400696, 0.35210523896217344, 0.35...   \n",
       "Classic Star (no warm-up) 2   [0.3108438994407654, 0.3160343985557556, 0.313...   \n",
       "Classic Star (no warm-up) 3   [0.292877231502533, 0.29854049582481385, 0.294...   \n",
       "Classic Star (new warm-up) 1  [0.35132595133781436, 0.34671875286102294, 0.3...   \n",
       "Classic Star (new warm-up) 2  [0.31103485140800474, 0.3120883293628693, 0.31...   \n",
       "Classic Star (new warm-up) 3  [0.29291184635162354, 0.2992772318840027, 0.29...   \n",
       "Snapshot 0                    [0.660176691532135, 0.483404047870636, 0.41702...   \n",
       "Snap Ensemble 1               [0.5351601425170899, 0.5457236451148987, 0.535...   \n",
       "Snap Ensemble 2               [0.46871138772964477, 0.4763269818305969, 0.47...   \n",
       "Snap Ensemble 3               [0.4258124871253967, 0.4315573698043823, 0.429...   \n",
       "Snap Star (no warm-up) 1      [0.45964179887771606, 0.5201472127437592, 0.51...   \n",
       "Snap Star (no warm-up) 2      [0.4907514078140259, 0.5038101556301117, 0.496...   \n",
       "Snap Star (no warm-up) 3      [0.42059751143455504, 0.42719009923934936, 0.4...   \n",
       "Snap Star (new warm-up) 1     [0.45103696627616885, 0.41390582637786866, 0.4...   \n",
       "Snap Star (new warm-up) 2     [0.4539941235780716, 0.4137339750766754, 0.506...   \n",
       "Snap Star (new warm-up) 3     [0.38316862828731535, 0.38378507661819455, 0.3...   \n",
       "Snap Star (shot warm-up) 1    [0.3558272723197937, 0.44945554895401, 0.49928...   \n",
       "Snap Star (shot warm-up) 2    [0.4631200907707214, 0.4953668309211731, 0.455...   \n",
       "Snap Star (shot warm-up) 3    [0.4247462708950043, 0.43244167037010195, 0.43...   \n",
       "Big NN 1                                                   [0.4449742022037506]   \n",
       "Big NN 2                                                   [0.5283780077934265]   \n",
       "Big NN 3                                                  [0.40379435081481935]   \n",
       "\n",
       "                                                                       Accuracy  \\\n",
       "Big NN 0                      [0.8677, 0.8436, 0.8244, 0.8457, 0.839, 0.8444...   \n",
       "Ensemble 1                                             [0.8861, 0.8734, 0.8727]   \n",
       "Ensemble 2                                             [0.8969, 0.8877, 0.8877]   \n",
       "Ensemble 3                                              [0.9023, 0.893, 0.8891]   \n",
       "Classic Star (no warm-up) 1                            [0.8821, 0.8789, 0.8819]   \n",
       "Classic Star (no warm-up) 2                             [0.898, 0.8933, 0.8964]   \n",
       "Classic Star (no warm-up) 3                            [0.9029, 0.9034, 0.9023]   \n",
       "Classic Star (new warm-up) 1                           [0.8842, 0.8817, 0.8829]   \n",
       "Classic Star (new warm-up) 2                            [0.898, 0.8964, 0.8957]   \n",
       "Classic Star (new warm-up) 3                           [0.9029, 0.9035, 0.9013]   \n",
       "Snapshot 0                    [0.7658, 0.8325, 0.8575, 0.8724, 0.7634, 0.829...   \n",
       "Snap Ensemble 1                                         [0.8137, 0.812, 0.8144]   \n",
       "Snap Ensemble 2                                        [0.8365, 0.8363, 0.8367]   \n",
       "Snap Ensemble 3                                        [0.8529, 0.8491, 0.8534]   \n",
       "Snap Star (no warm-up) 1                               [0.8382, 0.8208, 0.8327]   \n",
       "Snap Star (no warm-up) 2                                [0.8331, 0.828, 0.8288]   \n",
       "Snap Star (no warm-up) 3                                [0.856, 0.8498, 0.8528]   \n",
       "Snap Star (new warm-up) 1                              [0.8462, 0.8598, 0.8604]   \n",
       "Snap Star (new warm-up) 2                              [0.8474, 0.8547, 0.8401]   \n",
       "Snap Star (new warm-up) 3                              [0.8673, 0.8677, 0.8767]   \n",
       "Snap Star (shot warm-up) 1                             [0.8766, 0.8453, 0.8386]   \n",
       "Snap Star (shot warm-up) 2                               [0.838, 0.8296, 0.844]   \n",
       "Snap Star (shot warm-up) 3                             [0.8544, 0.8493, 0.8521]   \n",
       "Big NN 1                                                               [0.8472]   \n",
       "Big NN 2                                                               [0.8284]   \n",
       "Big NN 3                                                               [0.8641]   \n",
       "\n",
       "                                                                     Train Loss  \\\n",
       "Big NN 0                      [0.35745231853961945, 0.40198987390518187, 0.4...   \n",
       "Ensemble 1                    [0.297635410490036, 0.3075022952079773, 0.3049...   \n",
       "Ensemble 2                    [0.27331409185409544, 0.2809423043346405, 0.26...   \n",
       "Ensemble 3                    [0.24825520288467406, 0.2674123253154755, 0.25...   \n",
       "Classic Star (no warm-up) 1   [0.3135467227077484, 0.3146791537570953, 0.296...   \n",
       "Classic Star (no warm-up) 2   [0.2569754233264923, 0.26269870041847226, 0.25...   \n",
       "Classic Star (no warm-up) 3   [0.23867048714160918, 0.24337536680221558, 0.2...   \n",
       "Classic Star (new warm-up) 1  [0.3053761303329468, 0.308457942943573, 0.2924...   \n",
       "Classic Star (new warm-up) 2  [0.259398263630867, 0.2600865338802338, 0.2583...   \n",
       "Classic Star (new warm-up) 3  [0.2408954661655426, 0.24411217144966124, 0.24...   \n",
       "Snapshot 0                    [0.6468640182304383, 0.41987566924095154, 0.30...   \n",
       "Snap Ensemble 1               [0.49334480310440065, 0.5022271536636352, 0.49...   \n",
       "Snap Ensemble 2               [0.3997778698539734, 0.40787676519393923, 0.39...   \n",
       "Snap Ensemble 3               [0.3325387121105194, 0.3359697277069092, 0.332...   \n",
       "Snap Star (no warm-up) 1      [0.4475654913520813, 0.48220178679466247, 0.49...   \n",
       "Snap Star (no warm-up) 2      [0.4394539219093323, 0.4453655867576599, 0.433...   \n",
       "Snap Star (no warm-up) 3      [0.3246989821195602, 0.329093617811203, 0.3229...   \n",
       "Snap Star (new warm-up) 1     [0.3360528066158295, 0.3347944870185852, 0.325...   \n",
       "Snap Star (new warm-up) 2     [0.3770606425380707, 0.34675657097816465, 0.39...   \n",
       "Snap Star (new warm-up) 3     [0.29372046738624574, 0.2988890048599243, 0.27...   \n",
       "Snap Star (shot warm-up) 1    [0.2766768713569641, 0.3772724753379822, 0.412...   \n",
       "Snap Star (shot warm-up) 2    [0.4140836661148071, 0.4394523384666443, 0.401...   \n",
       "Snap Star (shot warm-up) 3    [0.33427501532554627, 0.33958159380912784, 0.3...   \n",
       "Big NN 1                                                  [0.38053372703552246]   \n",
       "Big NN 2                                                    [0.458850551776886]   \n",
       "Big NN 3                                                  [0.34096638934135437]   \n",
       "\n",
       "                                                                 Train Accuracy  \\\n",
       "Big NN 0                      [0.88476, 0.86182, 0.83478, 0.86832, 0.85316, ...   \n",
       "Ensemble 1                                            [0.90502, 0.898, 0.89716]   \n",
       "Ensemble 2                                           [0.91764, 0.9113, 0.91328]   \n",
       "Ensemble 3                                          [0.92596, 0.91692, 0.91746]   \n",
       "Classic Star (no warm-up) 1                          [0.90172, 0.9019, 0.90802]   \n",
       "Classic Star (no warm-up) 2                          [0.92332, 0.92038, 0.9201]   \n",
       "Classic Star (no warm-up) 3                         [0.92846, 0.92708, 0.92818]   \n",
       "Classic Star (new warm-up) 1                         [0.90642, 0.9049, 0.90828]   \n",
       "Classic Star (new warm-up) 2                         [0.9229, 0.92116, 0.92064]   \n",
       "Classic Star (new warm-up) 3                        [0.92776, 0.92746, 0.92738]   \n",
       "Snapshot 0                    [0.77524, 0.85684, 0.89956, 0.92578, 0.77066, ...   \n",
       "Snap Ensemble 1                                     [0.83272, 0.83134, 0.83308]   \n",
       "Snap Ensemble 2                                      [0.86728, 0.8644, 0.86936]   \n",
       "Snap Ensemble 3                                      [0.8913, 0.89048, 0.89156]   \n",
       "Snap Star (no warm-up) 1                              [0.845, 0.83366, 0.83646]   \n",
       "Snap Star (no warm-up) 2                            [0.85376, 0.85372, 0.85782]   \n",
       "Snap Star (no warm-up) 3                             [0.8955, 0.89338, 0.89542]   \n",
       "Snap Star (new warm-up) 1                            [0.88186, 0.8836, 0.88568]   \n",
       "Snap Star (new warm-up) 2                           [0.86656, 0.87774, 0.86016]   \n",
       "Snap Star (new warm-up) 3                            [0.9014, 0.89728, 0.91402]   \n",
       "Snap Star (shot warm-up) 1                           [0.90558, 0.8666, 0.85998]   \n",
       "Snap Star (shot warm-up) 2                          [0.86056, 0.85448, 0.86434]   \n",
       "Snap Star (shot warm-up) 3                          [0.89284, 0.89122, 0.89288]   \n",
       "Big NN 1                                                              [0.87012]   \n",
       "Big NN 2                                                              [0.84428]   \n",
       "Big NN 3                                                               [0.8831]   \n",
       "\n",
       "                                                                           Time  \\\n",
       "Big NN 0                      [900.5, 782.8, 757.3, 758.1, 757.5, 758.5, 776...   \n",
       "Ensemble 1                                             [1683.3, 1740.5, 1557.6]   \n",
       "Ensemble 2                                             [2440.6, 2581.6, 2327.8]   \n",
       "Ensemble 3                                             [3198.7, 3398.3, 3085.9]   \n",
       "Classic Star (no warm-up) 1                            [1830.3, 1707.2, 1724.8]   \n",
       "Classic Star (no warm-up) 2                            [2788.0, 2844.2, 2663.1]   \n",
       "Classic Star (no warm-up) 3    [3718.5, 3858.3999999999996, 3652.1000000000004]   \n",
       "Classic Star (new warm-up) 1               [1796.2, 1705.0, 1725.6999999999998]   \n",
       "Classic Star (new warm-up) 2               [2717.8, 2797.6000000000004, 2669.2]   \n",
       "Classic Star (new warm-up) 3                           [3613.5, 3839.7, 3534.5]   \n",
       "Snapshot 0                    [812, 752, 753, 752, 749, 749, 749, 749, 749, ...   \n",
       "Snap Ensemble 1                                              [1564, 1498, 1498]   \n",
       "Snap Ensemble 2                                              [2317, 2247, 2249]   \n",
       "Snap Ensemble 3                                              [3069, 2996, 2998]   \n",
       "Snap Star (no warm-up) 1                               [1741.6, 1679.0, 1679.0]   \n",
       "Snap Star (no warm-up) 2                               [2667.7, 2602.4, 2601.7]   \n",
       "Snap Star (no warm-up) 3                               [3595.0, 3523.9, 3526.7]   \n",
       "Snap Star (new warm-up) 1                              [1708.5, 1644.3, 1644.3]   \n",
       "Snap Star (new warm-up) 2                              [2598.8, 2532.0, 2532.0]   \n",
       "Snap Star (new warm-up) 3                              [3492.3, 3419.4, 3422.0]   \n",
       "Snap Star (shot warm-up) 1                       [[1706.5], [1642.0], [1643.2]]   \n",
       "Snap Star (shot warm-up) 2                       [[2597.7], [2531.3], [2530.1]]   \n",
       "Snap Star (shot warm-up) 3                       [[3490.0], [3417.1], [3420.7]]   \n",
       "Big NN 1                                                               [1598.9]   \n",
       "Big NN 2                                                               [2308.1]   \n",
       "Big NN 3                                                               [3019.5]   \n",
       "\n",
       "                                d  \n",
       "Big NN 0                        0  \n",
       "Ensemble 1                      1  \n",
       "Ensemble 2                      2  \n",
       "Ensemble 3                      3  \n",
       "Classic Star (no warm-up) 1     1  \n",
       "Classic Star (no warm-up) 2     2  \n",
       "Classic Star (no warm-up) 3     3  \n",
       "Classic Star (new warm-up) 1    1  \n",
       "Classic Star (new warm-up) 2    2  \n",
       "Classic Star (new warm-up) 3    3  \n",
       "Snapshot 0                    NaN  \n",
       "Snap Ensemble 1               NaN  \n",
       "Snap Ensemble 2               NaN  \n",
       "Snap Ensemble 3               NaN  \n",
       "Snap Star (no warm-up) 1      NaN  \n",
       "Snap Star (no warm-up) 2      NaN  \n",
       "Snap Star (no warm-up) 3      NaN  \n",
       "Snap Star (new warm-up) 1     NaN  \n",
       "Snap Star (new warm-up) 2     NaN  \n",
       "Snap Star (new warm-up) 3     NaN  \n",
       "Snap Star (shot warm-up) 1    NaN  \n",
       "Snap Star (shot warm-up) 2    NaN  \n",
       "Snap Star (shot warm-up) 3    NaN  \n",
       "Big NN 1                      NaN  \n",
       "Big NN 2                      NaN  \n",
       "Big NN 3                      NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.rename(index={\n",
    "    'Snap Star (no warm-up)1': 'Snap Star (no warm-up) 1',\n",
    "    'Snap Star (no warm-up)2': 'Snap Star (no warm-up) 2',\n",
    "    'Snap Star (no warm-up)3': 'Snap Star (no warm-up) 3',\n",
    "    'Snapshot' : 'Snapshot 0'\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in results.index:\n",
    "    d = idx.rsplit(' ', 1)[1]\n",
    "    results.loc[idx, 'd'] = d \n",
    "results.sort_values(by='d', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snap Ensemble & 3 & $0.852 \\pm 0.002$ & 0.891 & 3021 \\\\\n",
      "Classic Star (no warm-up) & 3 & $0.903 \\pm 0.0$ & 0.928 & 3743 \\\\\n",
      "Snap Star (shot warm-up) & 3 & $0.852 \\pm 0.002$ & 0.892 & 3443 \\\\\n",
      "Snap Star (new warm-up) & 3 & $0.871 \\pm 0.004$ & 0.904 & 3445 \\\\\n",
      "Snap Star (no warm-up) & 3 & $0.853 \\pm 0.003$ & 0.895 & 3549 \\\\\n",
      "Classic Star (new warm-up) & 3 & $0.903 \\pm 0.001$ & 0.928 & 3663 \\\\\n",
      "Big NN & 3 & $0.864 \\pm 0.0$ & 0.883 & 3020 \\\\\n",
      "Ensemble & 3 & $0.895 \\pm 0.006$ & 0.92 & 3228 \\\\\n",
      "Classic Star (no warm-up) & 2 & $0.896 \\pm 0.002$ & 0.921 & 2765 \\\\\n",
      "Big NN & 2 & $0.828 \\pm 0.0$ & 0.844 & 2308 \\\\\n",
      "Snap Ensemble & 2 & $0.836 \\pm 0.0$ & 0.867 & 2271 \\\\\n",
      "Ensemble & 2 & $0.891 \\pm 0.004$ & 0.914 & 2450 \\\\\n",
      "Snap Star (shot warm-up) & 2 & $0.837 \\pm 0.006$ & 0.86 & 2553 \\\\\n",
      "Snap Star (no warm-up) & 2 & $0.83 \\pm 0.002$ & 0.855 & 2624 \\\\\n",
      "Classic Star (new warm-up) & 2 & $0.897 \\pm 0.001$ & 0.922 & 2728 \\\\\n",
      "Snap Star (new warm-up) & 2 & $0.847 \\pm 0.006$ & 0.868 & 2554 \\\\\n",
      "Classic Star (new warm-up) & 1 & $0.883 \\pm 0.001$ & 0.907 & 1742 \\\\\n",
      "Big NN & 1 & $0.847 \\pm 0.0$ & 0.87 & 1599 \\\\\n",
      "Snap Star (shot warm-up) & 1 & $0.854 \\pm 0.017$ & 0.877 & 1664 \\\\\n",
      "Classic Star (no warm-up) & 1 & $0.881 \\pm 0.001$ & 0.904 & 1754 \\\\\n",
      "Snap Star (new warm-up) & 1 & $0.855 \\pm 0.007$ & 0.884 & 1666 \\\\\n",
      "Snap Star (no warm-up) & 1 & $0.831 \\pm 0.007$ & 0.838 & 1700 \\\\\n",
      "Ensemble & 1 & $0.877 \\pm 0.006$ & 0.9 & 1660 \\\\\n",
      "Snap Ensemble & 1 & $0.813 \\pm 0.001$ & 0.832 & 1520 \\\\\n",
      "Snapshot & 0 & $0.831 \\pm 0.039$ & 0.864 & 755 \\\\\n",
      "Big NN & 0 & $0.839 \\pm 0.017$ & 0.854 & 796 \\\\\n"
     ]
    }
   ],
   "source": [
    "converted_list = []\n",
    "\n",
    "for idx in results.index:\n",
    "    name = idx.rsplit(' ', 1)[0]\n",
    "#     mean_mse = np.mean(results.loc[idx, 'Loss'])\n",
    "#     mean_mse = np.std(results.loc[idx, 'Loss'])\n",
    "    mean_acc = np.mean(results.loc[idx, 'Accuracy'])\n",
    "    std_acc = np.std(results.loc[idx, 'Accuracy'])\n",
    "    mean_tr_acc = np.mean(results.loc[idx, 'Train Accuracy'])\n",
    "    std_tr_acc = np.std(results.loc[idx, 'Train Accuracy'])\n",
    "    cur_time = np.mean(results.loc[idx, 'Time'])\n",
    "    d = int(results.loc[idx, 'd'])\n",
    "\n",
    "    \n",
    "    converted_list.append([name, d, str(np.round(mean_acc, 3)) + ' ± ' + str(np.round(std_acc, 3)),\n",
    "                          str(np.round(mean_tr_acc, 3)) + ' ± ' + str(np.round(std_tr_acc, 3)), round(cur_time)])\n",
    "    print('{} & {} & ${} \\pm {}$ & {} & {} \\\\\\\\'.format(\n",
    "          name, d, np.round(mean_acc, 3), np.round(std_acc, 3), \n",
    "          np.round(mean_tr_acc, 3), round(cur_time))\n",
    "    )\n",
    "\n",
    "converted_results = pd.DataFrame(converted_list, \n",
    "        columns=['model', 'd', 'Accuracy', 'Train Accuracy', 'TIME (sec)'])\n",
    "\n",
    "converted_results.to_csv(f'Cifar results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>d</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>TIME (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snap Ensemble</td>\n",
       "      <td>3</td>\n",
       "      <td>0.852 ± 0.002</td>\n",
       "      <td>0.891 ± 0.0</td>\n",
       "      <td>3021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classic Star (no warm-up)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903 ± 0.0</td>\n",
       "      <td>0.928 ± 0.001</td>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snap Star (shot warm-up)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.852 ± 0.002</td>\n",
       "      <td>0.892 ± 0.001</td>\n",
       "      <td>3443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snap Star (new warm-up)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871 ± 0.004</td>\n",
       "      <td>0.904 ± 0.007</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snap Star (no warm-up)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.853 ± 0.003</td>\n",
       "      <td>0.895 ± 0.001</td>\n",
       "      <td>3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Classic Star (new warm-up)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903 ± 0.001</td>\n",
       "      <td>0.928 ± 0.0</td>\n",
       "      <td>3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big NN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864 ± 0.0</td>\n",
       "      <td>0.883 ± 0.0</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>3</td>\n",
       "      <td>0.895 ± 0.006</td>\n",
       "      <td>0.92 ± 0.004</td>\n",
       "      <td>3228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Classic Star (no warm-up)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.896 ± 0.002</td>\n",
       "      <td>0.921 ± 0.001</td>\n",
       "      <td>2765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Big NN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.828 ± 0.0</td>\n",
       "      <td>0.844 ± 0.0</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Snap Ensemble</td>\n",
       "      <td>2</td>\n",
       "      <td>0.836 ± 0.0</td>\n",
       "      <td>0.867 ± 0.002</td>\n",
       "      <td>2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>2</td>\n",
       "      <td>0.891 ± 0.004</td>\n",
       "      <td>0.914 ± 0.003</td>\n",
       "      <td>2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Snap Star (shot warm-up)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.837 ± 0.006</td>\n",
       "      <td>0.86 ± 0.004</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Snap Star (no warm-up)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83 ± 0.002</td>\n",
       "      <td>0.855 ± 0.002</td>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Classic Star (new warm-up)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897 ± 0.001</td>\n",
       "      <td>0.922 ± 0.001</td>\n",
       "      <td>2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Snap Star (new warm-up)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847 ± 0.006</td>\n",
       "      <td>0.868 ± 0.007</td>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Classic Star (new warm-up)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883 ± 0.001</td>\n",
       "      <td>0.907 ± 0.001</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Big NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847 ± 0.0</td>\n",
       "      <td>0.87 ± 0.0</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Snap Star (shot warm-up)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854 ± 0.017</td>\n",
       "      <td>0.877 ± 0.02</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Classic Star (no warm-up)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881 ± 0.001</td>\n",
       "      <td>0.904 ± 0.003</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Snap Star (new warm-up)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855 ± 0.007</td>\n",
       "      <td>0.884 ± 0.002</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Snap Star (no warm-up)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831 ± 0.007</td>\n",
       "      <td>0.838 ± 0.005</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877 ± 0.006</td>\n",
       "      <td>0.9 ± 0.004</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Snap Ensemble</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813 ± 0.001</td>\n",
       "      <td>0.832 ± 0.001</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Snapshot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831 ± 0.039</td>\n",
       "      <td>0.864 ± 0.057</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Big NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.839 ± 0.017</td>\n",
       "      <td>0.854 ± 0.02</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  d       Accuracy Train Accuracy  TIME (sec)\n",
       "0                Snap Ensemble  3  0.852 ± 0.002    0.891 ± 0.0        3021\n",
       "1    Classic Star (no warm-up)  3    0.903 ± 0.0  0.928 ± 0.001        3743\n",
       "2     Snap Star (shot warm-up)  3  0.852 ± 0.002  0.892 ± 0.001        3443\n",
       "3      Snap Star (new warm-up)  3  0.871 ± 0.004  0.904 ± 0.007        3445\n",
       "4       Snap Star (no warm-up)  3  0.853 ± 0.003  0.895 ± 0.001        3549\n",
       "5   Classic Star (new warm-up)  3  0.903 ± 0.001    0.928 ± 0.0        3663\n",
       "6                       Big NN  3    0.864 ± 0.0    0.883 ± 0.0        3020\n",
       "7                     Ensemble  3  0.895 ± 0.006   0.92 ± 0.004        3228\n",
       "8    Classic Star (no warm-up)  2  0.896 ± 0.002  0.921 ± 0.001        2765\n",
       "9                       Big NN  2    0.828 ± 0.0    0.844 ± 0.0        2308\n",
       "10               Snap Ensemble  2    0.836 ± 0.0  0.867 ± 0.002        2271\n",
       "11                    Ensemble  2  0.891 ± 0.004  0.914 ± 0.003        2450\n",
       "12    Snap Star (shot warm-up)  2  0.837 ± 0.006   0.86 ± 0.004        2553\n",
       "13      Snap Star (no warm-up)  2   0.83 ± 0.002  0.855 ± 0.002        2624\n",
       "14  Classic Star (new warm-up)  2  0.897 ± 0.001  0.922 ± 0.001        2728\n",
       "15     Snap Star (new warm-up)  2  0.847 ± 0.006  0.868 ± 0.007        2554\n",
       "16  Classic Star (new warm-up)  1  0.883 ± 0.001  0.907 ± 0.001        1742\n",
       "17                      Big NN  1    0.847 ± 0.0     0.87 ± 0.0        1599\n",
       "18    Snap Star (shot warm-up)  1  0.854 ± 0.017   0.877 ± 0.02        1664\n",
       "19   Classic Star (no warm-up)  1  0.881 ± 0.001  0.904 ± 0.003        1754\n",
       "20     Snap Star (new warm-up)  1  0.855 ± 0.007  0.884 ± 0.002        1666\n",
       "21      Snap Star (no warm-up)  1  0.831 ± 0.007  0.838 ± 0.005        1700\n",
       "22                    Ensemble  1  0.877 ± 0.006    0.9 ± 0.004        1660\n",
       "23               Snap Ensemble  1  0.813 ± 0.001  0.832 ± 0.001        1520\n",
       "24                    Snapshot  0  0.831 ± 0.039  0.864 ± 0.057         755\n",
       "25                      Big NN  0  0.839 ± 0.017   0.854 ± 0.02         796"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cQrmQXCPCVLB"
   ],
   "name": "CifarStarAlgorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06ffe57a2c7840bfab7736754b1f00d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26b6a0c77af942eaaa746801fb3a566c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78abf27d5e4643c6ba2bf0e4570c9ae1",
       "IPY_MODEL_81da4bd986974a4583fc795fdca1afcc",
       "IPY_MODEL_e1c5ace95b7549f3a3a6be4af3335441"
      ],
      "layout": "IPY_MODEL_56eecab378904496a0f39a4a0575a886"
     }
    },
    "4d0650ade7a342b9967dbae6a1fcd815": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56eecab378904496a0f39a4a0575a886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b7c6cbb6381475a9888d83d7e402120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78abf27d5e4643c6ba2bf0e4570c9ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b7c6cbb6381475a9888d83d7e402120",
      "placeholder": "​",
      "style": "IPY_MODEL_06ffe57a2c7840bfab7736754b1f00d6",
      "value": ""
     }
    },
    "80e7e4a83ee14ac2b96ee970119b5278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81da4bd986974a4583fc795fdca1afcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d0650ade7a342b9967dbae6a1fcd815",
      "max": 169001437,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a73c3cbe46814ec487d56935bde31aef",
      "value": 169001437
     }
    },
    "985178ddc2204e32b763061205accb8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a73c3cbe46814ec487d56935bde31aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1c5ace95b7549f3a3a6be4af3335441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80e7e4a83ee14ac2b96ee970119b5278",
      "placeholder": "​",
      "style": "IPY_MODEL_985178ddc2204e32b763061205accb8e",
      "value": " 169001984/? [00:03&lt;00:00, 60048289.08it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
