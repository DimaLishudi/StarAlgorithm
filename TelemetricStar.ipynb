{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "TelemetricStar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1959BLzub7d4nU1lOLmrgcftVwoNUfTpO",
      "authorship_tag": "ABX9TyOFxVe5M3IXxInTDKNQkq9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimlish/StarAlgorithm/blob/main/TelemetricStar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC1buI2cG8Wl"
      },
      "source": [
        "import numpy as np \n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upOhheiuG-8I"
      },
      "source": [
        "class TelemetricDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_arr):\n",
        "        '''\n",
        "        args:\n",
        "            data_arr - dataset array\n",
        "        '''\n",
        "        self.y = torch.from_numpy(data_arr[:,4:5])\n",
        "        self.x = torch.from_numpy(np.delete(data_arr, [0, 4, 5], 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkAzhrCiUTYB"
      },
      "source": [
        "class BaseRegression(nn.Module):\n",
        "    '''\n",
        "    Base regression model\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #self.scale = nn.Parameter(torch.rand(19), dtype=torch.float32)\n",
        "        self.l1 = nn.Linear(19, 200)\n",
        "        self.l2 = nn.Linear(200, 500)\n",
        "        self.l3 = nn.Linear(500, 200)\n",
        "        self.l4 = nn.Linear(200, 20)\n",
        "        self.l5 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        x = self.l5(x)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDfBPBcJaucA"
      },
      "source": [
        "class ParallelRegression(nn.Module):\n",
        "    def __init__(self, BaseClass, *args):\n",
        "        '''\n",
        "        args:\n",
        "            BaseClass - class of models,\n",
        "                        which will be connected with weights self.l\n",
        "                        and trained in parallel\n",
        "            *args - arguments for BaseClass initialization \n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.m1 = BaseClass(*args)\n",
        "        self.m2 = BaseClass(*args)\n",
        "        self.l = nn.Linear(2, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l(torch.hstack((self.m1(x), self.m2(x))))\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjzmRUd4P7IQ"
      },
      "source": [
        "class AggregationRegression(nn.Module):\n",
        "    def __init__(self, trained_first, trained_second):\n",
        "        '''\n",
        "        args:\n",
        "            trained_first, trained_second - trained models, which will be aggregated to a bigger model\n",
        "        '''\n",
        "\n",
        "        super().__init__()\n",
        "        self.first = trained_first\n",
        "        self.second = trained_second\n",
        "        for p in self.first.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in self.second.parameters():\n",
        "            p.requires_grad = False\n",
        "        self.l = nn.Linear(2, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l(torch.hstack((self.first(x), self.second(x))))\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6HC6ziHUnnZ"
      },
      "source": [
        "class StarRegression(nn.Module):\n",
        "    def __init__(self, trained_model, BaseClass, *args):\n",
        "        '''\n",
        "        args:\n",
        "            trained_model - trained model (its parameters are freezed)\n",
        "            BaseClass - class of new model,\n",
        "                        which will be connected with trained_model\n",
        "                        and trained alongside weights of models (self.l)\n",
        "            *args - arguments for BaseClass initialization \n",
        "        '''\n",
        "\n",
        "        super().__init__()\n",
        "        self.trained = trained_model\n",
        "        for p in self.trained.parameters():\n",
        "            p.requires_grad = False\n",
        "        self.training = BaseClass(*args)\n",
        "        self.l = nn.Linear(2, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l(torch.hstack((self.trained(x), self.training(x))))\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpmj3RLMcODL"
      },
      "source": [
        "train_ratio = 0.8\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 25\n",
        "sigma = 1\n",
        "k = 6\n",
        "epoches = 150\n",
        "enable_triple = True # enables triple star model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_FwL5pDUgCN"
      },
      "source": [
        "data = np.genfromtxt(\"/content/drive/MyDrive/parkinsons_updrs.data\",\n",
        "                     delimiter=',', dtype=np.float32)\n",
        "train_len = round(train_ratio * len(data))\n",
        "train_set = TelemetricDataset(data[:train_len,])\n",
        "test_set = TelemetricDataset(data[train_len:,])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "crit = nn.MSELoss() # criterion"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2FpGzZkauj3"
      },
      "source": [
        "def train(model, trainloader, testloader, epoch_num, lr=0.0001, momentum=0, tol=1e-5, test_freq=2, plot_graph=False, name=None):\n",
        "    '''\n",
        "    args:\n",
        "    model - model to be trained\n",
        "    trainloader - dataloader of training dataset\n",
        "    testloader - dataloader of testing dataset\n",
        "    epoch_num - amount of epoches to train\n",
        "    lr - learning rate\n",
        "    momentum - momentum for SGD\n",
        "    tol - tolerance of loss, if difference is < tol, training is stopped\n",
        "    test_freq - every test_freq epoches loss on testing dataset is calculated\n",
        "    plot_graph - if true, then real time graph is shown, else loss is printed\n",
        "    name - name of model\n",
        "    \n",
        "    returns:\n",
        "      losses - list of avg loss on training dataset per every test_freq epoches\n",
        "    '''\n",
        "\n",
        "    start_time = time.time()\n",
        "    if name is not None:\n",
        "        print(\"\\n\" + '-' * 50)\n",
        "        print(name + \":\")\n",
        "    losses = []\n",
        "    optimizer = optim.SGD(model.parameters(), lr, momentum=momentum)\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        for x_train, y_train in trainloader:\n",
        " #           x_train = x_train.reshape((x_train.shape[0], ))\n",
        " #           y_train = y_train.reshape((y_train.shape[0], 1))\n",
        "            x_train = x_train.to(device)\n",
        "            y_train = y_train.to(device)\n",
        "            y_pred = model(x_train)\n",
        "      \n",
        "            loss = crit(y_pred, y_train)\n",
        "            print(\"x:\", x_train)\n",
        "            print(\"expected:\", y_train)\n",
        "            print(\"prediction\", y_pred)\n",
        "            print(\"loss:\", loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if epoch % test_freq == 0:\n",
        "            mean_val_loss = []\n",
        "            val_accuracy = []\n",
        "            with torch.no_grad():\n",
        "                for x_test, y_test in testloader:\n",
        "#                    x_test = x_test.reshape((x_test.shape[0], 1))\n",
        "#                    y_test = y_test.reshape((y_test.shape[0], 1))\n",
        "                    x_test = x_test.to(device)\n",
        "                    y_test = y_test.to(device)\n",
        "                    y_pred = model(x_test)\n",
        "                    print(\"test expected:\", y_train)\n",
        "                    print(\"test prediction\", y_pred)\n",
        "                    loss = crit(y_pred, y_test)\n",
        "                    print(\"test loss:\", loss)\n",
        "                    mean_val_loss.append(loss.numpy())\n",
        "\n",
        "            losses.append(np.mean(mean_val_loss))\n",
        "\n",
        "\n",
        "            if plot_graph:\n",
        "                clear_output(True)\n",
        "                (x, y) = test_set.getall()\n",
        "                x = x.reshape((test_size, 1))\n",
        "                plt.scatter(x, y, c='black', marker='.', label='true')\n",
        "                y = model(x)\n",
        "                plt.scatter(x, y.detach().numpy(), marker='.', c='red', label=name)\n",
        "                plt.legend(loc='upper left')\n",
        "                plt.title('Epoch: {epoch}, loss: {loss}'.format(\n",
        "                      epoch=epoch, loss=np.mean(mean_val_loss)))\n",
        "                plt.show()\n",
        "            else:\n",
        "                print('Epoch: {epoch}, loss: {loss}'.format(\n",
        "                      epoch=epoch, loss=np.mean(mean_val_loss)))\n",
        "\n",
        "            if losses[-1] != losses[-1]:\n",
        "                raise ValueError(\"NaN loss\")\n",
        "            if len(losses) > 2 and abs(losses[-1] - losses[-2]) < tol:\n",
        "                while len(losses) != epoch_num // test_freq:\n",
        "                    losses.append(losses[-1]) # fill the list before returning\n",
        "                break\n",
        "\n",
        "    print(\"Training time:\", round(time.time() - start_time), \"seconds\")\n",
        "    return losses, time.time() - start_time"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "juditG5HsunV",
        "outputId": "05da8d70-1fcd-4a0b-9add-9784add2e7c9"
      },
      "source": [
        "base = BaseRegression()\n",
        "base.to(device)\n",
        "\n",
        "base_losses, base_time = train(base, train_loader, test_loader, epoches, name=\"base\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "        [24.6990],\n",
            "        [22.8560],\n",
            "        [21.9310],\n",
            "        [21.0090],\n",
            "        [20.0910],\n",
            "        [19.1680],\n",
            "        [18.2460],\n",
            "        [27.6820],\n",
            "        [28.0390]])\n",
            "prediction tensor([[23.0561],\n",
            "        [29.6691],\n",
            "        [29.8601],\n",
            "        [29.6131],\n",
            "        [29.7116],\n",
            "        [29.8279],\n",
            "        [29.7012],\n",
            "        [29.4177],\n",
            "        [28.1823],\n",
            "        [27.7333],\n",
            "        [27.2762],\n",
            "        [26.0728],\n",
            "        [25.4719],\n",
            "        [25.1515],\n",
            "        [24.9692],\n",
            "        [24.8305],\n",
            "        [24.3931],\n",
            "        [23.2738],\n",
            "        [23.4406],\n",
            "        [23.2711],\n",
            "        [23.0765],\n",
            "        [22.5495],\n",
            "        [23.0147],\n",
            "        [29.7233],\n",
            "        [30.0792]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(6.5524, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[7.5000e+01, 0.0000e+00, 2.7379e+01, 9.1800e-03, 6.9910e-05, 3.4300e-03,\n",
            "         4.7000e-03, 1.0290e-02, 5.4410e-02, 4.8600e-01, 1.8710e-02, 3.2890e-02,\n",
            "         7.8610e-02, 5.6140e-02, 2.0265e-02, 1.8244e+01, 5.8627e-01, 7.8767e-01,\n",
            "         3.1665e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 3.4358e+01, 7.9400e-03, 5.9590e-05, 2.9400e-03,\n",
            "         3.8800e-03, 8.8300e-03, 4.9000e-02, 4.2300e-01, 2.1060e-02, 3.0150e-02,\n",
            "         5.1830e-02, 6.3180e-02, 2.2564e-02, 1.7835e+01, 6.2013e-01, 7.6870e-01,\n",
            "         2.9995e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 4.1358e+01, 7.6900e-03, 6.0180e-05, 2.2500e-03,\n",
            "         3.6500e-03, 6.7600e-03, 2.2170e-02, 1.9200e-01, 1.1010e-02, 1.3600e-02,\n",
            "         2.3580e-02, 3.3020e-02, 1.2376e-02, 1.9953e+01, 5.4719e-01, 7.7907e-01,\n",
            "         2.7185e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 4.8395e+01, 6.9000e-03, 5.0640e-05, 2.3600e-03,\n",
            "         3.7500e-03, 7.0700e-03, 4.4310e-02, 3.8000e-01, 1.4510e-02, 2.6050e-02,\n",
            "         6.3070e-02, 4.3540e-02, 1.5195e-02, 2.1142e+01, 5.8803e-01, 7.5667e-01,\n",
            "         3.0573e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 5.5346e+01, 8.1600e-03, 6.2250e-05, 2.8100e-03,\n",
            "         4.0700e-03, 8.4300e-03, 3.3730e-02, 3.1200e-01, 1.2900e-02, 2.0250e-02,\n",
            "         4.1190e-02, 3.8710e-02, 1.6505e-02, 2.0224e+01, 5.0215e-01, 7.6085e-01,\n",
            "         3.2098e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 7.6350e+01, 6.8800e-03, 5.2550e-05, 2.3500e-03,\n",
            "         3.4200e-03, 7.0400e-03, 3.8710e-02, 3.5900e-01, 1.5830e-02, 2.3620e-02,\n",
            "         4.6290e-02, 4.7480e-02, 2.0410e-02, 2.0624e+01, 5.9788e-01, 7.6424e-01,\n",
            "         2.7202e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 8.8415e+01, 5.0400e-03, 3.9950e-05, 1.9000e-03,\n",
            "         2.8900e-03, 5.7000e-03, 3.3510e-02, 2.9400e-01, 1.4960e-02, 2.2780e-02,\n",
            "         3.7650e-02, 4.4880e-02, 1.0959e-02, 2.0317e+01, 5.3102e-01, 7.6632e-01,\n",
            "         2.5030e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 9.7358e+01, 7.1300e-03, 6.4720e-05, 2.4300e-03,\n",
            "         3.2400e-03, 7.3000e-03, 4.5100e-02, 4.3200e-01, 1.5840e-02, 2.4550e-02,\n",
            "         5.4850e-02, 4.7520e-02, 2.4953e-02, 1.9032e+01, 5.8541e-01, 7.4337e-01,\n",
            "         2.8941e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.1835e+02, 8.3500e-03, 6.5020e-05, 3.1300e-03,\n",
            "         4.5000e-03, 9.4000e-03, 2.8860e-02, 3.2600e-01, 1.0850e-02, 1.7660e-02,\n",
            "         3.1190e-02, 3.2560e-02, 1.4978e-02, 2.2003e+01, 4.7172e-01, 7.8131e-01,\n",
            "         3.0531e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.2534e+02, 8.8500e-03, 6.9660e-05, 3.4400e-03,\n",
            "         4.6700e-03, 1.0310e-02, 3.4410e-02, 3.2800e-01, 1.6380e-02, 2.1390e-02,\n",
            "         3.5700e-02, 4.9150e-02, 2.1616e-02, 1.8976e+01, 5.0175e-01, 7.7936e-01,\n",
            "         3.2182e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.3235e+02, 5.8100e-03, 5.4440e-05, 2.8200e-03,\n",
            "         3.4300e-03, 8.4500e-03, 3.3810e-02, 3.0200e-01, 1.4430e-02, 2.1300e-02,\n",
            "         3.7150e-02, 4.3280e-02, 8.9560e-03, 2.2686e+01, 4.5677e-01, 7.5796e-01,\n",
            "         2.7214e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.3935e+02, 8.9900e-03, 7.3860e-05, 2.7800e-03,\n",
            "         4.0500e-03, 8.3300e-03, 3.2040e-02, 2.8500e-01, 1.0650e-02, 1.9010e-02,\n",
            "         4.4800e-02, 3.1940e-02, 2.7487e-02, 1.9942e+01, 5.0202e-01, 7.7247e-01,\n",
            "         3.2047e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.4635e+02, 1.0210e-02, 8.1950e-05, 3.1900e-03,\n",
            "         4.4900e-03, 9.5800e-03, 4.0530e-02, 4.3600e-01, 1.7200e-02, 2.1270e-02,\n",
            "         4.0040e-02, 5.1610e-02, 1.7616e-02, 2.0131e+01, 5.2951e-01, 7.8544e-01,\n",
            "         3.2048e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.5337e+02, 1.0060e-02, 7.8130e-05, 3.2300e-03,\n",
            "         4.9800e-03, 9.7000e-03, 3.6360e-02, 3.1800e-01, 1.4280e-02, 2.0610e-02,\n",
            "         4.1330e-02, 4.2830e-02, 1.9439e-02, 1.9658e+01, 5.4032e-01, 7.8707e-01,\n",
            "         3.5475e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.6734e+02, 8.9800e-03, 6.9800e-05, 2.9900e-03,\n",
            "         4.3900e-03, 8.9600e-03, 3.8400e-02, 3.3800e-01, 1.2840e-02, 2.3480e-02,\n",
            "         5.3650e-02, 3.8520e-02, 2.5541e-02, 1.8434e+01, 5.4063e-01, 7.5737e-01,\n",
            "         3.0833e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.7436e+02, 7.6800e-03, 5.4180e-05, 2.8900e-03,\n",
            "         3.8200e-03, 8.6800e-03, 2.4900e-02, 2.8600e-01, 9.7300e-03, 1.4570e-02,\n",
            "         3.0700e-02, 2.9180e-02, 1.4346e-02, 2.2130e+01, 5.0087e-01, 7.6703e-01,\n",
            "         3.5306e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.8135e+02, 7.0100e-03, 5.4850e-05, 2.7000e-03,\n",
            "         3.7100e-03, 8.1000e-03, 2.8690e-02, 2.6900e-01, 1.1960e-02, 1.5990e-02,\n",
            "         2.7680e-02, 3.5890e-02, 1.7749e-02, 2.0992e+01, 5.0528e-01, 7.6762e-01,\n",
            "         2.4917e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.8831e+02, 6.2100e-03, 4.7970e-05, 2.0800e-03,\n",
            "         2.9300e-03, 6.2400e-03, 2.3700e-02, 2.1900e-01, 8.9300e-03, 1.3340e-02,\n",
            "         2.5940e-02, 2.6800e-02, 7.6700e-03, 2.4589e+01, 5.1741e-01, 7.6749e-01,\n",
            "         2.5789e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 1.9531e+02, 6.8200e-03, 5.4990e-05, 3.0200e-03,\n",
            "         3.9100e-03, 9.0700e-03, 6.7760e-02, 6.0600e-01, 3.1880e-02, 4.2100e-02,\n",
            "         7.3980e-02, 9.5630e-02, 5.1214e-02, 1.3444e+01, 6.4037e-01, 7.1598e-01,\n",
            "         3.1382e-01],\n",
            "        [7.5000e+01, 0.0000e+00, 2.0231e+02, 7.8200e-03, 5.7700e-05, 2.5800e-03,\n",
            "         3.7900e-03, 7.7400e-03, 2.5230e-02, 2.3600e-01, 9.9500e-03, 1.3700e-02,\n",
            "         2.5710e-02, 2.9850e-02, 1.5885e-02, 2.2141e+01, 5.1595e-01, 7.7365e-01,\n",
            "         3.0648e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1477e+01, 3.6400e-03, 1.9150e-05, 1.9100e-03,\n",
            "         1.8200e-03, 5.7400e-03, 1.8930e-02, 1.6400e-01, 8.2400e-03, 9.5200e-03,\n",
            "         1.4010e-02, 2.4720e-02, 9.4980e-03, 2.3986e+01, 5.9051e-01, 6.3861e-01,\n",
            "         1.3868e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7447e+01, 2.1700e-03, 1.1460e-05, 9.0000e-04,\n",
            "         1.0600e-03, 2.7000e-03, 1.1540e-02, 9.9000e-02, 5.4000e-03, 6.0300e-03,\n",
            "         9.2100e-03, 1.6190e-02, 7.6770e-03, 2.5965e+01, 5.3341e-01, 6.7200e-01,\n",
            "         1.2272e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 2.4419e+01, 2.4400e-03, 1.1310e-05, 1.1500e-03,\n",
            "         1.2200e-03, 3.4500e-03, 1.5240e-02, 1.2900e-01, 7.7800e-03, 8.7500e-03,\n",
            "         1.0630e-02, 2.3330e-02, 5.6830e-03, 2.4675e+01, 5.5164e-01, 5.8716e-01,\n",
            "         1.0054e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.1404e+01, 4.3200e-03, 2.4350e-05, 1.9300e-03,\n",
            "         2.0800e-03, 5.7800e-03, 2.8370e-02, 2.4200e-01, 1.4390e-02, 1.5760e-02,\n",
            "         2.0740e-02, 4.3170e-02, 1.7404e-02, 2.0087e+01, 6.1435e-01, 6.0112e-01,\n",
            "         1.5761e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.8402e+01, 3.7100e-03, 2.0650e-05, 1.5200e-03,\n",
            "         1.8600e-03, 4.5500e-03, 3.5880e-02, 2.9500e-01, 1.7610e-02, 2.0950e-02,\n",
            "         2.7820e-02, 5.2830e-02, 1.6418e-02, 2.0729e+01, 5.9728e-01, 6.1428e-01,\n",
            "         1.8145e-01]])\n",
            "expected: tensor([[28.3970],\n",
            "        [28.7530],\n",
            "        [29.1100],\n",
            "        [29.4690],\n",
            "        [29.8240],\n",
            "        [30.8950],\n",
            "        [31.5110],\n",
            "        [31.9670],\n",
            "        [29.3170],\n",
            "        [28.3940],\n",
            "        [27.4700],\n",
            "        [26.5470],\n",
            "        [25.6250],\n",
            "        [24.6990],\n",
            "        [22.8560],\n",
            "        [21.9310],\n",
            "        [21.0090],\n",
            "        [20.0910],\n",
            "        [19.1680],\n",
            "        [18.2450],\n",
            "        [16.4870],\n",
            "        [15.6990],\n",
            "        [14.7800],\n",
            "        [13.8590],\n",
            "        [12.9360]])\n",
            "prediction tensor([[29.3977],\n",
            "        [29.2648],\n",
            "        [29.4559],\n",
            "        [29.4981],\n",
            "        [29.1669],\n",
            "        [28.2985],\n",
            "        [27.5655],\n",
            "        [26.7565],\n",
            "        [25.8394],\n",
            "        [24.8857],\n",
            "        [25.0645],\n",
            "        [24.1790],\n",
            "        [23.8466],\n",
            "        [23.4227],\n",
            "        [22.5789],\n",
            "        [22.7631],\n",
            "        [22.3283],\n",
            "        [22.5606],\n",
            "        [21.4786],\n",
            "        [22.2226],\n",
            "        [16.2698],\n",
            "        [16.5120],\n",
            "        [16.2881],\n",
            "        [15.4692],\n",
            "        [15.3524]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(5.3217, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[3.6000e+01, 1.0000e+00, 4.5412e+01, 3.3300e-03, 1.8810e-05, 1.2600e-03,\n",
            "         1.5700e-03, 3.7700e-03, 2.4460e-02, 2.2200e-01, 1.0980e-02, 1.2100e-02,\n",
            "         1.8410e-02, 3.2950e-02, 9.2570e-03, 2.2960e+01, 5.8498e-01, 6.1931e-01,\n",
            "         1.6426e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.2419e+01, 3.0300e-03, 1.6360e-05, 1.3000e-03,\n",
            "         1.4600e-03, 3.9000e-03, 1.9610e-02, 1.7800e-01, 9.6700e-03, 1.0960e-02,\n",
            "         1.3750e-02, 2.9000e-02, 9.9790e-03, 2.4416e+01, 4.8418e-01, 6.3431e-01,\n",
            "         1.4600e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.9388e+01, 3.6500e-03, 2.0720e-05, 1.6300e-03,\n",
            "         1.8400e-03, 4.8800e-03, 2.0970e-02, 1.8400e-01, 9.3900e-03, 1.1740e-02,\n",
            "         1.6570e-02, 2.8160e-02, 9.6520e-03, 2.2530e+01, 5.4225e-01, 5.9836e-01,\n",
            "         1.9522e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 9.1463e+01, 4.0400e-03, 2.2920e-05, 2.0400e-03,\n",
            "         2.3500e-03, 6.1200e-03, 3.9470e-02, 3.5100e-01, 2.1030e-02, 2.2400e-02,\n",
            "         2.5610e-02, 6.3080e-02, 1.3349e-02, 2.2929e+01, 4.9270e-01, 6.8552e-01,\n",
            "         1.9056e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0168e+02, 3.7700e-03, 2.1480e-05, 1.7200e-03,\n",
            "         2.0000e-03, 5.1700e-03, 2.0640e-02, 1.7500e-01, 9.6900e-03, 1.1100e-02,\n",
            "         1.5720e-02, 2.9070e-02, 9.8320e-03, 2.2970e+01, 5.5471e-01, 6.6728e-01,\n",
            "         1.8031e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0850e+02, 5.0700e-03, 2.8120e-05, 2.3200e-03,\n",
            "         2.5400e-03, 6.9500e-03, 2.8040e-02, 2.3900e-01, 1.3810e-02, 1.6770e-02,\n",
            "         2.3860e-02, 4.1420e-02, 3.1746e-02, 1.7496e+01, 6.3257e-01, 6.5469e-01,\n",
            "         2.5847e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1561e+02, 3.4500e-03, 1.8860e-05, 1.7600e-03,\n",
            "         1.7900e-03, 5.2800e-03, 2.5550e-02, 2.2900e-01, 1.3230e-02, 1.4780e-02,\n",
            "         1.8390e-02, 3.9690e-02, 1.6808e-02, 2.6528e+01, 5.1573e-01, 6.3834e-01,\n",
            "         1.1237e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.2250e+02, 4.7100e-03, 2.6670e-05, 2.4600e-03,\n",
            "         2.4400e-03, 7.3800e-03, 3.0840e-02, 3.0100e-01, 1.4890e-02, 1.5830e-02,\n",
            "         2.1710e-02, 4.4660e-02, 1.8564e-02, 2.2328e+01, 5.1095e-01, 6.6443e-01,\n",
            "         1.4735e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.3644e+02, 3.0100e-03, 1.7130e-05, 1.4600e-03,\n",
            "         1.5600e-03, 4.3900e-03, 3.2750e-02, 2.6400e-01, 1.6260e-02, 1.8920e-02,\n",
            "         2.5620e-02, 4.8770e-02, 1.3375e-02, 2.5079e+01, 6.2622e-01, 6.5961e-01,\n",
            "         1.3369e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.4378e+02, 3.4700e-03, 1.9550e-05, 1.7000e-03,\n",
            "         1.9100e-03, 5.0900e-03, 2.0180e-02, 1.7100e-01, 1.0050e-02, 1.1990e-02,\n",
            "         1.5610e-02, 3.0140e-02, 1.2623e-02, 2.2995e+01, 5.6028e-01, 6.6012e-01,\n",
            "         1.3244e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.6455e+02, 2.8400e-03, 1.6190e-05, 1.3200e-03,\n",
            "         1.4800e-03, 3.9700e-03, 2.9100e-02, 2.6200e-01, 1.3740e-02, 1.5650e-02,\n",
            "         2.0690e-02, 4.1220e-02, 9.2070e-03, 2.2791e+01, 6.3196e-01, 6.2013e-01,\n",
            "         1.2177e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7854e+02, 3.7400e-03, 2.0730e-05, 1.7600e-03,\n",
            "         1.7900e-03, 5.2900e-03, 2.0760e-02, 1.9300e-01, 1.0960e-02, 1.2450e-02,\n",
            "         1.4750e-02, 3.2870e-02, 1.7570e-02, 2.3951e+01, 5.5126e-01, 6.3757e-01,\n",
            "         1.7098e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1477e+01, 3.3700e-03, 1.8090e-05, 1.6600e-03,\n",
            "         1.8900e-03, 4.9900e-03, 1.8970e-02, 1.7100e-01, 1.0360e-02, 1.1030e-02,\n",
            "         1.3210e-02, 3.1080e-02, 1.5854e-02, 2.4936e+01, 3.6070e-01, 6.4474e-01,\n",
            "         1.6345e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7448e+01, 4.4200e-03, 2.4310e-05, 1.8700e-03,\n",
            "         1.9300e-03, 5.6200e-03, 1.2760e-02, 1.3200e-01, 6.0100e-03, 6.8400e-03,\n",
            "         1.1240e-02, 1.8030e-02, 2.1871e-02, 2.3460e+01, 4.2075e-01, 6.8729e-01,\n",
            "         1.9422e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 2.4419e+01, 4.7100e-03, 2.1740e-05, 2.2600e-03,\n",
            "         2.0800e-03, 6.7800e-03, 2.5520e-02, 2.3400e-01, 1.4020e-02, 1.4070e-02,\n",
            "         1.7710e-02, 4.2050e-02, 1.7506e-02, 2.3158e+01, 4.4031e-01, 5.8357e-01,\n",
            "         1.6577e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.1405e+01, 3.1500e-03, 1.7730e-05, 1.2800e-03,\n",
            "         1.3100e-03, 3.8400e-03, 1.5710e-02, 1.5000e-01, 7.1800e-03, 8.7400e-03,\n",
            "         1.2570e-02, 2.1550e-02, 1.5632e-02, 2.5773e+01, 4.8176e-01, 5.8419e-01,\n",
            "         1.7362e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.8403e+01, 3.0800e-03, 1.6910e-05, 1.3400e-03,\n",
            "         1.5200e-03, 4.0200e-03, 2.1160e-02, 1.9000e-01, 1.1380e-02, 1.2740e-02,\n",
            "         1.5780e-02, 3.4150e-02, 1.0075e-02, 2.3442e+01, 4.8174e-01, 5.9095e-01,\n",
            "         1.4585e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 4.5413e+01, 5.7100e-03, 3.3190e-05, 2.9000e-03,\n",
            "         2.9800e-03, 8.7100e-03, 2.8620e-02, 2.9100e-01, 1.4490e-02, 1.7270e-02,\n",
            "         2.2110e-02, 4.3460e-02, 2.3619e-02, 2.1609e+01, 4.9871e-01, 6.2988e-01,\n",
            "         2.5510e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.2419e+01, 3.0100e-03, 1.6230e-05, 1.3000e-03,\n",
            "         1.4200e-03, 3.8900e-03, 1.6150e-02, 1.3800e-01, 8.4800e-03, 9.6900e-03,\n",
            "         1.1740e-02, 2.5450e-02, 6.1820e-03, 2.6482e+01, 4.5821e-01, 6.1600e-01,\n",
            "         1.1729e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.9388e+01, 3.4900e-03, 1.9370e-05, 1.6400e-03,\n",
            "         2.0400e-03, 4.9300e-03, 2.2070e-02, 1.9400e-01, 1.1340e-02, 1.3910e-02,\n",
            "         1.7140e-02, 3.4030e-02, 6.5470e-03, 2.3360e+01, 4.0287e-01, 6.5331e-01,\n",
            "         1.8896e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 9.1463e+01, 3.5300e-03, 2.0330e-05, 1.7500e-03,\n",
            "         1.7800e-03, 5.2500e-03, 2.1180e-02, 1.8100e-01, 1.0490e-02, 1.1690e-02,\n",
            "         1.4950e-02, 3.1460e-02, 1.7078e-02, 2.5425e+01, 5.5285e-01, 6.7898e-01,\n",
            "         1.7136e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0168e+02, 4.3600e-03, 2.5210e-05, 2.0300e-03,\n",
            "         1.8600e-03, 6.0800e-03, 1.7960e-02, 1.5300e-01, 8.9800e-03, 1.0110e-02,\n",
            "         1.3550e-02, 2.6940e-02, 1.6181e-02, 2.3780e+01, 4.9848e-01, 6.8093e-01,\n",
            "         2.2223e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0850e+02, 3.6600e-03, 2.0080e-05, 1.7100e-03,\n",
            "         2.0700e-03, 5.1200e-03, 2.1930e-02, 2.0500e-01, 1.0970e-02, 1.3480e-02,\n",
            "         1.8850e-02, 3.2920e-02, 1.4086e-02, 2.2533e+01, 4.3944e-01, 6.4318e-01,\n",
            "         2.0528e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1561e+02, 5.1300e-03, 2.8530e-05, 2.4900e-03,\n",
            "         2.9000e-03, 7.4600e-03, 1.6910e-02, 1.7000e-01, 8.1200e-03, 9.5000e-03,\n",
            "         1.2460e-02, 2.4350e-02, 1.7722e-02, 2.2415e+01, 4.9685e-01, 6.6986e-01,\n",
            "         1.7939e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.2250e+02, 3.5200e-03, 2.0150e-05, 1.6800e-03,\n",
            "         1.6000e-03, 5.0400e-03, 1.8700e-02, 1.7200e-01, 8.7600e-03, 1.0120e-02,\n",
            "         1.4600e-02, 2.6270e-02, 8.1170e-03, 2.4405e+01, 4.4096e-01, 6.4093e-01,\n",
            "         1.2824e-01]])\n",
            "expected: tensor([[12.0120],\n",
            "        [11.0880],\n",
            "        [10.1690],\n",
            "        [ 6.0102],\n",
            "        [ 6.2347],\n",
            "        [ 6.3845],\n",
            "        [ 6.5408],\n",
            "        [ 6.6924],\n",
            "        [ 6.9987],\n",
            "        [ 7.1599],\n",
            "        [ 7.6164],\n",
            "        [ 7.9240],\n",
            "        [16.4870],\n",
            "        [15.6990],\n",
            "        [14.7800],\n",
            "        [13.8590],\n",
            "        [12.9360],\n",
            "        [12.0110],\n",
            "        [11.0880],\n",
            "        [10.1690],\n",
            "        [ 6.0102],\n",
            "        [ 6.2347],\n",
            "        [ 6.3845],\n",
            "        [ 6.5408],\n",
            "        [ 6.6924]])\n",
            "prediction tensor([[15.8142],\n",
            "        [15.6354],\n",
            "        [14.9151],\n",
            "        [13.1733],\n",
            "        [12.8511],\n",
            "        [11.9912],\n",
            "        [13.2915],\n",
            "        [12.8076],\n",
            "        [13.4597],\n",
            "        [13.4571],\n",
            "        [14.1321],\n",
            "        [14.7049],\n",
            "        [16.7692],\n",
            "        [16.5817],\n",
            "        [16.4929],\n",
            "        [16.7219],\n",
            "        [16.2104],\n",
            "        [15.5885],\n",
            "        [15.9702],\n",
            "        [15.0574],\n",
            "        [13.6103],\n",
            "        [12.9842],\n",
            "        [12.6902],\n",
            "        [12.7127],\n",
            "        [13.0657]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(29.6807, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[3.6000e+01, 1.0000e+00, 1.3644e+02, 4.0500e-03, 2.3050e-05, 2.0800e-03,\n",
            "         2.1000e-03, 6.2300e-03, 1.7960e-02, 1.5500e-01, 9.7100e-03, 1.0460e-02,\n",
            "         1.2080e-02, 2.9140e-02, 9.1660e-03, 2.3847e+01, 4.8602e-01, 6.7357e-01,\n",
            "         1.2468e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.4378e+02, 4.2700e-03, 2.3620e-05, 1.9900e-03,\n",
            "         2.6300e-03, 5.9600e-03, 2.1080e-02, 2.0800e-01, 9.3500e-03, 1.1280e-02,\n",
            "         1.6600e-02, 2.8060e-02, 1.3491e-02, 2.3979e+01, 5.3244e-01, 6.3642e-01,\n",
            "         2.3252e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.6455e+02, 3.1800e-03, 1.7740e-05, 1.4700e-03,\n",
            "         1.6700e-03, 4.4000e-03, 2.6700e-02, 2.4600e-01, 1.4430e-02, 1.5290e-02,\n",
            "         1.9220e-02, 4.3290e-02, 1.0211e-02, 2.3677e+01, 5.6660e-01, 6.6380e-01,\n",
            "         1.1127e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7854e+02, 4.7600e-03, 2.6660e-05, 2.6900e-03,\n",
            "         2.5000e-03, 8.0700e-03, 1.8250e-02, 1.5600e-01, 1.0010e-02, 1.0760e-02,\n",
            "         1.2930e-02, 3.0030e-02, 1.5456e-02, 2.0133e+01, 5.0765e-01, 6.3649e-01,\n",
            "         1.6981e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1478e+01, 4.0800e-03, 2.2340e-05, 1.9100e-03,\n",
            "         1.7400e-03, 5.7200e-03, 1.9620e-02, 1.8700e-01, 1.0050e-02, 1.1620e-02,\n",
            "         1.5470e-02, 3.0140e-02, 1.8765e-02, 2.3121e+01, 3.8461e-01, 6.3487e-01,\n",
            "         1.5441e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7448e+01, 2.8100e-03, 1.5430e-05, 1.2600e-03,\n",
            "         1.5000e-03, 3.7800e-03, 1.3980e-02, 1.2500e-01, 6.6700e-03, 7.8300e-03,\n",
            "         1.0650e-02, 2.0010e-02, 9.1340e-03, 2.5872e+01, 4.2987e-01, 6.7871e-01,\n",
            "         1.3819e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 2.4419e+01, 4.0300e-03, 1.8190e-05, 1.9200e-03,\n",
            "         1.5000e-03, 5.7600e-03, 1.7900e-02, 1.6600e-01, 9.0300e-03, 9.8300e-03,\n",
            "         1.3100e-02, 2.7080e-02, 1.6697e-02, 2.4519e+01, 4.3249e-01, 5.7333e-01,\n",
            "         1.3740e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.1405e+01, 3.4900e-03, 1.9390e-05, 1.6400e-03,\n",
            "         1.6700e-03, 4.9300e-03, 2.0360e-02, 1.8100e-01, 9.7800e-03, 1.1030e-02,\n",
            "         1.7010e-02, 2.9350e-02, 1.2442e-02, 2.3160e+01, 4.8776e-01, 5.8242e-01,\n",
            "         1.6120e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.8403e+01, 5.1600e-03, 2.8300e-05, 2.4000e-03,\n",
            "         2.2100e-03, 7.2000e-03, 2.5840e-02, 2.4900e-01, 1.3370e-02, 1.5220e-02,\n",
            "         1.8170e-02, 4.0120e-02, 3.2477e-02, 2.3958e+01, 4.4331e-01, 6.1254e-01,\n",
            "         2.1051e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 4.5414e+01, 3.9100e-03, 2.3140e-05, 1.7500e-03,\n",
            "         2.1100e-03, 5.2500e-03, 3.0260e-02, 3.0200e-01, 1.4660e-02, 1.6430e-02,\n",
            "         2.3750e-02, 4.3970e-02, 2.1977e-02, 2.2161e+01, 5.5362e-01, 6.0953e-01,\n",
            "         2.1279e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.2419e+01, 3.8700e-03, 2.1430e-05, 2.0100e-03,\n",
            "         2.0700e-03, 6.0200e-03, 1.4720e-02, 1.2800e-01, 7.9900e-03, 9.1400e-03,\n",
            "         1.1110e-02, 2.3960e-02, 8.7680e-03, 2.2303e+01, 3.7783e-01, 5.9069e-01,\n",
            "         1.7140e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.9389e+01, 5.6800e-03, 3.1310e-05, 2.6400e-03,\n",
            "         3.5500e-03, 7.9100e-03, 2.6070e-02, 2.4300e-01, 1.4230e-02, 1.6070e-02,\n",
            "         1.8420e-02, 4.2690e-02, 2.8615e-02, 2.0451e+01, 4.7934e-01, 6.7980e-01,\n",
            "         2.5453e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 9.1464e+01, 5.1500e-03, 2.9520e-05, 2.2500e-03,\n",
            "         2.7300e-03, 6.7600e-03, 2.4710e-02, 2.0700e-01, 1.2940e-02, 1.4600e-02,\n",
            "         1.8380e-02, 3.8820e-02, 2.0379e-02, 2.0735e+01, 6.3957e-01, 6.9837e-01,\n",
            "         2.5856e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0168e+02, 4.5100e-03, 2.5730e-05, 2.2000e-03,\n",
            "         2.2000e-03, 6.6000e-03, 1.5020e-02, 1.3100e-01, 6.8600e-03, 7.9700e-03,\n",
            "         1.0240e-02, 2.0590e-02, 2.7060e-02, 2.3211e+01, 5.1800e-01, 6.6674e-01,\n",
            "         2.6845e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0850e+02, 4.1200e-03, 2.2430e-05, 2.0800e-03,\n",
            "         1.9100e-03, 6.2300e-03, 1.7710e-02, 1.9400e-01, 8.3000e-03, 1.0440e-02,\n",
            "         1.5210e-02, 2.4890e-02, 1.2939e-02, 2.3561e+01, 4.3227e-01, 6.1143e-01,\n",
            "         1.4931e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1561e+02, 4.8200e-03, 2.7110e-05, 2.0200e-03,\n",
            "         2.0400e-03, 6.0600e-03, 1.5490e-02, 1.3600e-01, 8.2100e-03, 9.1300e-03,\n",
            "         1.0550e-02, 2.4630e-02, 1.4745e-02, 2.2922e+01, 4.3205e-01, 6.6893e-01,\n",
            "         1.5811e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.2250e+02, 4.0700e-03, 2.2700e-05, 2.1700e-03,\n",
            "         2.2000e-03, 6.5200e-03, 1.8040e-02, 1.7700e-01, 8.6900e-03, 9.7500e-03,\n",
            "         1.3300e-02, 2.6060e-02, 2.3454e-02, 2.3718e+01, 4.8199e-01, 6.3683e-01,\n",
            "         1.4466e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.3644e+02, 3.6700e-03, 2.0450e-05, 1.8500e-03,\n",
            "         1.9100e-03, 5.5500e-03, 1.5720e-02, 1.3700e-01, 8.5500e-03, 9.5400e-03,\n",
            "         1.0690e-02, 2.5650e-02, 1.7767e-02, 2.4193e+01, 4.5439e-01, 6.7854e-01,\n",
            "         1.9542e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.4378e+02, 3.9200e-03, 2.1680e-05, 1.9300e-03,\n",
            "         1.9300e-03, 5.7800e-03, 1.9480e-02, 1.8300e-01, 9.2100e-03, 1.0680e-02,\n",
            "         1.5060e-02, 2.7630e-02, 1.4547e-02, 2.4303e+01, 4.1671e-01, 6.5608e-01,\n",
            "         1.4016e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.6455e+02, 4.1900e-03, 2.3270e-05, 2.0900e-03,\n",
            "         2.2300e-03, 6.2800e-03, 2.9460e-02, 2.7400e-01, 1.5740e-02, 1.7330e-02,\n",
            "         2.1090e-02, 4.7230e-02, 1.7375e-02, 2.2862e+01, 5.7667e-01, 6.7535e-01,\n",
            "         1.6708e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7854e+02, 3.3400e-03, 1.9040e-05, 1.8000e-03,\n",
            "         2.0500e-03, 5.3900e-03, 1.8450e-02, 1.6100e-01, 1.0520e-02, 1.1900e-02,\n",
            "         1.3600e-02, 3.1550e-02, 8.3330e-03, 2.2111e+01, 5.1335e-01, 6.3864e-01,\n",
            "         1.6996e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1479e+01, 4.4900e-03, 2.4440e-05, 2.6900e-03,\n",
            "         2.3200e-03, 8.0600e-03, 1.9750e-02, 1.8500e-01, 1.1000e-02, 1.1840e-02,\n",
            "         1.2980e-02, 3.3010e-02, 1.6538e-02, 2.3161e+01, 3.8308e-01, 6.2710e-01,\n",
            "         1.8465e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7450e+01, 3.6200e-03, 1.9770e-05, 1.9700e-03,\n",
            "         2.0300e-03, 5.9000e-03, 1.4190e-02, 1.2300e-01, 7.2000e-03, 7.7400e-03,\n",
            "         1.2190e-02, 2.1590e-02, 7.8360e-03, 2.4542e+01, 4.6382e-01, 6.7758e-01,\n",
            "         1.3108e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 2.4422e+01, 3.3100e-03, 1.7700e-05, 1.3800e-03,\n",
            "         1.7700e-03, 4.1400e-03, 2.0580e-02, 2.1100e-01, 1.1120e-02, 1.2400e-02,\n",
            "         1.5680e-02, 3.3360e-02, 9.5670e-03, 2.3048e+01, 4.5579e-01, 6.0472e-01,\n",
            "         1.9631e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.1407e+01, 4.9000e-03, 2.7810e-05, 2.1600e-03,\n",
            "         2.3000e-03, 6.4900e-03, 2.1030e-02, 1.9200e-01, 1.0330e-02, 1.2640e-02,\n",
            "         1.8720e-02, 3.0990e-02, 2.4884e-02, 1.9871e+01, 5.9821e-01, 6.0847e-01,\n",
            "         1.7867e-01]])\n",
            "expected: tensor([[ 6.9987],\n",
            "        [ 7.1599],\n",
            "        [ 7.6164],\n",
            "        [ 7.9240],\n",
            "        [16.4860],\n",
            "        [15.6990],\n",
            "        [14.7800],\n",
            "        [13.8590],\n",
            "        [12.9360],\n",
            "        [12.0110],\n",
            "        [11.0880],\n",
            "        [10.1680],\n",
            "        [ 6.0102],\n",
            "        [ 6.2347],\n",
            "        [ 6.3846],\n",
            "        [ 6.5408],\n",
            "        [ 6.6924],\n",
            "        [ 6.9987],\n",
            "        [ 7.1599],\n",
            "        [ 7.6165],\n",
            "        [ 7.9240],\n",
            "        [16.4860],\n",
            "        [15.6990],\n",
            "        [14.7800],\n",
            "        [13.8580]])\n",
            "prediction tensor([[ 8.9612],\n",
            "        [ 9.0377],\n",
            "        [ 9.2486],\n",
            "        [ 9.2288],\n",
            "        [14.3598],\n",
            "        [14.5764],\n",
            "        [14.2496],\n",
            "        [13.7995],\n",
            "        [13.5834],\n",
            "        [12.8294],\n",
            "        [12.2936],\n",
            "        [11.4169],\n",
            "        [ 9.0574],\n",
            "        [ 9.0060],\n",
            "        [ 8.9008],\n",
            "        [ 8.7888],\n",
            "        [ 8.8763],\n",
            "        [ 8.9890],\n",
            "        [ 9.0622],\n",
            "        [ 9.1894],\n",
            "        [ 9.3564],\n",
            "        [14.3632],\n",
            "        [14.4260],\n",
            "        [14.0686],\n",
            "        [13.3817]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(2.9599, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[3.6000e+01, 1.0000e+00, 3.8404e+01, 3.9800e-03, 2.1800e-05, 1.9800e-03,\n",
            "         2.2400e-03, 5.9400e-03, 2.1160e-02, 1.8700e-01, 1.0480e-02, 1.3170e-02,\n",
            "         1.6420e-02, 3.1430e-02, 3.2476e-02, 2.2682e+01, 5.4989e-01, 6.3228e-01,\n",
            "         2.1490e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 4.5415e+01, 8.5600e-03, 4.7670e-05, 4.1900e-03,\n",
            "         4.0300e-03, 1.2570e-02, 2.6390e-02, 2.7700e-01, 1.3090e-02, 1.5940e-02,\n",
            "         2.0880e-02, 3.9260e-02, 7.2991e-02, 2.0305e+01, 5.3736e-01, 5.8921e-01,\n",
            "         2.9419e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.2421e+01, 3.9900e-03, 2.1950e-05, 2.2600e-03,\n",
            "         2.0700e-03, 6.7700e-03, 1.9720e-02, 1.7400e-01, 1.1200e-02, 1.1730e-02,\n",
            "         1.3610e-02, 3.3590e-02, 2.1547e-02, 2.1570e+01, 4.2467e-01, 5.9682e-01,\n",
            "         1.5395e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.9390e+01, 5.2300e-03, 2.9110e-05, 2.7500e-03,\n",
            "         3.1600e-03, 8.2600e-03, 1.9060e-02, 1.6500e-01, 9.4600e-03, 1.1330e-02,\n",
            "         1.5160e-02, 2.8370e-02, 1.3879e-02, 1.9761e+01, 5.4626e-01, 6.2005e-01,\n",
            "         2.5677e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 9.1465e+01, 3.5100e-03, 1.9760e-05, 1.7200e-03,\n",
            "         1.8500e-03, 5.1500e-03, 2.5060e-02, 2.3800e-01, 1.2700e-02, 1.4610e-02,\n",
            "         1.7360e-02, 3.8110e-02, 1.7141e-02, 2.4964e+01, 4.9455e-01, 6.5884e-01,\n",
            "         1.4285e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0168e+02, 3.6000e-03, 2.0230e-05, 1.6900e-03,\n",
            "         1.9700e-03, 5.0800e-03, 1.5860e-02, 1.3800e-01, 7.0700e-03, 8.4700e-03,\n",
            "         1.3550e-02, 2.1200e-02, 1.9438e-02, 2.4356e+01, 5.0328e-01, 6.6359e-01,\n",
            "         2.1231e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0850e+02, 5.8300e-03, 3.1820e-05, 2.9900e-03,\n",
            "         3.3200e-03, 8.9600e-03, 2.4050e-02, 2.5000e-01, 1.2570e-02, 1.4620e-02,\n",
            "         1.7940e-02, 3.7700e-02, 3.1425e-02, 1.9089e+01, 5.2748e-01, 6.2393e-01,\n",
            "         2.2223e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1561e+02, 3.4500e-03, 1.8910e-05, 1.7300e-03,\n",
            "         1.9200e-03, 5.2000e-03, 1.8600e-02, 1.6600e-01, 9.1800e-03, 1.1270e-02,\n",
            "         1.3850e-02, 2.7550e-02, 7.7850e-03, 2.4584e+01, 4.4212e-01, 6.4600e-01,\n",
            "         1.3619e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.2250e+02, 4.2400e-03, 2.3620e-05, 1.6500e-03,\n",
            "         2.0500e-03, 4.9400e-03, 2.2980e-02, 2.3200e-01, 1.1120e-02, 1.1850e-02,\n",
            "         1.6520e-02, 3.3360e-02, 2.8068e-02, 2.2413e+01, 6.2271e-01, 6.7136e-01,\n",
            "         1.9413e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.3644e+02, 6.3800e-03, 3.5810e-05, 3.4700e-03,\n",
            "         3.2300e-03, 1.0410e-02, 1.5470e-02, 1.3500e-01, 8.4600e-03, 9.0600e-03,\n",
            "         1.0770e-02, 2.5380e-02, 1.7438e-02, 2.1552e+01, 5.3351e-01, 6.3882e-01,\n",
            "         1.5968e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.4378e+02, 4.3500e-03, 2.4550e-05, 2.2200e-03,\n",
            "         2.2700e-03, 6.6500e-03, 1.8920e-02, 1.6200e-01, 1.0120e-02, 1.0910e-02,\n",
            "         1.3610e-02, 3.0350e-02, 1.1161e-02, 2.3087e+01, 5.3195e-01, 6.4670e-01,\n",
            "         1.3365e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.6455e+02, 4.5300e-03, 2.4520e-05, 2.2800e-03,\n",
            "         2.1300e-03, 6.8400e-03, 2.1850e-02, 1.9900e-01, 1.0500e-02, 1.2390e-02,\n",
            "         1.6180e-02, 3.1500e-02, 2.9481e-02, 2.1554e+01, 5.7773e-01, 6.5273e-01,\n",
            "         1.7625e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7854e+02, 3.5100e-03, 1.9080e-05, 1.7200e-03,\n",
            "         1.9300e-03, 5.1700e-03, 1.5190e-02, 1.3100e-01, 7.5800e-03, 9.1200e-03,\n",
            "         1.1590e-02, 2.2750e-02, 8.8940e-03, 2.2157e+01, 4.8678e-01, 6.3477e-01,\n",
            "         1.6364e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1480e+01, 1.9000e-03, 8.6100e-06, 8.3000e-04,\n",
            "         7.5000e-04, 2.5000e-03, 1.0600e-02, 1.0200e-01, 5.0200e-03, 5.7500e-03,\n",
            "         8.4400e-03, 1.5070e-02, 6.4240e-03, 2.9904e+01, 3.3722e-01, 5.4110e-01,\n",
            "         5.8426e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7450e+01, 2.3400e-03, 9.7300e-06, 1.1200e-03,\n",
            "         1.2600e-03, 3.3500e-03, 1.2630e-02, 1.1000e-01, 6.4000e-03, 7.5600e-03,\n",
            "         9.1000e-03, 1.9210e-02, 3.1910e-03, 2.6750e+01, 4.8189e-01, 5.6312e-01,\n",
            "         9.7894e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 2.4422e+01, 2.2500e-03, 9.3100e-06, 8.1000e-04,\n",
            "         1.0100e-03, 2.4300e-03, 1.3210e-02, 1.3400e-01, 4.2400e-03, 5.7000e-03,\n",
            "         9.7900e-03, 1.2720e-02, 1.1362e-02, 2.5968e+01, 5.2363e-01, 5.1977e-01,\n",
            "         1.2915e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.1407e+01, 1.9000e-03, 8.3600e-06, 6.8000e-04,\n",
            "         8.7000e-04, 2.0500e-03, 1.2950e-02, 1.2300e-01, 6.0800e-03, 7.0200e-03,\n",
            "         1.0840e-02, 1.8250e-02, 6.4470e-03, 2.8113e+01, 4.0744e-01, 5.2720e-01,\n",
            "         9.9342e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 3.8405e+01, 2.2000e-03, 1.0070e-05, 9.0000e-04,\n",
            "         1.0100e-03, 2.6900e-03, 1.5280e-02, 1.5400e-01, 7.2900e-03, 8.2700e-03,\n",
            "         1.1360e-02, 2.1860e-02, 8.0090e-03, 2.7410e+01, 3.7663e-01, 5.3467e-01,\n",
            "         9.6100e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 4.5416e+01, 4.1300e-03, 2.0050e-05, 2.0000e-03,\n",
            "         1.6300e-03, 6.0000e-03, 1.7590e-02, 1.7300e-01, 8.9100e-03, 9.5800e-03,\n",
            "         1.2150e-02, 2.6740e-02, 1.7951e-02, 2.2906e+01, 5.3059e-01, 5.4616e-01,\n",
            "         1.1169e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.2422e+01, 3.0100e-03, 1.2610e-05, 1.4800e-03,\n",
            "         1.3900e-03, 4.4500e-03, 1.3980e-02, 1.3000e-01, 5.0000e-03, 6.3600e-03,\n",
            "         1.1740e-02, 1.4990e-02, 1.2516e-02, 2.4986e+01, 5.7988e-01, 5.2544e-01,\n",
            "         8.0683e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 5.9391e+01, 5.1000e-03, 2.3520e-05, 2.7700e-03,\n",
            "         3.0800e-03, 8.3200e-03, 2.0470e-02, 1.8300e-01, 1.1080e-02, 1.2580e-02,\n",
            "         1.4680e-02, 3.3240e-02, 1.8715e-02, 1.9605e+01, 5.7262e-01, 5.4105e-01,\n",
            "         1.9407e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 9.1466e+01, 2.2100e-03, 1.0900e-05, 7.4000e-04,\n",
            "         8.6000e-04, 2.2300e-03, 1.6410e-02, 1.4500e-01, 8.0000e-03, 8.6900e-03,\n",
            "         1.0990e-02, 2.4010e-02, 1.3825e-02, 2.5381e+01, 4.9893e-01, 5.9861e-01,\n",
            "         1.0921e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0168e+02, 2.5900e-03, 1.2190e-05, 1.2500e-03,\n",
            "         1.3900e-03, 3.7600e-03, 1.3290e-02, 1.1900e-01, 6.8200e-03, 7.4000e-03,\n",
            "         9.8200e-03, 2.0450e-02, 1.0497e-02, 2.5747e+01, 4.6162e-01, 5.5609e-01,\n",
            "         1.0709e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0850e+02, 3.7100e-03, 1.8320e-05, 1.7400e-03,\n",
            "         1.8900e-03, 5.2200e-03, 1.8600e-02, 1.6700e-01, 8.9800e-03, 9.6400e-03,\n",
            "         1.2630e-02, 2.6950e-02, 1.7411e-02, 1.9917e+01, 6.8369e-01, 5.4987e-01,\n",
            "         1.5461e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1561e+02, 4.2100e-03, 2.0850e-05, 2.2600e-03,\n",
            "         2.1500e-03, 6.7700e-03, 1.7850e-02, 1.8000e-01, 8.8900e-03, 8.7900e-03,\n",
            "         1.0190e-02, 2.6660e-02, 1.6035e-02, 2.0723e+01, 6.2160e-01, 5.5373e-01,\n",
            "         1.3564e-01]])\n",
            "expected: tensor([[12.9360],\n",
            "        [12.0110],\n",
            "        [11.0870],\n",
            "        [10.1680],\n",
            "        [ 6.0102],\n",
            "        [ 6.2347],\n",
            "        [ 6.3846],\n",
            "        [ 6.5408],\n",
            "        [ 6.6924],\n",
            "        [ 6.9987],\n",
            "        [ 7.1600],\n",
            "        [ 7.6165],\n",
            "        [ 7.9240],\n",
            "        [16.4860],\n",
            "        [15.6990],\n",
            "        [14.7800],\n",
            "        [13.8580],\n",
            "        [12.9360],\n",
            "        [12.0110],\n",
            "        [11.0870],\n",
            "        [10.1680],\n",
            "        [ 6.0102],\n",
            "        [ 6.2347],\n",
            "        [ 6.3846],\n",
            "        [ 6.5408]])\n",
            "prediction tensor([[13.0513],\n",
            "        [12.1541],\n",
            "        [11.7483],\n",
            "        [10.8330],\n",
            "        [ 9.0395],\n",
            "        [ 8.4824],\n",
            "        [ 7.7356],\n",
            "        [ 8.2291],\n",
            "        [ 7.9948],\n",
            "        [ 7.9536],\n",
            "        [ 8.1113],\n",
            "        [ 8.1779],\n",
            "        [ 8.3794],\n",
            "        [14.8505],\n",
            "        [14.4057],\n",
            "        [14.1291],\n",
            "        [14.0925],\n",
            "        [13.6751],\n",
            "        [12.5428],\n",
            "        [12.2439],\n",
            "        [10.8055],\n",
            "        [ 9.1029],\n",
            "        [ 8.6690],\n",
            "        [ 7.8232],\n",
            "        [ 7.8534]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(2.0215, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[3.6000e+01, 1.0000e+00, 1.2250e+02, 2.9900e-03, 1.5340e-05, 1.5400e-03,\n",
            "         1.5200e-03, 4.6300e-03, 1.3410e-02, 1.1800e-01, 7.1200e-03, 7.4800e-03,\n",
            "         1.0460e-02, 2.1370e-02, 6.7550e-03, 2.3689e+01, 5.9506e-01, 5.3695e-01,\n",
            "         1.2365e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.3644e+02, 2.9200e-03, 1.5300e-05, 1.1100e-03,\n",
            "         1.3200e-03, 3.3300e-03, 1.6700e-02, 1.7000e-01, 8.1200e-03, 9.0100e-03,\n",
            "         1.1880e-02, 2.4370e-02, 1.2710e-02, 2.4288e+01, 6.1339e-01, 5.4196e-01,\n",
            "         1.2718e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.4378e+02, 3.0300e-03, 1.5700e-05, 1.3400e-03,\n",
            "         1.4400e-03, 4.0300e-03, 1.2550e-02, 1.3400e-01, 6.0800e-03, 7.2000e-03,\n",
            "         9.3400e-03, 1.8230e-02, 1.2101e-02, 2.4627e+01, 5.6612e-01, 5.5484e-01,\n",
            "         1.2101e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.6455e+02, 2.5500e-03, 1.1140e-05, 1.2400e-03,\n",
            "         1.3400e-03, 3.7300e-03, 1.3660e-02, 1.2200e-01, 6.6300e-03, 7.1100e-03,\n",
            "         9.2500e-03, 1.9880e-02, 1.1142e-02, 2.3799e+01, 5.4206e-01, 5.2965e-01,\n",
            "         1.1876e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7854e+02, 2.2200e-03, 1.0250e-05, 1.1500e-03,\n",
            "         1.1800e-03, 3.4500e-03, 1.7610e-02, 1.5100e-01, 1.0250e-02, 9.7000e-03,\n",
            "         1.1990e-02, 3.0750e-02, 5.1030e-03, 2.4697e+01, 4.7577e-01, 5.3925e-01,\n",
            "         9.2377e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1480e+01, 2.6500e-03, 1.1290e-05, 1.0400e-03,\n",
            "         1.0700e-03, 3.1300e-03, 1.1620e-02, 1.2600e-01, 5.3000e-03, 6.2500e-03,\n",
            "         9.4800e-03, 1.5890e-02, 8.0440e-03, 2.7311e+01, 5.3500e-01, 5.3733e-01,\n",
            "         9.3211e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7451e+01, 2.3800e-03, 9.6100e-06, 1.2500e-03,\n",
            "         1.3100e-03, 3.7500e-03, 1.5570e-02, 1.3700e-01, 9.0000e-03, 9.4600e-03,\n",
            "         1.0750e-02, 2.7010e-02, 3.0740e-03, 2.6524e+01, 4.0572e-01, 5.4696e-01,\n",
            "         8.6541e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 2.4422e+01, 2.5100e-03, 1.0110e-05, 9.3000e-04,\n",
            "         1.0500e-03, 2.7800e-03, 1.1930e-02, 1.1700e-01, 5.4000e-03, 6.3700e-03,\n",
            "         9.1900e-03, 1.6190e-02, 1.7257e-02, 2.6689e+01, 3.9503e-01, 5.2142e-01,\n",
            "         8.4167e-02],\n",
            "        [3.6000e+01, 1.0000e+00, 3.1408e+01, 1.7600e-03, 7.5100e-06, 7.4000e-04,\n",
            "         8.9000e-04, 2.2100e-03, 1.5270e-02, 1.3200e-01, 4.7300e-03, 6.8700e-03,\n",
            "         1.4510e-02, 1.4200e-02, 1.0512e-02, 2.7102e+01, 5.8947e-01, 5.1687e-01,\n",
            "         2.1300e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 3.8406e+01, 2.3100e-03, 1.0450e-05, 9.7000e-04,\n",
            "         9.7000e-04, 2.9000e-03, 1.4170e-02, 1.1600e-01, 6.2300e-03, 7.6900e-03,\n",
            "         1.2280e-02, 1.8680e-02, 7.4520e-03, 2.7293e+01, 5.1256e-01, 5.2572e-01,\n",
            "         1.3393e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 4.5416e+01, 2.1200e-03, 9.9600e-06, 1.0100e-03,\n",
            "         1.0700e-03, 3.0200e-03, 1.2390e-02, 1.1800e-01, 5.4500e-03, 6.4000e-03,\n",
            "         9.1700e-03, 1.6340e-02, 6.6630e-03, 2.5583e+01, 4.7455e-01, 5.2945e-01,\n",
            "         1.1332e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.2422e+01, 3.5800e-03, 1.5520e-05, 1.9200e-03,\n",
            "         1.7300e-03, 5.7500e-03, 1.2640e-02, 1.2500e-01, 5.1500e-03, 6.4300e-03,\n",
            "         9.2200e-03, 1.5460e-02, 1.2798e-02, 2.2223e+01, 4.8404e-01, 5.1655e-01,\n",
            "         1.2017e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 5.9391e+01, 4.9600e-03, 2.3420e-05, 2.7100e-03,\n",
            "         3.0300e-03, 8.1300e-03, 3.9500e-02, 3.7400e-01, 2.0900e-02, 2.3970e-02,\n",
            "         3.0450e-02, 6.2710e-02, 2.5821e-02, 1.8967e+01, 5.8932e-01, 5.3814e-01,\n",
            "         2.2562e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 9.1466e+01, 3.2500e-03, 1.5590e-05, 1.6600e-03,\n",
            "         1.7200e-03, 4.9700e-03, 1.7090e-02, 1.4800e-01, 8.8000e-03, 9.7500e-03,\n",
            "         1.2050e-02, 2.6400e-02, 1.3671e-02, 2.3505e+01, 5.2458e-01, 5.6645e-01,\n",
            "         1.0109e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0168e+02, 2.5000e-03, 1.1950e-05, 9.6000e-04,\n",
            "         1.1700e-03, 2.8900e-03, 1.5020e-02, 1.4600e-01, 6.5100e-03, 8.0000e-03,\n",
            "         1.1230e-02, 1.9530e-02, 7.7690e-03, 2.3815e+01, 5.4057e-01, 5.3269e-01,\n",
            "         1.2885e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.0850e+02, 2.8300e-03, 1.4240e-05, 1.0800e-03,\n",
            "         1.3300e-03, 3.2400e-03, 1.6890e-02, 1.6100e-01, 7.1900e-03, 9.0800e-03,\n",
            "         1.3140e-02, 2.1580e-02, 1.3451e-02, 2.2426e+01, 5.9932e-01, 5.2891e-01,\n",
            "         1.5577e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.1561e+02, 2.8400e-03, 1.4900e-05, 1.3700e-03,\n",
            "         1.3600e-03, 4.1200e-03, 1.2820e-02, 1.1200e-01, 6.5900e-03, 7.2700e-03,\n",
            "         9.1500e-03, 1.9760e-02, 7.0090e-03, 2.3219e+01, 5.5865e-01, 5.4958e-01,\n",
            "         1.2365e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.2251e+02, 2.7600e-03, 1.4720e-05, 1.2500e-03,\n",
            "         1.2200e-03, 3.7500e-03, 1.3430e-02, 1.1400e-01, 6.4800e-03, 7.3000e-03,\n",
            "         9.8800e-03, 1.9450e-02, 1.3915e-02, 2.3053e+01, 5.8893e-01, 5.4429e-01,\n",
            "         1.3209e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.3644e+02, 2.8500e-03, 1.6130e-05, 9.5000e-04,\n",
            "         1.1700e-03, 2.8500e-03, 1.3520e-02, 1.1800e-01, 6.2800e-03, 6.9700e-03,\n",
            "         9.9700e-03, 1.8850e-02, 1.3237e-02, 2.3842e+01, 6.0616e-01, 5.4486e-01,\n",
            "         1.4512e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.6455e+02, 4.2900e-03, 1.8510e-05, 1.8400e-03,\n",
            "         1.9800e-03, 5.5100e-03, 1.7860e-02, 1.7200e-01, 8.9300e-03, 1.0210e-02,\n",
            "         1.3720e-02, 2.6780e-02, 2.3574e-02, 2.0728e+01, 5.9826e-01, 5.3111e-01,\n",
            "         1.6841e-01],\n",
            "        [3.6000e+01, 1.0000e+00, 1.7854e+02, 2.6300e-03, 1.2180e-05, 1.0800e-03,\n",
            "         7.6000e-04, 3.2500e-03, 1.7180e-02, 1.4800e-01, 7.5300e-03, 8.9800e-03,\n",
            "         1.3680e-02, 2.2590e-02, 1.1631e-02, 2.7341e+01, 5.4958e-01, 5.4126e-01,\n",
            "         9.5074e-02],\n",
            "        [6.6000e+01, 1.0000e+00, 9.3806e+00, 7.3300e-03, 3.4180e-05, 4.0900e-03,\n",
            "         3.8600e-03, 1.2270e-02, 5.5740e-02, 4.8600e-01, 3.2050e-02, 3.1650e-02,\n",
            "         3.5980e-02, 9.6160e-02, 3.4412e-02, 1.5742e+01, 6.0897e-01, 6.4520e-01,\n",
            "         2.5559e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6439e+01, 6.8900e-03, 3.0930e-05, 3.4400e-03,\n",
            "         3.6600e-03, 1.0320e-02, 6.5950e-02, 6.3000e-01, 3.4830e-02, 3.6510e-02,\n",
            "         4.7240e-02, 1.0448e-01, 2.7664e-02, 1.6770e+01, 6.5207e-01, 6.4375e-01,\n",
            "         2.7604e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 2.3376e+01, 7.7800e-03, 2.7990e-05, 4.2700e-03,\n",
            "         4.8100e-03, 1.2810e-02, 4.9500e-02, 4.6400e-01, 2.7900e-02, 3.1520e-02,\n",
            "         3.7620e-02, 8.3690e-02, 4.3207e-02, 1.9190e+01, 4.6479e-01, 5.7689e-01,\n",
            "         2.3797e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.0398e+01, 4.9400e-03, 1.9670e-05, 2.2900e-03,\n",
            "         2.5300e-03, 6.8800e-03, 3.2830e-02, 3.1800e-01, 1.7160e-02, 1.7850e-02,\n",
            "         2.3990e-02, 5.1490e-02, 2.4585e-02, 1.9048e+01, 5.5161e-01, 5.8428e-01,\n",
            "         2.6179e-01]])\n",
            "expected: tensor([[ 6.6924],\n",
            "        [ 6.9987],\n",
            "        [ 7.1600],\n",
            "        [ 7.6165],\n",
            "        [ 7.9240],\n",
            "        [16.4860],\n",
            "        [15.6990],\n",
            "        [14.7790],\n",
            "        [13.8580],\n",
            "        [12.9360],\n",
            "        [12.0110],\n",
            "        [11.0870],\n",
            "        [10.1680],\n",
            "        [ 6.0102],\n",
            "        [ 6.2347],\n",
            "        [ 6.3846],\n",
            "        [ 6.5409],\n",
            "        [ 6.6924],\n",
            "        [ 6.9988],\n",
            "        [ 7.6165],\n",
            "        [ 7.9240],\n",
            "        [23.3260],\n",
            "        [23.5720],\n",
            "        [23.8130],\n",
            "        [24.0570]])\n",
            "prediction tensor([[ 7.5421],\n",
            "        [ 7.5578],\n",
            "        [ 7.6015],\n",
            "        [ 7.6622],\n",
            "        [ 7.8331],\n",
            "        [14.3174],\n",
            "        [14.1039],\n",
            "        [13.9164],\n",
            "        [13.6544],\n",
            "        [13.3243],\n",
            "        [12.5576],\n",
            "        [11.4550],\n",
            "        [10.2899],\n",
            "        [ 8.3024],\n",
            "        [ 7.8765],\n",
            "        [ 7.5444],\n",
            "        [ 7.5406],\n",
            "        [ 7.4849],\n",
            "        [ 7.5242],\n",
            "        [ 7.4666],\n",
            "        [ 8.0048],\n",
            "        [22.3089],\n",
            "        [22.3256],\n",
            "        [22.4690],\n",
            "        [22.2503]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(1.1503, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[6.6000e+01, 1.0000e+00, 3.7410e+01, 3.4400e-03, 1.1110e-05, 1.6600e-03,\n",
            "         1.7100e-03, 4.9800e-03, 2.6760e-02, 2.5700e-01, 1.3930e-02, 1.5600e-02,\n",
            "         2.1510e-02, 4.1780e-02, 1.1502e-02, 2.2320e+01, 4.6162e-01, 5.3683e-01,\n",
            "         2.0242e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 4.4372e+01, 6.6800e-03, 2.7900e-05, 3.2000e-03,\n",
            "         2.8000e-03, 9.6100e-03, 4.0910e-02, 3.6900e-01, 2.2370e-02, 2.3810e-02,\n",
            "         2.9220e-02, 6.7100e-02, 4.8361e-02, 1.7346e+01, 6.2739e-01, 5.9384e-01,\n",
            "         2.3153e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.1408e+01, 5.1500e-03, 1.9260e-05, 2.8800e-03,\n",
            "         2.4500e-03, 8.6300e-03, 3.1410e-02, 2.8400e-01, 1.6910e-02, 1.7900e-02,\n",
            "         2.4250e-02, 5.0730e-02, 1.9054e-02, 2.0732e+01, 4.4984e-01, 5.9397e-01,\n",
            "         2.1760e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.8415e+01, 7.2600e-03, 3.0150e-05, 3.5000e-03,\n",
            "         3.5800e-03, 1.0490e-02, 5.1790e-02, 4.7900e-01, 2.7620e-02, 3.2830e-02,\n",
            "         4.0040e-02, 8.2850e-02, 2.8548e-02, 1.6809e+01, 6.1669e-01, 6.1643e-01,\n",
            "         3.1116e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 6.5397e+01, 3.9700e-03, 1.4840e-05, 1.7800e-03,\n",
            "         1.9400e-03, 5.3300e-03, 3.7070e-02, 3.4900e-01, 1.9670e-02, 2.2030e-02,\n",
            "         3.3590e-02, 5.9020e-02, 9.9490e-03, 2.1509e+01, 4.5015e-01, 5.8776e-01,\n",
            "         2.3367e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.2412e+01, 6.1200e-03, 3.4820e-05, 2.9400e-03,\n",
            "         3.3100e-03, 8.8200e-03, 4.5590e-02, 4.1900e-01, 2.4280e-02, 2.7990e-02,\n",
            "         3.3850e-02, 7.2840e-02, 2.5458e-02, 1.8455e+01, 6.9277e-01, 6.4807e-01,\n",
            "         2.5326e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.9442e+01, 7.2600e-03, 2.7890e-05, 3.9900e-03,\n",
            "         3.6700e-03, 1.1960e-02, 4.3380e-02, 3.8100e-01, 2.4630e-02, 2.4720e-02,\n",
            "         2.9370e-02, 7.3900e-02, 3.1449e-02, 1.9170e+01, 5.7203e-01, 5.7443e-01,\n",
            "         2.4429e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0037e+02, 7.5600e-03, 4.2130e-05, 3.4100e-03,\n",
            "         3.6100e-03, 1.0230e-02, 6.0000e-02, 5.2800e-01, 3.3060e-02, 3.6700e-02,\n",
            "         4.8050e-02, 9.9180e-02, 5.1121e-02, 1.4314e+01, 6.1964e-01, 5.6749e-01,\n",
            "         2.8977e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0740e+02, 6.2100e-03, 2.3370e-05, 3.0800e-03,\n",
            "         2.8700e-03, 9.2500e-03, 4.0530e-02, 3.8100e-01, 2.2090e-02, 2.2600e-02,\n",
            "         2.8490e-02, 6.6280e-02, 2.9050e-02, 1.6650e+01, 5.3048e-01, 5.7286e-01,\n",
            "         2.8201e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.1441e+02, 6.8700e-03, 3.4260e-05, 3.2100e-03,\n",
            "         3.0300e-03, 9.6400e-03, 6.3880e-02, 5.6300e-01, 3.4730e-02, 3.6780e-02,\n",
            "         4.8300e-02, 1.0418e-01, 4.8284e-02, 1.5462e+01, 6.1222e-01, 5.7708e-01,\n",
            "         2.3954e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2135e+02, 4.2700e-03, 1.5940e-05, 2.2200e-03,\n",
            "         2.0800e-03, 6.6500e-03, 5.1010e-02, 4.4500e-01, 2.8810e-02, 3.0760e-02,\n",
            "         3.7790e-02, 8.6440e-02, 2.3521e-02, 1.7895e+01, 5.4922e-01, 5.8888e-01,\n",
            "         2.3350e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2836e+02, 7.8200e-03, 4.1130e-05, 3.2800e-03,\n",
            "         3.4200e-03, 9.8500e-03, 4.8840e-02, 4.6500e-01, 2.5030e-02, 2.6270e-02,\n",
            "         4.1330e-02, 7.5090e-02, 6.3035e-02, 1.5236e+01, 6.3228e-01, 6.1950e-01,\n",
            "         3.0125e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.3541e+02, 6.1400e-03, 2.2520e-05, 3.0600e-03,\n",
            "         3.0400e-03, 9.1700e-03, 4.8760e-02, 4.6700e-01, 2.7290e-02, 2.8870e-02,\n",
            "         3.2480e-02, 8.1870e-02, 2.5837e-02, 1.8434e+01, 4.9593e-01, 5.6001e-01,\n",
            "         2.3950e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4239e+02, 4.5000e-03, 1.7620e-05, 2.1200e-03,\n",
            "         2.4400e-03, 6.3700e-03, 3.9430e-02, 3.8100e-01, 2.1140e-02, 2.5630e-02,\n",
            "         3.3200e-02, 6.3410e-02, 1.0975e-02, 2.2781e+01, 4.3795e-01, 5.6241e-01,\n",
            "         2.9037e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4940e+02, 4.4900e-03, 3.1120e-05, 1.5000e-03,\n",
            "         2.5100e-03, 4.4900e-03, 5.9410e-02, 5.0900e-01, 3.0860e-02, 3.2980e-02,\n",
            "         5.0920e-02, 9.2580e-02, 2.9958e-02, 1.6694e+01, 6.3695e-01, 5.8207e-01,\n",
            "         2.5885e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.5645e+02, 6.5100e-03, 4.1380e-05, 2.9600e-03,\n",
            "         3.7000e-03, 8.8900e-03, 7.7390e-02, 7.1500e-01, 3.6770e-02, 4.7320e-02,\n",
            "         7.7630e-02, 1.1030e-01, 7.8461e-02, 1.4526e+01, 6.6805e-01, 5.6577e-01,\n",
            "         3.4399e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6335e+02, 7.3000e-03, 2.9990e-05, 3.5200e-03,\n",
            "         4.1200e-03, 1.0550e-02, 4.0950e-02, 3.7300e-01, 2.0430e-02, 2.3470e-02,\n",
            "         3.6770e-02, 6.1300e-02, 3.3964e-02, 1.8619e+01, 6.5708e-01, 6.2772e-01,\n",
            "         2.8968e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7042e+02, 8.8300e-03, 3.7720e-05, 4.7500e-03,\n",
            "         4.6700e-03, 1.4250e-02, 4.5520e-02, 4.0300e-01, 2.3760e-02, 2.7170e-02,\n",
            "         3.5900e-02, 7.1270e-02, 6.7052e-02, 1.3766e+01, 6.0220e-01, 5.6845e-01,\n",
            "         3.3499e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7746e+02, 3.4000e-03, 1.4440e-05, 1.4100e-03,\n",
            "         1.7300e-03, 4.2300e-03, 2.8520e-02, 2.5100e-01, 1.5840e-02, 1.6450e-02,\n",
            "         2.0900e-02, 4.7510e-02, 2.2068e-02, 1.7916e+01, 5.7829e-01, 6.0455e-01,\n",
            "         2.5933e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 9.3812e+00, 9.3200e-03, 4.2480e-05, 4.9000e-03,\n",
            "         5.3900e-03, 1.4700e-02, 5.1990e-02, 4.9400e-01, 2.8260e-02, 3.1180e-02,\n",
            "         4.2860e-02, 8.4770e-02, 7.2636e-02, 1.5851e+01, 5.7624e-01, 6.0652e-01,\n",
            "         3.0911e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6440e+01, 6.8100e-03, 3.1160e-05, 3.4500e-03,\n",
            "         3.4800e-03, 1.0360e-02, 7.0860e-02, 6.5500e-01, 4.0140e-02, 4.2470e-02,\n",
            "         5.1920e-02, 1.2043e-01, 4.1394e-02, 1.5757e+01, 5.7406e-01, 6.2045e-01,\n",
            "         2.7170e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 2.3376e+01, 4.7000e-03, 1.4490e-05, 2.7500e-03,\n",
            "         2.2300e-03, 8.2400e-03, 4.0900e-02, 3.3000e-01, 2.5590e-02, 2.0210e-02,\n",
            "         2.4790e-02, 7.6780e-02, 1.5639e-02, 2.2197e+01, 4.6381e-01, 5.3137e-01,\n",
            "         1.8354e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.0399e+01, 6.1300e-03, 2.3160e-05, 3.2700e-03,\n",
            "         3.0900e-03, 9.8000e-03, 3.6040e-02, 3.3700e-01, 2.0420e-02, 1.9700e-02,\n",
            "         2.4160e-02, 6.1270e-02, 3.1669e-02, 1.8908e+01, 5.1771e-01, 5.5946e-01,\n",
            "         2.5290e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.7410e+01, 1.9000e-03, 5.5200e-06, 9.8000e-04,\n",
            "         9.0000e-04, 2.9300e-03, 1.7630e-02, 1.6000e-01, 9.5000e-03, 9.8100e-03,\n",
            "         1.2780e-02, 2.8500e-02, 3.8860e-03, 2.5879e+01, 4.7771e-01, 5.1903e-01,\n",
            "         1.1911e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 4.4372e+01, 4.0100e-03, 1.4030e-05, 1.9000e-03,\n",
            "         1.9700e-03, 5.7100e-03, 3.3170e-02, 3.0100e-01, 1.8780e-02, 1.8430e-02,\n",
            "         2.2180e-02, 5.6340e-02, 1.9010e-02, 2.0938e+01, 5.0525e-01, 5.4790e-01,\n",
            "         2.5525e-01]])\n",
            "expected: tensor([[24.3010],\n",
            "        [24.5430],\n",
            "        [24.7880],\n",
            "        [25.0320],\n",
            "        [25.2750],\n",
            "        [25.5190],\n",
            "        [25.7630],\n",
            "        [26.4910],\n",
            "        [26.7360],\n",
            "        [26.9800],\n",
            "        [27.2850],\n",
            "        [27.5980],\n",
            "        [27.9140],\n",
            "        [28.2260],\n",
            "        [28.5400],\n",
            "        [28.8560],\n",
            "        [29.1650],\n",
            "        [29.4810],\n",
            "        [29.7970],\n",
            "        [23.3260],\n",
            "        [23.5720],\n",
            "        [23.8130],\n",
            "        [24.0570],\n",
            "        [24.3010],\n",
            "        [24.5430]])\n",
            "prediction tensor([[22.5245],\n",
            "        [21.5525],\n",
            "        [21.5957],\n",
            "        [20.5170],\n",
            "        [20.6961],\n",
            "        [19.6194],\n",
            "        [19.1009],\n",
            "        [16.3145],\n",
            "        [16.0179],\n",
            "        [15.1856],\n",
            "        [14.8955],\n",
            "        [13.9697],\n",
            "        [13.8123],\n",
            "        [13.8385],\n",
            "        [12.7086],\n",
            "        [12.1781],\n",
            "        [12.2236],\n",
            "        [11.7047],\n",
            "        [11.8646],\n",
            "        [22.4588],\n",
            "        [22.3152],\n",
            "        [22.9749],\n",
            "        [22.3466],\n",
            "        [22.9914],\n",
            "        [22.0547]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(108.5078, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[6.6000e+01, 1.0000e+00, 5.1408e+01, 4.3400e-03, 1.6010e-05, 2.2900e-03,\n",
            "         2.2400e-03, 6.8600e-03, 3.1500e-02, 2.8000e-01, 1.6970e-02, 1.7570e-02,\n",
            "         2.3000e-02, 5.0900e-02, 1.3702e-02, 2.1315e+01, 4.3468e-01, 5.7139e-01,\n",
            "         2.1497e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.8415e+01, 8.2500e-03, 3.5280e-05, 4.2100e-03,\n",
            "         4.2100e-03, 1.2620e-02, 4.6360e-02, 4.1700e-01, 2.5400e-02, 2.7860e-02,\n",
            "         3.4510e-02, 7.6190e-02, 4.7933e-02, 1.6347e+01, 6.2287e-01, 5.7823e-01,\n",
            "         3.0136e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 6.5398e+01, 3.1700e-03, 1.0910e-05, 1.2700e-03,\n",
            "         1.5100e-03, 3.8200e-03, 3.6430e-02, 3.3500e-01, 1.9590e-02, 2.2760e-02,\n",
            "         2.7250e-02, 5.8770e-02, 1.0894e-02, 2.3006e+01, 3.3640e-01, 5.6032e-01,\n",
            "         2.4273e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.2412e+01, 7.0300e-03, 2.9900e-05, 3.5200e-03,\n",
            "         3.6900e-03, 1.0570e-02, 5.2470e-02, 4.8800e-01, 2.7540e-02, 3.0000e-02,\n",
            "         3.7320e-02, 8.2620e-02, 2.8055e-02, 1.7738e+01, 5.7778e-01, 6.3067e-01,\n",
            "         2.5728e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.9442e+01, 3.2400e-03, 1.1850e-05, 1.5600e-03,\n",
            "         1.5100e-03, 4.6900e-03, 2.8390e-02, 2.5600e-01, 1.6030e-02, 1.5960e-02,\n",
            "         1.9950e-02, 4.8080e-02, 1.4533e-02, 2.2329e+01, 4.0760e-01, 5.5640e-01,\n",
            "         1.8786e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0740e+02, 4.4800e-03, 1.5800e-05, 2.2200e-03,\n",
            "         2.2600e-03, 6.6600e-03, 6.2020e-02, 5.5600e-01, 3.6610e-02, 3.3380e-02,\n",
            "         3.8130e-02, 1.0983e-01, 2.3538e-02, 1.8145e+01, 4.4447e-01, 5.5596e-01,\n",
            "         2.7071e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.1441e+02, 4.8000e-03, 1.8390e-05, 2.6300e-03,\n",
            "         2.3500e-03, 7.9000e-03, 5.6160e-02, 4.8600e-01, 3.3530e-02, 3.0460e-02,\n",
            "         3.6680e-02, 1.0059e-01, 1.7358e-02, 1.8782e+01, 4.6857e-01, 5.5723e-01,\n",
            "         2.5947e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2135e+02, 4.8400e-03, 1.6920e-05, 2.4400e-03,\n",
            "         2.5500e-03, 7.3300e-03, 5.4490e-02, 5.1500e-01, 3.2440e-02, 3.0980e-02,\n",
            "         3.5340e-02, 9.7310e-02, 2.6716e-02, 1.8408e+01, 5.5696e-01, 5.4463e-01,\n",
            "         2.0654e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2836e+02, 6.3700e-03, 3.2990e-05, 2.4100e-03,\n",
            "         2.8700e-03, 7.2200e-03, 3.6040e-02, 3.2000e-01, 1.6710e-02, 2.1680e-02,\n",
            "         3.2040e-02, 5.0120e-02, 4.8088e-02, 1.5198e+01, 5.7697e-01, 5.9787e-01,\n",
            "         3.2006e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.3541e+02, 5.5900e-03, 1.9700e-05, 2.8600e-03,\n",
            "         3.3500e-03, 8.5900e-03, 4.9590e-02, 4.6300e-01, 2.7180e-02, 3.1200e-02,\n",
            "         3.7210e-02, 8.1540e-02, 2.2215e-02, 1.8414e+01, 4.9548e-01, 5.5422e-01,\n",
            "         2.3261e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4239e+02, 5.1000e-03, 2.2180e-05, 2.0700e-03,\n",
            "         1.9100e-03, 6.2200e-03, 4.4810e-02, 4.3700e-01, 2.4300e-02, 2.5730e-02,\n",
            "         3.5100e-02, 7.2900e-02, 3.5308e-02, 1.7649e+01, 6.0997e-01, 5.6884e-01,\n",
            "         3.2196e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4940e+02, 6.7500e-03, 2.7680e-05, 3.8100e-03,\n",
            "         3.1300e-03, 1.1430e-02, 6.6420e-02, 4.9600e-01, 4.1930e-02, 3.3360e-02,\n",
            "         4.3010e-02, 1.2580e-01, 3.1493e-02, 1.7551e+01, 5.5746e-01, 5.3874e-01,\n",
            "         2.4019e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.5645e+02, 8.3100e-03, 4.3850e-05, 3.5500e-03,\n",
            "         5.1600e-03, 1.0640e-02, 1.4318e-01, 1.3640e+00, 7.1410e-02, 9.8440e-02,\n",
            "         1.0876e-01, 2.1423e-01, 8.9442e-02, 1.2185e+01, 6.4442e-01, 5.4697e-01,\n",
            "         2.8276e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6335e+02, 6.4200e-03, 2.9480e-05, 2.7600e-03,\n",
            "         2.6200e-03, 8.2700e-03, 4.2600e-02, 3.9500e-01, 2.3590e-02, 2.3320e-02,\n",
            "         3.6420e-02, 7.0760e-02, 1.6428e-02, 2.0109e+01, 6.2512e-01, 6.3192e-01,\n",
            "         2.7357e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7042e+02, 6.6000e-03, 2.4770e-05, 3.2700e-03,\n",
            "         3.1200e-03, 9.8000e-03, 4.6840e-02, 4.4400e-01, 2.6110e-02, 2.8130e-02,\n",
            "         3.6880e-02, 7.8340e-02, 2.6057e-02, 1.7131e+01, 4.7263e-01, 5.5192e-01,\n",
            "         3.0740e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7746e+02, 4.8300e-03, 1.9640e-05, 2.2700e-03,\n",
            "         2.5100e-03, 6.8100e-03, 2.7600e-02, 2.4000e-01, 1.4430e-02, 1.5600e-02,\n",
            "         2.1660e-02, 4.3290e-02, 2.7020e-02, 1.7757e+01, 5.9283e-01, 5.6857e-01,\n",
            "         2.4921e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 9.3812e+00, 6.9400e-03, 3.1940e-05, 3.6300e-03,\n",
            "         3.5000e-03, 1.0900e-02, 3.4690e-02, 2.9800e-01, 1.7480e-02, 2.2200e-02,\n",
            "         3.3140e-02, 5.2440e-02, 4.3910e-02, 1.7832e+01, 6.1130e-01, 6.0854e-01,\n",
            "         2.6066e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6440e+01, 4.1200e-03, 1.9080e-05, 1.7700e-03,\n",
            "         2.0700e-03, 5.3100e-03, 3.9310e-02, 3.6100e-01, 2.1130e-02, 2.3830e-02,\n",
            "         3.0010e-02, 6.3380e-02, 3.1100e-02, 1.8861e+01, 5.4346e-01, 5.8962e-01,\n",
            "         2.5969e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 2.3377e+01, 2.6100e-03, 7.9700e-06, 1.1900e-03,\n",
            "         1.2600e-03, 3.5800e-03, 2.0000e-02, 2.0400e-01, 1.1070e-02, 1.1610e-02,\n",
            "         1.3930e-02, 3.3220e-02, 9.2740e-03, 2.4128e+01, 3.3114e-01, 5.3042e-01,\n",
            "         2.1300e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.0399e+01, 6.8800e-03, 2.5460e-05, 3.5800e-03,\n",
            "         4.2400e-03, 1.0740e-02, 2.4480e-02, 2.3800e-01, 1.2350e-02, 1.3900e-02,\n",
            "         1.9210e-02, 3.7040e-02, 3.2818e-02, 1.7245e+01, 5.1836e-01, 5.4387e-01,\n",
            "         2.4801e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.7411e+01, 3.0400e-03, 9.2400e-06, 1.2200e-03,\n",
            "         1.3800e-03, 3.6500e-03, 2.4540e-02, 2.2600e-01, 1.2990e-02, 1.3730e-02,\n",
            "         1.8040e-02, 3.8960e-02, 2.2094e-02, 2.1538e+01, 4.8131e-01, 5.2581e-01,\n",
            "         1.8401e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 4.4372e+01, 4.6200e-03, 1.5990e-05, 2.3400e-03,\n",
            "         1.8300e-03, 7.0100e-03, 2.8820e-02, 2.6300e-01, 1.5180e-02, 1.5960e-02,\n",
            "         2.0060e-02, 4.5550e-02, 1.7207e-02, 2.0620e+01, 5.4854e-01, 5.4866e-01,\n",
            "         2.3461e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.1409e+01, 5.9000e-03, 1.9730e-05, 3.4200e-03,\n",
            "         2.6700e-03, 1.0250e-02, 7.3410e-02, 6.4200e-01, 4.4990e-02, 3.7300e-02,\n",
            "         4.5640e-02, 1.3496e-01, 2.2025e-02, 1.9083e+01, 4.6135e-01, 5.4931e-01,\n",
            "         2.4419e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.8415e+01, 3.4700e-03, 1.3880e-05, 1.5100e-03,\n",
            "         1.6000e-03, 4.5300e-03, 2.6370e-02, 2.4100e-01, 1.4850e-02, 1.5420e-02,\n",
            "         1.9150e-02, 4.4560e-02, 1.7680e-02, 2.0180e+01, 5.7090e-01, 5.6080e-01,\n",
            "         2.3519e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 6.5398e+01, 3.1900e-03, 1.0450e-05, 1.4000e-03,\n",
            "         1.6600e-03, 4.2000e-03, 2.0380e-02, 2.2500e-01, 1.0770e-02, 1.1600e-02,\n",
            "         1.4760e-02, 3.2300e-02, 1.4034e-02, 2.4934e+01, 3.3575e-01, 5.4624e-01,\n",
            "         2.2227e-01]])\n",
            "expected: tensor([[24.7880],\n",
            "        [25.0320],\n",
            "        [25.2750],\n",
            "        [25.5190],\n",
            "        [25.7630],\n",
            "        [26.7360],\n",
            "        [26.9800],\n",
            "        [27.2850],\n",
            "        [27.5980],\n",
            "        [27.9140],\n",
            "        [28.2260],\n",
            "        [28.5400],\n",
            "        [28.8560],\n",
            "        [29.1650],\n",
            "        [29.4820],\n",
            "        [29.7970],\n",
            "        [23.3260],\n",
            "        [23.5720],\n",
            "        [23.8130],\n",
            "        [24.0570],\n",
            "        [24.3010],\n",
            "        [24.5430],\n",
            "        [24.7880],\n",
            "        [25.0320],\n",
            "        [25.2750]])\n",
            "prediction tensor([[30.4531],\n",
            "        [29.4688],\n",
            "        [30.4372],\n",
            "        [29.3321],\n",
            "        [29.8779],\n",
            "        [27.7734],\n",
            "        [27.5584],\n",
            "        [27.1709],\n",
            "        [26.3670],\n",
            "        [26.6231],\n",
            "        [26.2802],\n",
            "        [26.0402],\n",
            "        [25.1727],\n",
            "        [26.0067],\n",
            "        [25.4582],\n",
            "        [25.4121],\n",
            "        [29.7467],\n",
            "        [30.0360],\n",
            "        [30.9039],\n",
            "        [29.9237],\n",
            "        [30.5889],\n",
            "        [30.4307],\n",
            "        [30.0841],\n",
            "        [30.1255],\n",
            "        [30.7680]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(20.3831, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[6.6000e+01, 1.0000e+00, 7.2412e+01, 6.6200e-03, 2.6370e-05, 3.4600e-03,\n",
            "         3.4300e-03, 1.0380e-02, 5.0920e-02, 4.6300e-01, 2.9270e-02, 2.9300e-02,\n",
            "         3.9570e-02, 8.7800e-02, 3.0395e-02, 1.8784e+01, 6.0339e-01, 5.8131e-01,\n",
            "         2.9215e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.9443e+01, 5.1300e-03, 1.7910e-05, 2.8500e-03,\n",
            "         2.5000e-03, 8.5600e-03, 3.0510e-02, 2.7800e-01, 1.6560e-02, 1.7650e-02,\n",
            "         2.3290e-02, 4.9680e-02, 2.0354e-02, 2.0096e+01, 4.1524e-01, 5.5295e-01,\n",
            "         2.5119e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0037e+02, 6.5100e-03, 2.7530e-05, 3.4100e-03,\n",
            "         3.5400e-03, 1.0230e-02, 4.0060e-02, 3.4800e-01, 2.1340e-02, 2.4170e-02,\n",
            "         2.9080e-02, 6.4020e-02, 3.2039e-02, 1.6372e+01, 6.0223e-01, 5.4099e-01,\n",
            "         2.7873e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0740e+02, 4.8500e-03, 1.6880e-05, 2.4600e-03,\n",
            "         2.5000e-03, 7.3700e-03, 3.9740e-02, 3.5200e-01, 2.1770e-02, 2.3350e-02,\n",
            "         2.8190e-02, 6.5300e-02, 2.0304e-02, 1.8972e+01, 5.3729e-01, 5.3665e-01,\n",
            "         2.5205e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.1441e+02, 6.8700e-03, 2.6570e-05, 3.8400e-03,\n",
            "         3.5500e-03, 1.1520e-02, 5.1890e-02, 4.6700e-01, 2.9660e-02, 3.1170e-02,\n",
            "         3.7770e-02, 8.8990e-02, 3.0278e-02, 1.7361e+01, 5.8247e-01, 5.5118e-01,\n",
            "         2.4885e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2135e+02, 4.7000e-03, 2.4600e-05, 2.1300e-03,\n",
            "         2.5100e-03, 6.3800e-03, 6.5170e-02, 5.9600e-01, 3.3240e-02, 4.2820e-02,\n",
            "         5.7200e-02, 9.9720e-02, 3.8551e-02, 1.6329e+01, 5.7137e-01, 5.5831e-01,\n",
            "         2.2081e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2836e+02, 8.0300e-03, 3.8960e-05, 3.9800e-03,\n",
            "         3.7300e-03, 1.1950e-02, 6.4680e-02, 5.9400e-01, 3.5790e-02, 3.7210e-02,\n",
            "         5.3050e-02, 1.0737e-01, 5.3791e-02, 1.4908e+01, 5.8882e-01, 6.5170e-01,\n",
            "         3.2269e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.3541e+02, 5.9200e-03, 2.1170e-05, 3.5300e-03,\n",
            "         2.8000e-03, 1.0580e-02, 3.8750e-02, 3.2800e-01, 2.2290e-02, 2.1510e-02,\n",
            "         2.6280e-02, 6.6860e-02, 2.1926e-02, 1.9177e+01, 5.5343e-01, 5.4307e-01,\n",
            "         1.9918e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4239e+02, 4.8200e-03, 1.8430e-05, 2.5000e-03,\n",
            "         2.3300e-03, 7.4900e-03, 3.1200e-02, 2.7400e-01, 1.7070e-02, 1.8590e-02,\n",
            "         2.4200e-02, 5.1220e-02, 2.5606e-02, 1.8868e+01, 5.5725e-01, 5.5622e-01,\n",
            "         2.3455e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4940e+02, 4.2200e-03, 1.6010e-05, 2.0600e-03,\n",
            "         2.0900e-03, 6.1900e-03, 2.6180e-02, 2.2500e-01, 1.3740e-02, 1.5790e-02,\n",
            "         1.9250e-02, 4.1220e-02, 1.8044e-02, 1.9684e+01, 5.6021e-01, 5.4569e-01,\n",
            "         2.2572e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.5645e+02, 5.7700e-03, 2.1820e-05, 3.0400e-03,\n",
            "         2.6000e-03, 9.1200e-03, 5.1660e-02, 4.2700e-01, 2.9390e-02, 3.0700e-02,\n",
            "         3.6680e-02, 8.8170e-02, 3.4486e-02, 1.7084e+01, 5.7577e-01, 5.3439e-01,\n",
            "         2.0694e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6335e+02, 5.4500e-03, 2.2470e-05, 2.9800e-03,\n",
            "         2.6800e-03, 8.9300e-03, 3.3770e-02, 2.9800e-01, 1.8010e-02, 1.8670e-02,\n",
            "         2.5880e-02, 5.4020e-02, 2.3091e-02, 1.9096e+01, 6.0744e-01, 5.7680e-01,\n",
            "         2.3374e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7042e+02, 6.8000e-03, 2.6350e-05, 3.0300e-03,\n",
            "         2.6600e-03, 9.0900e-03, 5.7580e-02, 5.6500e-01, 3.1910e-02, 3.6170e-02,\n",
            "         4.3010e-02, 9.5740e-02, 4.5580e-02, 1.5515e+01, 5.7445e-01, 5.5045e-01,\n",
            "         2.7127e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7746e+02, 4.5800e-03, 1.8510e-05, 2.2100e-03,\n",
            "         2.4300e-03, 6.6200e-03, 2.7220e-02, 2.5400e-01, 1.3700e-02, 1.5400e-02,\n",
            "         2.0630e-02, 4.1100e-02, 1.9213e-02, 1.8596e+01, 6.2401e-01, 5.5925e-01,\n",
            "         2.2699e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 9.3833e+00, 4.5900e-03, 1.6250e-05, 2.3900e-03,\n",
            "         2.3500e-03, 7.1600e-03, 3.5640e-02, 3.4500e-01, 1.9590e-02, 2.0020e-02,\n",
            "         2.6180e-02, 5.8760e-02, 1.6934e-02, 2.1349e+01, 4.8967e-01, 5.5554e-01,\n",
            "         2.3767e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6441e+01, 4.6000e-03, 1.9640e-05, 1.8500e-03,\n",
            "         2.1500e-03, 5.5600e-03, 3.9930e-02, 3.8200e-01, 2.0510e-02, 2.4130e-02,\n",
            "         3.1650e-02, 6.1540e-02, 2.1615e-02, 1.8763e+01, 5.4200e-01, 5.7583e-01,\n",
            "         2.1733e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 2.3378e+01, 8.1100e-03, 2.8060e-05, 4.6300e-03,\n",
            "         4.0700e-03, 1.3890e-02, 9.1500e-02, 8.1600e-01, 5.7960e-02, 4.3230e-02,\n",
            "         5.4340e-02, 1.7387e-01, 3.9731e-02, 1.6387e+01, 4.8895e-01, 5.7671e-01,\n",
            "         2.6516e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.0400e+01, 3.3600e-03, 1.2040e-05, 1.5800e-03,\n",
            "         1.7500e-03, 4.7400e-03, 3.4510e-02, 3.1000e-01, 1.8590e-02, 2.0600e-02,\n",
            "         2.7270e-02, 5.5770e-02, 1.1702e-02, 2.0968e+01, 4.7827e-01, 5.6562e-01,\n",
            "         2.2386e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.7412e+01, 4.4400e-03, 1.4820e-05, 2.4000e-03,\n",
            "         2.0500e-03, 7.2100e-03, 5.7230e-02, 5.3600e-01, 3.4010e-02, 2.9000e-02,\n",
            "         3.5050e-02, 1.0203e-01, 2.2242e-02, 1.8725e+01, 4.6235e-01, 5.5518e-01,\n",
            "         2.3647e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 4.4374e+01, 6.5200e-03, 2.5090e-05, 3.2900e-03,\n",
            "         3.1600e-03, 9.8700e-03, 3.3480e-02, 3.0200e-01, 1.7870e-02, 2.0660e-02,\n",
            "         2.6220e-02, 5.3620e-02, 3.0539e-02, 1.8860e+01, 5.5800e-01, 5.6663e-01,\n",
            "         2.9237e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.1410e+01, 7.7600e-03, 2.6710e-05, 4.1100e-03,\n",
            "         4.0700e-03, 1.2320e-02, 4.8950e-02, 4.3300e-01, 2.6930e-02, 2.8430e-02,\n",
            "         3.5290e-02, 8.0800e-02, 4.7077e-02, 1.6731e+01, 5.8114e-01, 5.5531e-01,\n",
            "         3.2341e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.8417e+01, 7.2500e-03, 2.9920e-05, 3.4700e-03,\n",
            "         3.3900e-03, 1.0410e-02, 4.8240e-02, 4.3300e-01, 2.5410e-02, 2.7690e-02,\n",
            "         3.6600e-02, 7.6220e-02, 3.6059e-02, 1.7655e+01, 6.1018e-01, 5.7047e-01,\n",
            "         2.6572e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 6.5400e+01, 5.0700e-03, 1.8350e-05, 2.6300e-03,\n",
            "         2.2400e-03, 7.8800e-03, 4.0910e-02, 3.8100e-01, 2.3610e-02, 2.2670e-02,\n",
            "         2.8060e-02, 7.0830e-02, 2.4708e-02, 1.7773e+01, 4.6666e-01, 5.6630e-01,\n",
            "         2.8164e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.2414e+01, 7.7900e-03, 3.9200e-05, 4.0900e-03,\n",
            "         3.7800e-03, 1.2260e-02, 4.9120e-02, 4.6400e-01, 2.7010e-02, 2.9550e-02,\n",
            "         3.9980e-02, 8.1030e-02, 4.1527e-02, 1.5685e+01, 6.4395e-01, 6.0096e-01,\n",
            "         2.4637e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.9444e+01, 8.0400e-03, 2.9770e-05, 4.3400e-03,\n",
            "         5.0900e-03, 1.3020e-02, 7.3310e-02, 6.3800e-01, 4.0160e-02, 4.7030e-02,\n",
            "         5.5370e-02, 1.2048e-01, 5.0660e-02, 1.5060e+01, 4.9334e-01, 5.6824e-01,\n",
            "         3.2083e-01]])\n",
            "expected: tensor([[25.5190],\n",
            "        [25.7630],\n",
            "        [26.4910],\n",
            "        [26.7360],\n",
            "        [26.9800],\n",
            "        [27.2850],\n",
            "        [27.5980],\n",
            "        [27.9140],\n",
            "        [28.2260],\n",
            "        [28.5400],\n",
            "        [28.8560],\n",
            "        [29.1650],\n",
            "        [29.4820],\n",
            "        [29.7970],\n",
            "        [23.3260],\n",
            "        [23.5720],\n",
            "        [23.8130],\n",
            "        [24.0570],\n",
            "        [24.3010],\n",
            "        [24.5430],\n",
            "        [24.7880],\n",
            "        [25.0320],\n",
            "        [25.2750],\n",
            "        [25.5190],\n",
            "        [25.7630]])\n",
            "prediction tensor([[26.3366],\n",
            "        [26.3066],\n",
            "        [24.8105],\n",
            "        [24.9269],\n",
            "        [24.3803],\n",
            "        [23.9270],\n",
            "        [23.5307],\n",
            "        [23.9054],\n",
            "        [23.6579],\n",
            "        [23.5671],\n",
            "        [23.0569],\n",
            "        [23.1308],\n",
            "        [22.6190],\n",
            "        [22.8341],\n",
            "        [27.0369],\n",
            "        [26.7860],\n",
            "        [26.5222],\n",
            "        [27.2049],\n",
            "        [26.8757],\n",
            "        [26.8702],\n",
            "        [26.4764],\n",
            "        [26.4728],\n",
            "        [26.3408],\n",
            "        [25.8457],\n",
            "        [25.5076]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(13.1423, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[6.6000e+01, 1.0000e+00, 1.0037e+02, 5.7400e-03, 2.7530e-05, 2.3100e-03,\n",
            "         2.7300e-03, 6.9400e-03, 6.5380e-02, 6.3800e-01, 3.5840e-02, 3.5950e-02,\n",
            "         4.5300e-02, 1.0751e-01, 7.0130e-02, 1.3583e+01, 6.5867e-01, 5.6274e-01,\n",
            "         3.0926e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0740e+02, 4.4000e-03, 1.6640e-05, 2.1100e-03,\n",
            "         2.2200e-03, 6.3300e-03, 4.5630e-02, 3.9600e-01, 2.4210e-02, 2.8480e-02,\n",
            "         3.6430e-02, 7.2620e-02, 2.6642e-02, 1.7171e+01, 4.9790e-01, 5.3168e-01,\n",
            "         2.6568e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.1441e+02, 5.1000e-03, 2.1320e-05, 2.4000e-03,\n",
            "         2.7800e-03, 7.2000e-03, 4.1770e-02, 3.7100e-01, 2.2330e-02, 2.5240e-02,\n",
            "         3.2980e-02, 6.7000e-02, 3.5159e-02, 1.6805e+01, 5.9599e-01, 5.8504e-01,\n",
            "         2.5483e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2136e+02, 6.9200e-03, 2.4820e-05, 4.0700e-03,\n",
            "         3.8000e-03, 1.2210e-02, 8.9100e-02, 7.7700e-01, 5.3400e-02, 4.5910e-02,\n",
            "         5.3840e-02, 1.6020e-01, 3.3630e-02, 1.7384e+01, 4.8085e-01, 5.6143e-01,\n",
            "         2.3094e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2836e+02, 6.8000e-03, 4.4770e-05, 3.1000e-03,\n",
            "         3.7700e-03, 9.3000e-03, 4.5040e-02, 4.3000e-01, 2.3280e-02, 2.6360e-02,\n",
            "         3.7270e-02, 6.9830e-02, 1.0449e-01, 1.3254e+01, 6.7985e-01, 6.2676e-01,\n",
            "         3.0759e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4239e+02, 3.8200e-03, 1.5390e-05, 1.6500e-03,\n",
            "         1.8400e-03, 4.9500e-03, 2.5110e-02, 2.2200e-01, 1.3070e-02, 1.4440e-02,\n",
            "         1.9350e-02, 3.9220e-02, 3.3565e-02, 1.8644e+01, 6.1992e-01, 5.7338e-01,\n",
            "         2.5644e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4940e+02, 5.2100e-03, 2.0720e-05, 2.3600e-03,\n",
            "         2.3400e-03, 7.0800e-03, 3.0180e-02, 2.7800e-01, 1.6450e-02, 1.8120e-02,\n",
            "         2.3580e-02, 4.9350e-02, 3.5255e-02, 1.8346e+01, 5.8183e-01, 5.4902e-01,\n",
            "         2.4844e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.5645e+02, 7.2700e-03, 2.8220e-05, 3.3400e-03,\n",
            "         3.5800e-03, 1.0030e-02, 7.7820e-02, 7.0000e-01, 4.2960e-02, 4.8420e-02,\n",
            "         6.0350e-02, 1.2888e-01, 5.5779e-02, 1.5639e+01, 6.0401e-01, 5.3590e-01,\n",
            "         4.1165e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6335e+02, 5.4500e-03, 2.3140e-05, 2.6300e-03,\n",
            "         2.8400e-03, 7.8900e-03, 5.3310e-02, 4.5700e-01, 2.6910e-02, 3.2800e-02,\n",
            "         4.3820e-02, 8.0740e-02, 3.0804e-02, 1.7145e+01, 6.5086e-01, 5.9441e-01,\n",
            "         2.7347e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7042e+02, 1.9690e-02, 7.1370e-05, 9.9100e-03,\n",
            "         1.4970e-02, 2.9730e-02, 1.1136e-01, 1.0380e+00, 5.9930e-02, 6.7180e-02,\n",
            "         7.8820e-02, 1.7979e-01, 1.7984e-01, 1.1227e+01, 6.3059e-01, 5.6279e-01,\n",
            "         3.8234e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7746e+02, 5.1700e-03, 2.0740e-05, 2.7200e-03,\n",
            "         2.5800e-03, 8.1500e-03, 2.3930e-02, 2.1700e-01, 1.2320e-02, 1.3040e-02,\n",
            "         1.8450e-02, 3.6970e-02, 2.9863e-02, 1.7833e+01, 6.2878e-01, 5.5626e-01,\n",
            "         2.1739e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 9.3833e+00, 5.6300e-03, 1.7880e-05, 3.2100e-03,\n",
            "         3.3400e-03, 9.6400e-03, 3.6760e-02, 3.5100e-01, 2.0520e-02, 2.1810e-02,\n",
            "         2.4270e-02, 6.1570e-02, 2.4238e-02, 2.1054e+01, 4.0644e-01, 5.3060e-01,\n",
            "         2.0432e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6442e+01, 6.1900e-03, 2.5910e-05, 2.5100e-03,\n",
            "         2.7600e-03, 7.5200e-03, 6.6210e-02, 6.2100e-01, 3.8380e-02, 3.6120e-02,\n",
            "         4.5300e-02, 1.1514e-01, 4.6083e-02, 1.5373e+01, 5.4822e-01, 5.6168e-01,\n",
            "         2.7731e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 2.3378e+01, 3.3700e-03, 9.8700e-06, 1.5500e-03,\n",
            "         1.5900e-03, 4.6600e-03, 2.7230e-02, 2.6900e-01, 1.5160e-02, 1.5850e-02,\n",
            "         1.8520e-02, 4.5490e-02, 1.4253e-02, 2.4045e+01, 4.1453e-01, 5.1971e-01,\n",
            "         1.9136e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.0401e+01, 5.3100e-03, 1.7130e-05, 2.4900e-03,\n",
            "         2.4100e-03, 7.4800e-03, 3.7190e-02, 3.6300e-01, 1.9970e-02, 2.1240e-02,\n",
            "         2.7680e-02, 5.9910e-02, 4.0596e-02, 1.7182e+01, 5.5675e-01, 5.3406e-01,\n",
            "         2.9328e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.7413e+01, 4.4400e-03, 1.3480e-05, 2.2500e-03,\n",
            "         2.9500e-03, 6.7500e-03, 3.7600e-02, 3.4600e-01, 2.0830e-02, 2.3360e-02,\n",
            "         2.6300e-02, 6.2480e-02, 2.7803e-02, 2.0831e+01, 3.8307e-01, 5.2662e-01,\n",
            "         2.5515e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 4.4374e+01, 6.5700e-03, 2.4120e-05, 3.2100e-03,\n",
            "         2.8800e-03, 9.6300e-03, 4.4360e-02, 4.2300e-01, 2.3450e-02, 2.2850e-02,\n",
            "         3.2760e-02, 7.0340e-02, 3.6128e-02, 1.7167e+01, 4.7711e-01, 5.3669e-01,\n",
            "         3.0260e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.1411e+01, 6.3400e-03, 1.8730e-05, 3.7800e-03,\n",
            "         3.4000e-03, 1.1330e-02, 3.5580e-02, 3.2700e-01, 1.9740e-02, 2.1510e-02,\n",
            "         2.4750e-02, 5.9220e-02, 1.8815e-02, 1.9586e+01, 3.8147e-01, 5.2829e-01,\n",
            "         2.6057e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.8417e+01, 8.0000e-03, 3.3510e-05, 3.2000e-03,\n",
            "         3.3900e-03, 9.5900e-03, 5.8510e-02, 5.8800e-01, 3.1760e-02, 3.4410e-02,\n",
            "         4.7150e-02, 9.5290e-02, 5.1726e-02, 1.6200e+01, 5.5883e-01, 5.5575e-01,\n",
            "         3.2881e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 6.5400e+01, 2.0700e-03, 6.3700e-06, 8.2000e-04,\n",
            "         1.0300e-03, 2.4700e-03, 1.9740e-02, 1.7200e-01, 1.0000e-02, 1.1380e-02,\n",
            "         1.5370e-02, 3.0010e-02, 5.4770e-03, 2.4623e+01, 3.2474e-01, 5.2947e-01,\n",
            "         1.9717e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.2414e+01, 6.7000e-03, 3.0190e-05, 3.0700e-03,\n",
            "         3.5100e-03, 9.2200e-03, 6.6490e-02, 5.9300e-01, 3.7220e-02, 3.9920e-02,\n",
            "         5.3300e-02, 1.1165e-01, 3.5030e-02, 1.7473e+01, 5.3694e-01, 5.8079e-01,\n",
            "         2.6107e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.9445e+01, 4.9300e-03, 2.8500e-05, 2.0300e-03,\n",
            "         2.7800e-03, 6.0800e-03, 7.1370e-02, 6.9500e-01, 3.9420e-02, 4.3890e-02,\n",
            "         5.5520e-02, 1.1827e-01, 6.0477e-02, 1.4310e+01, 5.4485e-01, 5.4113e-01,\n",
            "         3.1708e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0037e+02, 5.1800e-03, 1.9970e-05, 2.1700e-03,\n",
            "         2.0800e-03, 6.5000e-03, 3.4550e-02, 3.3300e-01, 1.8580e-02, 2.1950e-02,\n",
            "         2.7170e-02, 5.5740e-02, 2.7829e-02, 1.6917e+01, 5.7526e-01, 5.2993e-01,\n",
            "         2.7271e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0740e+02, 3.0400e-03, 9.4400e-06, 1.5000e-03,\n",
            "         1.4500e-03, 4.5100e-03, 3.0230e-02, 2.8100e-01, 1.5770e-02, 1.7990e-02,\n",
            "         2.2660e-02, 4.7300e-02, 1.1987e-02, 2.0374e+01, 5.3778e-01, 5.2646e-01,\n",
            "         2.0892e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.1441e+02, 4.3400e-03, 1.4950e-05, 1.9300e-03,\n",
            "         1.7800e-03, 5.7800e-03, 3.6450e-02, 3.3400e-01, 2.0140e-02, 2.0050e-02,\n",
            "         2.6530e-02, 6.0410e-02, 1.9663e-02, 1.9988e+01, 5.4027e-01, 5.2944e-01,\n",
            "         2.3546e-01]])\n",
            "expected: tensor([[26.4910],\n",
            "        [26.7360],\n",
            "        [26.9800],\n",
            "        [27.2850],\n",
            "        [27.5980],\n",
            "        [28.2260],\n",
            "        [28.5400],\n",
            "        [28.8560],\n",
            "        [29.1650],\n",
            "        [29.4820],\n",
            "        [29.7970],\n",
            "        [23.3260],\n",
            "        [23.5720],\n",
            "        [23.8130],\n",
            "        [24.0570],\n",
            "        [24.3010],\n",
            "        [24.5430],\n",
            "        [24.7880],\n",
            "        [25.0320],\n",
            "        [25.2750],\n",
            "        [25.5190],\n",
            "        [25.7630],\n",
            "        [26.4910],\n",
            "        [26.7360],\n",
            "        [26.9800]])\n",
            "prediction tensor([[27.1688],\n",
            "        [27.5852],\n",
            "        [27.3778],\n",
            "        [27.2915],\n",
            "        [26.6479],\n",
            "        [27.2338],\n",
            "        [27.1088],\n",
            "        [26.7151],\n",
            "        [26.8587],\n",
            "        [26.2071],\n",
            "        [26.8983],\n",
            "        [28.3355],\n",
            "        [27.7103],\n",
            "        [29.1005],\n",
            "        [28.2830],\n",
            "        [28.8825],\n",
            "        [28.4049],\n",
            "        [28.8044],\n",
            "        [28.2559],\n",
            "        [29.5575],\n",
            "        [28.4103],\n",
            "        [27.7938],\n",
            "        [27.7221],\n",
            "        [28.1149],\n",
            "        [27.8792]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(8.7928, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[6.6000e+01, 1.0000e+00, 1.2136e+02, 8.8800e-03, 2.7990e-05, 4.7500e-03,\n",
            "         5.3100e-03, 1.4260e-02, 7.3390e-02, 6.5500e-01, 4.5430e-02, 3.7150e-02,\n",
            "         4.4100e-02, 1.3629e-01, 5.5778e-02, 1.6419e+01, 5.2122e-01, 5.3283e-01,\n",
            "         2.6805e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2836e+02, 6.1500e-03, 3.4580e-05, 2.2900e-03,\n",
            "         2.9200e-03, 6.8800e-03, 4.2440e-02, 3.8100e-01, 2.0850e-02, 2.6380e-02,\n",
            "         3.4220e-02, 6.2560e-02, 5.3826e-02, 1.5141e+01, 6.9489e-01, 5.9286e-01,\n",
            "         3.1968e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.3541e+02, 5.2000e-03, 2.8950e-05, 1.7900e-03,\n",
            "         2.2000e-03, 5.3600e-03, 5.3640e-02, 4.7100e-01, 3.0060e-02, 2.7920e-02,\n",
            "         3.8040e-02, 9.0190e-02, 6.5038e-02, 1.5346e+01, 6.3731e-01, 5.4549e-01,\n",
            "         2.5823e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.4940e+02, 3.4800e-03, 1.2060e-05, 1.8600e-03,\n",
            "         1.7400e-03, 5.5900e-03, 2.7390e-02, 2.4100e-01, 1.4240e-02, 1.7080e-02,\n",
            "         2.1890e-02, 4.2720e-02, 1.2779e-02, 2.0502e+01, 4.5958e-01, 5.4043e-01,\n",
            "         2.1585e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.5645e+02, 4.2100e-03, 1.3310e-05, 2.2100e-03,\n",
            "         1.8900e-03, 6.6400e-03, 4.2980e-02, 3.7400e-01, 2.4050e-02, 2.4510e-02,\n",
            "         2.9930e-02, 7.2150e-02, 1.8524e-02, 1.9469e+01, 5.2036e-01, 5.3811e-01,\n",
            "         2.4019e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6335e+02, 3.7400e-03, 1.3510e-05, 1.9100e-03,\n",
            "         1.8700e-03, 5.7300e-03, 3.2660e-02, 2.8700e-01, 1.7610e-02, 2.0700e-02,\n",
            "         2.4740e-02, 5.2840e-02, 1.5500e-02, 2.0712e+01, 4.4375e-01, 5.6317e-01,\n",
            "         2.2750e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7042e+02, 7.1500e-03, 2.4160e-05, 4.0900e-03,\n",
            "         3.2900e-03, 1.2280e-02, 4.8400e-02, 4.9900e-01, 2.7590e-02, 2.7980e-02,\n",
            "         3.5820e-02, 8.2780e-02, 4.0506e-02, 1.5990e+01, 5.7865e-01, 5.3150e-01,\n",
            "         2.2302e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.7746e+02, 7.2700e-03, 2.7920e-05, 3.5100e-03,\n",
            "         2.9400e-03, 1.0540e-02, 3.5870e-02, 3.2000e-01, 1.8700e-02, 2.1090e-02,\n",
            "         2.5760e-02, 5.6100e-02, 2.9694e-02, 1.7723e+01, 5.5605e-01, 5.5642e-01,\n",
            "         2.5455e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 9.3840e+00, 4.7000e-03, 1.5720e-05, 2.6100e-03,\n",
            "         2.3200e-03, 7.8200e-03, 2.8940e-02, 2.5600e-01, 1.6060e-02, 1.6760e-02,\n",
            "         2.0430e-02, 4.8180e-02, 2.0676e-02, 1.9349e+01, 4.9848e-01, 5.3687e-01,\n",
            "         2.5316e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.6442e+01, 4.1300e-03, 1.3160e-05, 2.4200e-03,\n",
            "         1.8800e-03, 7.2500e-03, 4.1740e-02, 3.8100e-01, 2.4930e-02, 2.2850e-02,\n",
            "         2.7640e-02, 7.4800e-02, 1.1636e-02, 2.0996e+01, 3.4412e-01, 5.3324e-01,\n",
            "         2.0647e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 2.3379e+01, 4.9000e-03, 1.3930e-05, 2.7600e-03,\n",
            "         2.2800e-03, 8.2800e-03, 5.9790e-02, 5.4800e-01, 3.7760e-02, 2.8710e-02,\n",
            "         3.5430e-02, 1.1329e-01, 1.7273e-02, 2.2156e+01, 3.4241e-01, 5.1977e-01,\n",
            "         1.9133e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.0401e+01, 3.3000e-03, 1.0210e-05, 1.5800e-03,\n",
            "         1.5300e-03, 4.7500e-03, 2.2740e-02, 2.2900e-01, 1.2000e-02, 1.2910e-02,\n",
            "         1.8250e-02, 3.6000e-02, 2.1930e-02, 2.0407e+01, 5.0141e-01, 5.2669e-01,\n",
            "         2.3438e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 3.7413e+01, 3.1600e-03, 8.9400e-06, 1.5500e-03,\n",
            "         1.6100e-03, 4.6600e-03, 3.2060e-02, 3.3300e-01, 1.7160e-02, 1.8270e-02,\n",
            "         2.3890e-02, 5.1490e-02, 1.7959e-02, 2.1430e+01, 5.1441e-01, 5.1404e-01,\n",
            "         2.3598e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 4.4374e+01, 3.6900e-03, 1.1900e-05, 1.8800e-03,\n",
            "         1.9600e-03, 5.6400e-03, 3.6070e-02, 3.3400e-01, 1.9920e-02, 2.0930e-02,\n",
            "         2.6690e-02, 5.9750e-02, 1.9011e-02, 2.1210e+01, 4.9931e-01, 5.3070e-01,\n",
            "         2.0952e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.1411e+01, 7.6200e-03, 3.4200e-05, 4.0700e-03,\n",
            "         4.6600e-03, 1.2200e-02, 1.0503e-01, 9.2300e-01, 5.8980e-02, 7.2290e-02,\n",
            "         8.0870e-02, 1.7694e-01, 5.4946e-02, 1.4301e+01, 5.2156e-01, 5.3176e-01,\n",
            "         2.6689e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 5.8418e+01, 3.3600e-03, 1.1360e-05, 1.4100e-03,\n",
            "         1.3100e-03, 4.2400e-03, 3.5530e-02, 3.2500e-01, 2.0170e-02, 1.8430e-02,\n",
            "         2.4900e-02, 6.0520e-02, 9.5750e-03, 2.1678e+01, 4.2023e-01, 5.2786e-01,\n",
            "         2.3054e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 6.5401e+01, 2.2400e-03, 6.5700e-06, 9.7000e-04,\n",
            "         1.0900e-03, 2.9100e-03, 2.5130e-02, 2.2800e-01, 1.3450e-02, 1.4330e-02,\n",
            "         2.0320e-02, 4.0360e-02, 6.4110e-03, 2.4102e+01, 2.9704e-01, 5.2756e-01,\n",
            "         2.2740e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.2415e+01, 9.7400e-03, 3.3040e-05, 5.4500e-03,\n",
            "         5.5300e-03, 1.6350e-02, 3.7680e-02, 4.4200e-01, 2.1670e-02, 2.2070e-02,\n",
            "         2.5680e-02, 6.5000e-02, 9.0996e-02, 1.7135e+01, 5.2672e-01, 5.4700e-01,\n",
            "         3.3631e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 7.9445e+01, 4.3100e-03, 1.5540e-05, 2.1000e-03,\n",
            "         2.1800e-03, 6.3100e-03, 6.7670e-02, 6.7300e-01, 4.1100e-02, 3.4460e-02,\n",
            "         4.5180e-02, 1.2330e-01, 2.9445e-02, 1.8190e+01, 4.2456e-01, 5.3790e-01,\n",
            "         2.6056e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0037e+02, 5.4900e-03, 1.8810e-05, 2.7800e-03,\n",
            "         2.3200e-03, 8.3500e-03, 4.4370e-02, 4.0400e-01, 2.5470e-02, 2.3590e-02,\n",
            "         3.1640e-02, 7.6400e-02, 2.8470e-02, 1.7224e+01, 5.7329e-01, 5.2423e-01,\n",
            "         2.5990e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.0740e+02, 5.0200e-03, 1.5490e-05, 2.5700e-03,\n",
            "         2.4200e-03, 7.7200e-03, 4.6780e-02, 4.4800e-01, 2.4000e-02, 2.7230e-02,\n",
            "         3.7450e-02, 7.2010e-02, 3.4077e-02, 1.7854e+01, 5.8546e-01, 5.2696e-01,\n",
            "         3.0984e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.1441e+02, 4.1700e-03, 1.2880e-05, 2.2700e-03,\n",
            "         2.0000e-03, 6.8200e-03, 3.7870e-02, 3.4900e-01, 2.0940e-02, 2.0930e-02,\n",
            "         2.5950e-02, 6.2820e-02, 1.5944e-02, 1.9866e+01, 4.6489e-01, 5.2940e-01,\n",
            "         2.2910e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2136e+02, 3.5600e-03, 1.5750e-05, 1.4800e-03,\n",
            "         1.9200e-03, 4.4400e-03, 5.9250e-02, 5.4100e-01, 3.2780e-02, 3.6690e-02,\n",
            "         4.1010e-02, 9.8330e-02, 2.4364e-02, 1.7526e+01, 4.8597e-01, 5.3762e-01,\n",
            "         2.1158e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.2836e+02, 6.2600e-03, 3.0310e-05, 2.5300e-03,\n",
            "         3.1500e-03, 7.5900e-03, 3.7630e-02, 3.6900e-01, 1.8140e-02, 2.1630e-02,\n",
            "         3.2190e-02, 5.4420e-02, 8.2841e-02, 1.5503e+01, 6.5588e-01, 5.8793e-01,\n",
            "         3.1553e-01],\n",
            "        [6.6000e+01, 1.0000e+00, 1.3541e+02, 6.0400e-03, 2.3960e-05, 3.1900e-03,\n",
            "         3.0400e-03, 9.5700e-03, 6.5740e-02, 5.9800e-01, 3.7330e-02, 3.7630e-02,\n",
            "         4.7730e-02, 1.1199e-01, 3.7327e-02, 1.6387e+01, 5.8790e-01, 5.3668e-01,\n",
            "         2.6958e-01]])\n",
            "expected: tensor([[27.2850],\n",
            "        [27.5980],\n",
            "        [27.9140],\n",
            "        [28.5400],\n",
            "        [28.8560],\n",
            "        [29.1650],\n",
            "        [29.4820],\n",
            "        [29.7970],\n",
            "        [23.3260],\n",
            "        [23.5720],\n",
            "        [23.8130],\n",
            "        [24.0570],\n",
            "        [24.3010],\n",
            "        [24.5430],\n",
            "        [24.7880],\n",
            "        [25.0320],\n",
            "        [25.2750],\n",
            "        [25.5190],\n",
            "        [25.7630],\n",
            "        [26.4910],\n",
            "        [26.7360],\n",
            "        [26.9800],\n",
            "        [27.2850],\n",
            "        [27.5980],\n",
            "        [27.9140]])\n",
            "prediction tensor([[25.3613],\n",
            "        [25.1507],\n",
            "        [25.1057],\n",
            "        [25.6446],\n",
            "        [25.4406],\n",
            "        [25.5369],\n",
            "        [25.0130],\n",
            "        [25.1917],\n",
            "        [26.2145],\n",
            "        [26.6055],\n",
            "        [26.9074],\n",
            "        [26.8218],\n",
            "        [27.0384],\n",
            "        [27.0835],\n",
            "        [26.1271],\n",
            "        [27.1741],\n",
            "        [27.5034],\n",
            "        [26.4611],\n",
            "        [26.5207],\n",
            "        [25.9199],\n",
            "        [25.8513],\n",
            "        [25.9990],\n",
            "        [25.5131],\n",
            "        [25.1975],\n",
            "        [25.2345]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(6.8658, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[ 6.6000e+01,  1.0000e+00,  1.4239e+02,  4.8000e-03,  1.6500e-05,\n",
            "          2.4600e-03,  2.5100e-03,  7.3800e-03,  2.6510e-02,  2.4000e-01,\n",
            "          1.4330e-02,  1.5980e-02,  2.1100e-02,  4.2990e-02,  2.6210e-02,\n",
            "          1.8342e+01,  5.4216e-01,  5.4690e-01,  2.5379e-01],\n",
            "        [ 6.6000e+01,  1.0000e+00,  1.4940e+02,  5.7300e-03,  1.8400e-05,\n",
            "          3.2800e-03,  2.5100e-03,  9.8500e-03,  4.1440e-02,  4.0700e-01,\n",
            "          2.4490e-02,  2.1270e-02,  2.8650e-02,  7.3480e-02,  2.8170e-02,\n",
            "          1.8676e+01,  5.3236e-01,  5.3193e-01,  2.4035e-01],\n",
            "        [ 6.6000e+01,  1.0000e+00,  1.5645e+02,  3.9300e-03,  1.3080e-05,\n",
            "          2.0100e-03,  1.9300e-03,  6.0200e-03,  5.5790e-02,  4.9800e-01,\n",
            "          3.0600e-02,  3.4930e-02,  4.1130e-02,  9.1810e-02,  2.2822e-02,\n",
            "          1.8362e+01,  5.8261e-01,  5.2823e-01,  1.9044e-01],\n",
            "        [ 6.6000e+01,  1.0000e+00,  1.6335e+02,  2.3300e-03,  8.4700e-06,\n",
            "          8.5000e-04,  1.0500e-03,  2.5500e-03,  1.6380e-02,  1.5200e-01,\n",
            "          7.9500e-03,  9.3000e-03,  1.3720e-02,  2.3840e-02,  1.3965e-02,\n",
            "          2.3184e+01,  4.9293e-01,  5.3599e-01,  1.4562e-01],\n",
            "        [ 6.6000e+01,  1.0000e+00,  1.7042e+02,  6.0600e-03,  1.9720e-05,\n",
            "          3.3400e-03,  2.7000e-03,  1.0020e-02,  4.3310e-02,  3.6600e-01,\n",
            "          2.4460e-02,  2.2520e-02,  3.1860e-02,  7.3370e-02,  2.7409e-02,\n",
            "          1.8692e+01,  4.9373e-01,  5.3427e-01,  2.6575e-01],\n",
            "        [ 6.6000e+01,  1.0000e+00,  1.7746e+02,  4.3300e-03,  1.4130e-05,\n",
            "          1.7000e-03,  1.6500e-03,  5.1000e-03,  3.4550e-02,  3.1000e-01,\n",
            "          1.9210e-02,  2.0230e-02,  2.3920e-02,  5.7630e-02,  2.3521e-02,\n",
            "          1.9309e+01,  4.1663e-01,  5.5277e-01,  2.6697e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00, -3.3125e+00,  4.4100e-03,  3.6770e-05,\n",
            "          2.0200e-03,  2.3900e-03,  6.0700e-03,  2.0970e-02,  1.7800e-01,\n",
            "          1.0430e-02,  1.0630e-02,  1.8500e-02,  3.1280e-02,  3.1377e-02,\n",
            "          1.9613e+01,  6.6328e-01,  6.4633e-01,  1.8148e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.2750e+00,  6.7700e-03,  6.4070e-05,\n",
            "          3.7200e-03,  3.6600e-03,  1.1170e-02,  1.7680e-02,  1.4900e-01,\n",
            "          7.5800e-03,  9.8500e-03,  1.7790e-02,  2.2740e-02,  2.5708e-02,\n",
            "          2.1413e+01,  6.6761e-01,  7.2480e-01,  2.8549e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0581e+01,  3.5800e-03,  3.2270e-05,\n",
            "          1.5900e-03,  2.0500e-03,  4.7600e-03,  1.6500e-02,  1.4100e-01,\n",
            "          7.4400e-03,  9.0700e-03,  1.4940e-02,  2.2330e-02,  1.2621e-02,\n",
            "          2.1375e+01,  6.3013e-01,  6.8880e-01,  1.8276e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7577e+01,  4.3100e-03,  4.4240e-05,\n",
            "          1.9000e-03,  2.4000e-03,  5.7000e-03,  1.4170e-02,  1.2200e-01,\n",
            "          6.9100e-03,  8.8300e-03,  1.3490e-02,  2.0740e-02,  1.3955e-02,\n",
            "          2.0894e+01,  6.8553e-01,  7.1612e-01,  1.9805e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  2.4540e+01,  9.1400e-03,  9.1100e-05,\n",
            "          4.7900e-03,  4.4400e-03,  1.4380e-02,  3.5240e-02,  3.0900e-01,\n",
            "          1.6560e-02,  1.8260e-02,  3.3470e-02,  4.9690e-02,  4.9628e-02,\n",
            "          1.6267e+01,  6.9867e-01,  6.9256e-01,  3.5247e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.1644e+01,  6.9400e-03,  7.7610e-05,\n",
            "          2.6900e-03,  3.3100e-03,  8.0800e-03,  3.4940e-02,  3.0200e-01,\n",
            "          1.8610e-02,  1.8910e-02,  2.7830e-02,  5.5840e-02,  5.7675e-02,\n",
            "          1.6575e+01,  7.0986e-01,  7.0953e-01,  3.2247e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.8625e+01,  5.8800e-03,  5.8820e-05,\n",
            "          2.2000e-03,  3.0200e-03,  6.6100e-03,  2.8470e-02,  2.4400e-01,\n",
            "          1.1780e-02,  1.6200e-02,  2.9930e-02,  3.5350e-02,  2.5149e-02,\n",
            "          2.0482e+01,  7.1074e-01,  7.0931e-01,  2.3275e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  4.5662e+01,  8.1900e-03,  8.1840e-05,\n",
            "          4.2000e-03,  4.7400e-03,  1.2590e-02,  3.4380e-02,  3.0700e-01,\n",
            "          1.4560e-02,  1.9690e-02,  3.1350e-02,  4.3670e-02,  3.8512e-02,\n",
            "          1.7931e+01,  7.0793e-01,  7.3296e-01,  3.3017e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.2665e+01,  1.0370e-02,  1.0906e-04,\n",
            "          6.0200e-03,  6.2100e-03,  1.8050e-02,  5.1290e-02,  4.4800e-01,\n",
            "          2.5940e-02,  3.2980e-02,  4.1530e-02,  7.7810e-02,  9.3566e-02,\n",
            "          1.2591e+01,  7.4359e-01,  7.1382e-01,  3.9344e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.7821e+01,  4.6500e-03,  4.6450e-05,\n",
            "          2.4400e-03,  2.8600e-03,  7.3100e-03,  1.6550e-02,  1.4400e-01,\n",
            "          8.1500e-03,  1.0590e-02,  1.6150e-02,  2.4440e-02,  2.3427e-02,\n",
            "          1.7551e+01,  6.3259e-01,  7.5224e-01,  2.2342e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  6.6658e+01,  8.1800e-03,  8.8060e-05,\n",
            "          4.8100e-03,  4.3900e-03,  1.4440e-02,  3.3360e-02,  2.7600e-01,\n",
            "          1.7380e-02,  1.8900e-02,  3.0440e-02,  5.2130e-02,  5.2032e-02,\n",
            "          1.5613e+01,  7.2826e-01,  7.1744e-01,  3.1874e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  7.3651e+01,  1.3560e-02,  1.6661e-04,\n",
            "          5.0600e-03,  7.0900e-03,  1.5180e-02,  2.6540e-02,  2.3600e-01,\n",
            "          1.2680e-02,  1.8430e-02,  2.7850e-02,  3.8030e-02,  7.2811e-02,\n",
            "          1.6043e+01,  7.5258e-01,  7.4325e-01,  4.5105e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.0599e+01,  6.5700e-03,  6.7150e-05,\n",
            "          3.1000e-03,  3.5000e-03,  9.3100e-03,  2.0880e-02,  1.7900e-01,\n",
            "          1.0090e-02,  1.3010e-02,  1.9360e-02,  3.0270e-02,  2.0340e-02,\n",
            "          1.9964e+01,  6.6804e-01,  7.2583e-01,  2.7456e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.7583e+01,  4.2900e-03,  4.4560e-05,\n",
            "          2.1300e-03,  2.6100e-03,  6.3900e-03,  2.1650e-02,  1.8700e-01,\n",
            "          1.0750e-02,  1.3390e-02,  2.1730e-02,  3.2260e-02,  1.7946e-02,\n",
            "          1.9789e+01,  6.3313e-01,  7.3454e-01,  2.0590e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  9.4525e+01,  1.2990e-02,  1.3224e-04,\n",
            "          7.4700e-03,  6.9100e-03,  2.2410e-02,  3.4340e-02,  3.0700e-01,\n",
            "          1.8000e-02,  1.8220e-02,  3.1560e-02,  5.4000e-02,  3.9476e-02,\n",
            "          1.7639e+01,  6.6581e-01,  7.1649e-01,  4.4731e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0159e+02,  5.2700e-03,  5.1700e-05,\n",
            "          2.6800e-03,  2.7100e-03,  8.0500e-03,  2.0180e-02,  1.7200e-01,\n",
            "          1.1090e-02,  1.2190e-02,  1.6020e-02,  3.3280e-02,  3.1657e-02,\n",
            "          1.8657e+01,  6.0744e-01,  7.0612e-01,  2.7445e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0854e+02,  9.7400e-03,  1.0226e-04,\n",
            "          4.9500e-03,  5.3200e-03,  1.4850e-02,  2.0310e-02,  1.7600e-01,\n",
            "          1.0060e-02,  1.0630e-02,  1.5880e-02,  3.0190e-02,  3.9822e-02,\n",
            "          1.8564e+01,  6.5364e-01,  7.4086e-01,  4.1283e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.1567e+02,  7.6100e-03,  8.2590e-05,\n",
            "          3.9300e-03,  4.1600e-03,  1.1790e-02,  2.1840e-02,  1.8800e-01,\n",
            "          9.6300e-03,  1.2850e-02,  2.3430e-02,  2.8880e-02,  2.9567e-02,\n",
            "          1.8387e+01,  7.1234e-01,  7.1373e-01,  3.1840e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2255e+02,  1.3050e-02,  1.2992e-04,\n",
            "          7.2700e-03,  6.0900e-03,  2.1810e-02,  3.1050e-02,  2.6800e-01,\n",
            "          1.3410e-02,  1.6790e-02,  3.0880e-02,  4.0220e-02,  6.4884e-02,\n",
            "          1.6942e+01,  7.0349e-01,  7.1779e-01,  3.9519e-01]])\n",
            "expected: tensor([[28.2260],\n",
            "        [28.5400],\n",
            "        [28.8560],\n",
            "        [29.1650],\n",
            "        [29.4820],\n",
            "        [29.7970],\n",
            "        [29.2910],\n",
            "        [28.7120],\n",
            "        [28.0700],\n",
            "        [27.4550],\n",
            "        [26.8430],\n",
            "        [26.2180],\n",
            "        [25.6040],\n",
            "        [24.9860],\n",
            "        [24.3700],\n",
            "        [23.9170],\n",
            "        [23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2320],\n",
            "        [21.6980],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800]])\n",
            "prediction tensor([[27.3314],\n",
            "        [27.3778],\n",
            "        [27.3552],\n",
            "        [27.9789],\n",
            "        [27.4799],\n",
            "        [27.5898],\n",
            "        [23.7320],\n",
            "        [24.3516],\n",
            "        [24.6382],\n",
            "        [24.7970],\n",
            "        [24.3911],\n",
            "        [24.5722],\n",
            "        [25.2483],\n",
            "        [24.9937],\n",
            "        [24.2423],\n",
            "        [25.0126],\n",
            "        [24.7887],\n",
            "        [24.8324],\n",
            "        [25.3570],\n",
            "        [25.2493],\n",
            "        [24.8281],\n",
            "        [24.8920],\n",
            "        [24.8147],\n",
            "        [24.7703],\n",
            "        [24.5722]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(6.6409, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[ 5.9000e+01,  0.0000e+00,  1.2953e+02,  1.0670e-02,  1.0302e-04,\n",
            "          5.6200e-03,  5.5700e-03,  1.6870e-02,  3.1910e-02,  2.7800e-01,\n",
            "          1.6000e-02,  1.8650e-02,  2.8800e-02,  4.8000e-02,  6.0053e-02,\n",
            "          1.5219e+01,  6.9005e-01,  7.1216e-01,  3.8172e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.3668e+02,  6.3700e-03,  6.2740e-05,\n",
            "          2.9300e-03,  3.5300e-03,  8.7800e-03,  1.4850e-02,  1.3000e-01,\n",
            "          7.2100e-03,  8.9700e-03,  1.4930e-02,  2.1640e-02,  2.1778e-02,\n",
            "          2.1253e+01,  6.3085e-01,  7.1133e-01,  2.7853e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.4361e+02,  6.0500e-03,  5.8030e-05,\n",
            "          2.4700e-03,  3.3600e-03,  7.4000e-03,  1.7850e-02,  1.5400e-01,\n",
            "          9.1900e-03,  9.8800e-03,  1.4770e-02,  2.7570e-02,  2.8140e-02,\n",
            "          1.7727e+01,  7.1621e-01,  7.1389e-01,  2.7372e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5765e+02,  3.6800e-03,  3.3920e-05,\n",
            "          1.7800e-03,  2.1700e-03,  5.3400e-03,  1.9480e-02,  1.6900e-01,\n",
            "          9.2300e-03,  1.0900e-02,  1.9980e-02,  2.7690e-02,  1.7756e-02,\n",
            "          2.0306e+01,  6.6149e-01,  7.3386e-01,  1.5305e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.6459e+02,  1.0400e-02,  1.1281e-04,\n",
            "          4.3200e-03,  4.5200e-03,  1.2960e-02,  1.7850e-02,  1.5600e-01,\n",
            "          9.1900e-03,  1.0580e-02,  1.5780e-02,  2.7570e-02,  5.1741e-02,\n",
            "          1.7526e+01,  7.2222e-01,  7.0438e-01,  3.1882e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7152e+02,  1.0450e-02,  1.1336e-04,\n",
            "          5.1600e-03,  5.0100e-03,  1.5470e-02,  3.2950e-02,  2.8400e-01,\n",
            "          1.8000e-02,  1.7430e-02,  2.7900e-02,  5.4000e-02,  5.1752e-02,\n",
            "          1.6123e+01,  7.0953e-01,  7.2425e-01,  3.7943e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7867e+02,  4.0300e-03,  4.1090e-05,\n",
            "          1.6900e-03,  2.1900e-03,  5.0800e-03,  1.8990e-02,  1.6500e-01,\n",
            "          8.6200e-03,  1.1560e-02,  2.0450e-02,  2.5860e-02,  1.5317e-02,\n",
            "          2.0409e+01,  6.7855e-01,  7.3146e-01,  2.1898e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00, -3.3118e+00,  2.2500e-03,  1.8020e-05,\n",
            "          1.0800e-03,  1.3900e-03,  3.2400e-03,  1.4820e-02,  1.2600e-01,\n",
            "          7.5000e-03,  8.7600e-03,  1.3880e-02,  2.2490e-02,  4.8390e-03,\n",
            "          2.4733e+01,  5.4671e-01,  6.6910e-01,  1.1849e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.2750e+00,  3.6600e-03,  3.3060e-05,\n",
            "          1.8000e-03,  2.0100e-03,  5.4100e-03,  1.4440e-02,  1.2000e-01,\n",
            "          5.3500e-03,  7.8900e-03,  1.6620e-02,  1.6060e-02,  9.2470e-03,\n",
            "          2.4820e+01,  6.8394e-01,  7.3623e-01,  1.7273e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0582e+01,  2.6400e-03,  2.3200e-05,\n",
            "          1.1200e-03,  1.4100e-03,  3.3600e-03,  1.4390e-02,  1.2400e-01,\n",
            "          5.9900e-03,  8.0400e-03,  1.4830e-02,  1.7980e-02,  4.8560e-03,\n",
            "          2.5378e+01,  6.0707e-01,  7.0337e-01,  1.1719e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7577e+01,  4.7400e-03,  4.8380e-05,\n",
            "          2.2600e-03,  2.0200e-03,  6.7900e-03,  1.3430e-02,  1.1400e-01,\n",
            "          5.3300e-03,  6.6500e-03,  1.3210e-02,  1.5980e-02,  1.3352e-02,\n",
            "          2.2340e+01,  6.8939e-01,  7.6058e-01,  1.9174e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  2.4541e+01,  3.7000e-03,  3.6120e-05,\n",
            "          1.9300e-03,  2.2300e-03,  5.8000e-03,  1.5230e-02,  1.3000e-01,\n",
            "          6.7600e-03,  8.9300e-03,  1.6960e-02,  2.0280e-02,  1.1591e-02,\n",
            "          2.2553e+01,  5.6461e-01,  7.7353e-01,  2.1633e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.1644e+01,  6.1900e-03,  6.6880e-05,\n",
            "          2.9000e-03,  3.3800e-03,  8.6900e-03,  2.2220e-02,  1.9200e-01,\n",
            "          9.9700e-03,  1.2970e-02,  2.3320e-02,  2.9920e-02,  2.0270e-02,\n",
            "          1.9893e+01,  6.2018e-01,  7.7106e-01,  3.0035e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.8626e+01,  3.9700e-03,  3.8180e-05,\n",
            "          1.7500e-03,  2.1500e-03,  5.2500e-03,  1.5760e-02,  1.3700e-01,\n",
            "          6.2500e-03,  8.7700e-03,  1.6850e-02,  1.8750e-02,  5.3660e-03,\n",
            "          2.4702e+01,  6.2164e-01,  7.5457e-01,  2.1324e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  4.5662e+01,  6.4100e-03,  6.8670e-05,\n",
            "          3.0900e-03,  3.2800e-03,  9.2600e-03,  2.1580e-02,  2.0100e-01,\n",
            "          6.6800e-03,  9.7600e-03,  2.2730e-02,  2.0040e-02,  2.4135e-02,\n",
            "          2.0211e+01,  6.3855e-01,  7.7352e-01,  2.6871e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.2665e+01,  3.7700e-03,  3.6480e-05,\n",
            "          1.5800e-03,  2.0600e-03,  4.7400e-03,  2.0060e-02,  1.7400e-01,\n",
            "          1.0580e-02,  1.1640e-02,  1.5800e-02,  3.1740e-02,  2.2424e-02,\n",
            "          2.3638e+01,  6.8795e-01,  7.0293e-01,  1.7935e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.7822e+01,  5.2200e-03,  5.2010e-05,\n",
            "          2.2600e-03,  2.6300e-03,  6.7700e-03,  1.6870e-02,  1.4600e-01,\n",
            "          6.2200e-03,  9.9400e-03,  2.0500e-02,  1.8670e-02,  1.9254e-02,\n",
            "          2.2008e+01,  6.6358e-01,  7.6132e-01,  2.0585e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  6.6658e+01,  4.1200e-03,  4.1600e-05,\n",
            "          1.6200e-03,  2.2400e-03,  4.8500e-03,  1.3460e-02,  1.1600e-01,\n",
            "          5.1200e-03,  7.6000e-03,  1.7510e-02,  1.5370e-02,  9.5500e-03,\n",
            "          2.3770e+01,  6.7019e-01,  7.3723e-01,  1.9654e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  7.3651e+01,  7.9500e-03,  8.8770e-05,\n",
            "          3.4400e-03,  3.7400e-03,  1.0310e-02,  2.4380e-02,  2.1900e-01,\n",
            "          1.2550e-02,  1.2840e-02,  1.9350e-02,  3.7650e-02,  3.8581e-02,\n",
            "          1.7454e+01,  6.1853e-01,  7.5568e-01,  2.6588e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.0600e+01,  4.5800e-03,  4.4350e-05,\n",
            "          1.7900e-03,  2.2300e-03,  5.3700e-03,  1.3620e-02,  1.2200e-01,\n",
            "          5.9000e-03,  7.3200e-03,  1.3620e-02,  1.7690e-02,  1.1025e-02,\n",
            "          2.5485e+01,  6.3980e-01,  7.4341e-01,  1.7409e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.7584e+01,  4.3400e-03,  4.5750e-05,\n",
            "          1.7300e-03,  2.3700e-03,  5.1900e-03,  1.2060e-02,  1.0500e-01,\n",
            "          4.3100e-03,  6.5300e-03,  1.5540e-02,  1.2940e-02,  1.3210e-02,\n",
            "          2.0851e+01,  6.5072e-01,  7.5381e-01,  2.0788e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  9.4526e+01,  6.2700e-03,  6.2480e-05,\n",
            "          2.9000e-03,  3.4100e-03,  8.6900e-03,  2.3740e-02,  2.0400e-01,\n",
            "          8.9700e-03,  1.2490e-02,  2.6260e-02,  2.6920e-02,  1.0699e-02,\n",
            "          2.3305e+01,  6.0083e-01,  7.6327e-01,  2.6691e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0159e+02,  5.6500e-03,  5.4710e-05,\n",
            "          2.2800e-03,  3.0400e-03,  6.8300e-03,  1.2650e-02,  1.1000e-01,\n",
            "          4.9700e-03,  7.0100e-03,  1.4740e-02,  1.4910e-02,  1.6469e-02,\n",
            "          2.2473e+01,  6.6255e-01,  7.3961e-01,  2.5142e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0854e+02,  5.8100e-03,  6.0460e-05,\n",
            "          2.7300e-03,  3.3800e-03,  8.1900e-03,  1.9270e-02,  1.6800e-01,\n",
            "          7.5300e-03,  1.0090e-02,  1.9290e-02,  2.2600e-02,  2.1323e-02,\n",
            "          1.9160e+01,  6.0075e-01,  7.6154e-01,  2.9850e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.1567e+02,  4.9400e-03,  4.8820e-05,\n",
            "          2.4700e-03,  3.0300e-03,  7.4100e-03,  1.5050e-02,  1.3000e-01,\n",
            "          6.9000e-03,  9.4700e-03,  1.5790e-02,  2.0690e-02,  7.6160e-03,\n",
            "          2.3008e+01,  6.2586e-01,  7.6126e-01,  2.5699e-01]])\n",
            "expected: tensor([[23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [25.3940],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [29.2910],\n",
            "        [28.7120],\n",
            "        [28.0700],\n",
            "        [27.4550],\n",
            "        [26.8430],\n",
            "        [26.2180],\n",
            "        [25.6040],\n",
            "        [24.9860],\n",
            "        [24.3700],\n",
            "        [23.9170],\n",
            "        [23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2320],\n",
            "        [21.6980],\n",
            "        [22.1570],\n",
            "        [22.6270]])\n",
            "prediction tensor([[24.3558],\n",
            "        [25.1478],\n",
            "        [24.6957],\n",
            "        [25.0314],\n",
            "        [24.8026],\n",
            "        [24.7743],\n",
            "        [25.3225],\n",
            "        [24.6605],\n",
            "        [24.9985],\n",
            "        [25.3377],\n",
            "        [25.1703],\n",
            "        [25.3883],\n",
            "        [25.1789],\n",
            "        [25.9851],\n",
            "        [25.4457],\n",
            "        [25.9945],\n",
            "        [25.7777],\n",
            "        [26.0970],\n",
            "        [25.1046],\n",
            "        [26.2552],\n",
            "        [25.4596],\n",
            "        [25.7442],\n",
            "        [25.5145],\n",
            "        [24.9162],\n",
            "        [25.4218]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(6.6875, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[ 5.9000e+01,  0.0000e+00,  1.2255e+02,  6.8700e-03,  6.5930e-05,\n",
            "          2.2200e-03,  3.2900e-03,  6.6700e-03,  1.7770e-02,  1.6100e-01,\n",
            "          8.4200e-03,  9.4800e-03,  1.4680e-02,  2.5260e-02,  2.3496e-02,\n",
            "          2.1856e+01,  6.2551e-01,  7.0755e-01,  2.4071e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2953e+02,  3.5300e-03,  3.3040e-05,\n",
            "          1.6300e-03,  2.1100e-03,  4.8800e-03,  1.1320e-02,  9.8000e-02,\n",
            "          5.4200e-03,  6.6800e-03,  1.1730e-02,  1.6250e-02,  8.5730e-03,\n",
            "          2.1757e+01,  5.4120e-01,  7.3434e-01,  1.8270e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.3668e+02,  5.5700e-03,  5.4170e-05,\n",
            "          2.8000e-03,  2.9400e-03,  8.4100e-03,  1.2590e-02,  1.1000e-01,\n",
            "          6.3500e-03,  6.8000e-03,  1.3140e-02,  1.9040e-02,  1.8427e-02,\n",
            "          2.0543e+01,  5.9386e-01,  7.4182e-01,  2.3432e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.4361e+02,  4.4300e-03,  3.7260e-05,\n",
            "          1.8900e-03,  2.1800e-03,  5.6600e-03,  1.0440e-02,  9.1000e-02,\n",
            "          5.0400e-03,  6.2100e-03,  1.1110e-02,  1.5120e-02,  1.6158e-02,\n",
            "          2.2362e+01,  6.5506e-01,  6.9810e-01,  1.6808e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5057e+02,  5.4600e-03,  5.0470e-05,\n",
            "          2.4500e-03,  2.9500e-03,  7.3500e-03,  1.5900e-02,  1.4600e-01,\n",
            "          7.2100e-03,  8.5800e-03,  1.4370e-02,  2.1620e-02,  1.2694e-02,\n",
            "          2.3631e+01,  6.8341e-01,  7.0322e-01,  2.3630e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5765e+02,  8.1100e-03,  7.0000e-05,\n",
            "          3.8900e-03,  2.6700e-03,  1.1660e-02,  1.8820e-02,  1.7200e-01,\n",
            "          1.0020e-02,  1.0050e-02,  1.5370e-02,  3.0050e-02,  4.0527e-02,\n",
            "          1.9994e+01,  6.3135e-01,  7.3921e-01,  1.7562e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.6459e+02,  3.4900e-03,  3.6830e-05,\n",
            "          1.4100e-03,  2.1000e-03,  4.2200e-03,  1.4000e-02,  1.2200e-01,\n",
            "          5.7000e-03,  8.3900e-03,  1.7230e-02,  1.7110e-02,  1.0418e-02,\n",
            "          2.1270e+01,  6.2719e-01,  7.3030e-01,  1.6520e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7152e+02,  3.8400e-03,  3.8800e-05,\n",
            "          1.8000e-03,  2.4300e-03,  5.3900e-03,  1.2520e-02,  1.0900e-01,\n",
            "          5.6300e-03,  7.4700e-03,  1.4250e-02,  1.6900e-02,  5.5560e-03,\n",
            "          2.4410e+01,  4.9145e-01,  7.5423e-01,  1.9503e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7867e+02,  4.7600e-03,  4.9260e-05,\n",
            "          2.1000e-03,  2.4300e-03,  6.3100e-03,  1.8190e-02,  1.6900e-01,\n",
            "          7.0600e-03,  9.4500e-03,  1.8300e-02,  2.1170e-02,  2.0661e-02,\n",
            "          2.1436e+01,  6.1203e-01,  7.6420e-01,  2.2275e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00, -3.3118e+00,  3.8800e-03,  3.1210e-05,\n",
            "          2.0100e-03,  1.8300e-03,  6.0200e-03,  2.2460e-02,  2.0000e-01,\n",
            "          1.2480e-02,  1.2510e-02,  1.8690e-02,  3.7430e-02,  1.9934e-02,\n",
            "          2.2683e+01,  4.7744e-01,  6.6811e-01,  1.6363e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.2757e+00,  4.5100e-03,  4.1280e-05,\n",
            "          1.8900e-03,  2.2100e-03,  5.6600e-03,  1.3140e-02,  1.1600e-01,\n",
            "          5.7600e-03,  6.6400e-03,  1.1660e-02,  1.7290e-02,  2.4723e-02,\n",
            "          2.4210e+01,  6.7622e-01,  7.4456e-01,  2.5587e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0582e+01,  2.9100e-03,  2.4410e-05,\n",
            "          1.2900e-03,  1.6500e-03,  3.8800e-03,  1.2640e-02,  1.1100e-01,\n",
            "          5.7400e-03,  6.4300e-03,  1.0950e-02,  1.7220e-02,  4.9580e-03,\n",
            "          2.5042e+01,  5.2071e-01,  7.2757e-01,  1.3955e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7578e+01,  3.3400e-03,  3.3250e-05,\n",
            "          1.6700e-03,  1.9200e-03,  5.0200e-03,  1.5010e-02,  1.2900e-01,\n",
            "          7.1900e-03,  8.8300e-03,  1.4250e-02,  2.1570e-02,  5.5410e-03,\n",
            "          2.4307e+01,  5.4678e-01,  7.7564e-01,  1.4520e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  2.4541e+01,  3.3500e-03,  3.3110e-05,\n",
            "          1.7000e-03,  1.9800e-03,  5.1000e-03,  1.8380e-02,  1.5900e-01,\n",
            "          6.5300e-03,  1.0060e-02,  2.2860e-02,  1.9590e-02,  5.6760e-03,\n",
            "          2.3868e+01,  6.2250e-01,  7.8718e-01,  2.0395e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.1645e+01,  3.8100e-03,  4.1440e-05,\n",
            "          1.8100e-03,  2.2000e-03,  5.4400e-03,  1.5950e-02,  1.3700e-01,\n",
            "          6.3300e-03,  8.7700e-03,  1.9880e-02,  1.8980e-02,  1.2294e-02,\n",
            "          2.0501e+01,  6.2278e-01,  7.6926e-01,  1.7295e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.8626e+01,  4.1100e-03,  4.0870e-05,\n",
            "          2.0200e-03,  2.3800e-03,  6.0700e-03,  1.4500e-02,  1.2600e-01,\n",
            "          6.0600e-03,  8.0100e-03,  1.5010e-02,  1.8170e-02,  7.1070e-03,\n",
            "          2.3330e+01,  5.3889e-01,  7.6720e-01,  1.8967e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  4.5663e+01,  3.3900e-03,  3.6550e-05,\n",
            "          1.4700e-03,  1.9700e-03,  4.4200e-03,  1.3360e-02,  1.1600e-01,\n",
            "          5.4100e-03,  7.5500e-03,  1.5000e-02,  1.6230e-02,  1.1470e-02,\n",
            "          2.0722e+01,  5.7440e-01,  7.6718e-01,  1.9346e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.2666e+01,  5.1400e-03,  4.9530e-05,\n",
            "          2.5000e-03,  2.1900e-03,  7.5000e-03,  1.5870e-02,  1.4400e-01,\n",
            "          6.0300e-03,  7.7600e-03,  1.7190e-02,  1.8080e-02,  9.3090e-03,\n",
            "          2.6143e+01,  6.0651e-01,  7.5145e-01,  2.6845e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.7822e+01,  4.3700e-03,  4.2310e-05,\n",
            "          1.9900e-03,  2.3400e-03,  5.9700e-03,  1.6070e-02,  1.4200e-01,\n",
            "          7.2000e-03,  9.4900e-03,  1.7010e-02,  2.1600e-02,  2.0415e-02,\n",
            "          2.0716e+01,  6.1693e-01,  7.5845e-01,  2.2243e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  6.6659e+01,  5.0800e-03,  4.9410e-05,\n",
            "          2.3200e-03,  2.9700e-03,  6.9700e-03,  1.8120e-02,  1.6000e-01,\n",
            "          6.4600e-03,  8.4700e-03,  1.9430e-02,  1.9390e-02,  2.2593e-02,\n",
            "          2.2381e+01,  6.8963e-01,  7.4572e-01,  2.1752e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  7.3651e+01,  6.8900e-03,  7.4810e-05,\n",
            "          3.1200e-03,  2.9800e-03,  9.3700e-03,  1.7880e-02,  1.5200e-01,\n",
            "          8.6500e-03,  9.1300e-03,  1.7140e-02,  2.5950e-02,  3.1445e-02,\n",
            "          1.9335e+01,  6.5385e-01,  7.5914e-01,  2.5015e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.0600e+01,  4.4900e-03,  4.3030e-05,\n",
            "          1.9200e-03,  2.2200e-03,  5.7700e-03,  1.2000e-02,  1.1800e-01,\n",
            "          3.6300e-03,  5.3500e-03,  1.1260e-02,  1.0880e-02,  1.6584e-02,\n",
            "          2.7452e+01,  6.3161e-01,  7.4037e-01,  1.8845e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.7584e+01,  2.9300e-03,  3.0740e-05,\n",
            "          1.0800e-03,  1.6200e-03,  3.2400e-03,  1.1400e-02,  9.8000e-02,\n",
            "          4.9900e-03,  6.1700e-03,  1.1870e-02,  1.4980e-02,  9.1860e-03,\n",
            "          2.1373e+01,  5.7011e-01,  7.6440e-01,  1.5004e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  9.4526e+01,  3.3200e-03,  3.1820e-05,\n",
            "          1.3800e-03,  1.8800e-03,  4.1300e-03,  1.2930e-02,  1.1200e-01,\n",
            "          4.7300e-03,  6.6900e-03,  1.5050e-02,  1.4200e-02,  2.6110e-03,\n",
            "          2.7622e+01,  5.4830e-01,  7.5806e-01,  1.6202e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0159e+02,  4.3200e-03,  4.3400e-05,\n",
            "          1.8500e-03,  2.3400e-03,  5.5600e-03,  1.3980e-02,  1.2300e-01,\n",
            "          5.6100e-03,  7.6500e-03,  1.4730e-02,  1.6830e-02,  1.1885e-02,\n",
            "          2.2686e+01,  5.9433e-01,  7.5374e-01,  1.6416e-01]])\n",
            "expected: tensor([[23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3940],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [29.2910],\n",
            "        [28.7120],\n",
            "        [28.0700],\n",
            "        [27.4550],\n",
            "        [26.8430],\n",
            "        [26.2180],\n",
            "        [25.6040],\n",
            "        [24.9860],\n",
            "        [24.3700],\n",
            "        [23.9170],\n",
            "        [23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2320],\n",
            "        [21.6980]])\n",
            "prediction tensor([[24.0301],\n",
            "        [23.9726],\n",
            "        [23.7833],\n",
            "        [23.9832],\n",
            "        [24.1112],\n",
            "        [23.6509],\n",
            "        [23.8177],\n",
            "        [24.2117],\n",
            "        [24.0253],\n",
            "        [23.8005],\n",
            "        [24.3050],\n",
            "        [24.6367],\n",
            "        [24.7229],\n",
            "        [24.8353],\n",
            "        [24.5073],\n",
            "        [24.9895],\n",
            "        [24.6817],\n",
            "        [25.4537],\n",
            "        [24.6779],\n",
            "        [24.9341],\n",
            "        [24.4062],\n",
            "        [25.5087],\n",
            "        [24.4712],\n",
            "        [25.2995],\n",
            "        [24.4060]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(6.1131, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[ 5.9000e+01,  0.0000e+00,  1.0854e+02,  5.3200e-03,  5.6520e-05,\n",
            "          2.4100e-03,  2.8400e-03,  7.2300e-03,  1.2820e-02,  1.1300e-01,\n",
            "          5.4900e-03,  6.9900e-03,  1.3870e-02,  1.6460e-02,  1.3535e-02,\n",
            "          2.0944e+01,  6.2667e-01,  7.6034e-01,  2.6311e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.1567e+02,  5.2400e-03,  5.2230e-05,\n",
            "          2.3400e-03,  2.1600e-03,  7.0200e-03,  1.5750e-02,  1.3500e-01,\n",
            "          6.9600e-03,  9.3100e-03,  1.6280e-02,  2.0890e-02,  1.4921e-02,\n",
            "          2.3428e+01,  6.3806e-01,  7.3594e-01,  2.1013e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2255e+02,  6.8300e-03,  7.0020e-05,\n",
            "          2.9100e-03,  3.9900e-03,  8.7300e-03,  2.6030e-02,  2.4000e-01,\n",
            "          1.2910e-02,  1.3780e-02,  2.1320e-02,  3.8740e-02,  3.7982e-02,\n",
            "          1.7884e+01,  6.4546e-01,  7.3776e-01,  2.4254e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2953e+02,  4.6200e-03,  4.3520e-05,\n",
            "          2.0900e-03,  2.3600e-03,  6.2600e-03,  1.6550e-02,  1.5000e-01,\n",
            "          6.6100e-03,  8.4800e-03,  1.8420e-02,  1.9840e-02,  1.4030e-02,\n",
            "          2.2818e+01,  5.1289e-01,  7.4882e-01,  1.8141e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.3668e+02,  4.0200e-03,  3.9890e-05,\n",
            "          2.2000e-03,  2.3600e-03,  6.5900e-03,  1.5020e-02,  1.3500e-01,\n",
            "          7.2000e-03,  8.0700e-03,  1.5030e-02,  2.1610e-02,  6.5620e-03,\n",
            "          2.3734e+01,  5.4575e-01,  7.5943e-01,  1.8433e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.4361e+02,  3.8400e-03,  3.4570e-05,\n",
            "          1.8000e-03,  1.9900e-03,  5.3900e-03,  1.7380e-02,  1.5100e-01,\n",
            "          9.4400e-03,  9.8600e-03,  1.4290e-02,  2.8320e-02,  1.2797e-02,\n",
            "          2.1661e+01,  6.1565e-01,  7.1551e-01,  1.5409e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5057e+02,  5.1000e-03,  4.3980e-05,\n",
            "          2.2600e-03,  2.4600e-03,  6.7800e-03,  1.3200e-02,  1.4100e-01,\n",
            "          5.7300e-03,  7.2800e-03,  1.2990e-02,  1.7190e-02,  1.4171e-02,\n",
            "          2.4006e+01,  5.2839e-01,  7.1999e-01,  1.7880e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5765e+02,  4.3500e-03,  3.7950e-05,\n",
            "          2.0800e-03,  2.2500e-03,  6.2300e-03,  1.2260e-02,  1.0600e-01,\n",
            "          5.4600e-03,  6.6100e-03,  1.2940e-02,  1.6370e-02,  8.7350e-03,\n",
            "          2.3695e+01,  6.0103e-01,  7.3761e-01,  1.7201e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.6459e+02,  2.9300e-03,  2.6960e-05,\n",
            "          1.1900e-03,  1.7000e-03,  3.5700e-03,  1.0990e-02,  9.4000e-02,\n",
            "          5.3800e-03,  6.3300e-03,  9.9600e-03,  1.6150e-02,  4.8560e-03,\n",
            "          2.5229e+01,  6.5304e-01,  7.2648e-01,  1.6807e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7152e+02,  6.0100e-03,  6.0360e-05,\n",
            "          2.8000e-03,  2.9200e-03,  8.4000e-03,  1.5430e-02,  1.3500e-01,\n",
            "          6.7100e-03,  9.1700e-03,  1.5820e-02,  2.0120e-02,  8.3700e-03,\n",
            "          2.4687e+01,  5.4462e-01,  7.6713e-01,  2.7451e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7868e+02,  3.7700e-03,  3.8320e-05,\n",
            "          1.8400e-03,  2.2300e-03,  5.5200e-03,  1.1240e-02,  9.7000e-02,\n",
            "          4.8200e-03,  6.7500e-03,  1.2720e-02,  1.4460e-02,  6.0880e-03,\n",
            "          2.4008e+01,  5.0506e-01,  7.7542e-01,  1.7445e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00, -3.3104e+00,  6.1700e-03,  5.7660e-05,\n",
            "          3.2200e-03,  3.2800e-03,  9.6500e-03,  2.4940e-02,  2.1700e-01,\n",
            "          1.2690e-02,  1.5350e-02,  2.6940e-02,  3.8060e-02,  3.0033e-02,\n",
            "          1.8866e+01,  6.9274e-01,  6.8188e-01,  2.4324e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.2771e+00,  4.2400e-03,  4.2480e-05,\n",
            "          2.1200e-03,  2.5000e-03,  6.3500e-03,  1.6390e-02,  1.4300e-01,\n",
            "          7.8300e-03,  9.7900e-03,  1.5980e-02,  2.3480e-02,  1.1846e-02,\n",
            "          2.0027e+01,  6.2550e-01,  7.2367e-01,  2.0406e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0583e+01,  3.3200e-03,  3.1750e-05,\n",
            "          1.5400e-03,  1.9700e-03,  4.6300e-03,  1.6980e-02,  1.4800e-01,\n",
            "          8.2900e-03,  9.3500e-03,  1.6010e-02,  2.4870e-02,  1.0776e-02,\n",
            "          2.1067e+01,  6.1572e-01,  7.4975e-01,  1.9637e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7579e+01,  4.0300e-03,  4.1450e-05,\n",
            "          1.6700e-03,  2.3200e-03,  5.0100e-03,  1.5880e-02,  1.3700e-01,\n",
            "          6.5000e-03,  8.3100e-03,  1.6190e-02,  1.9500e-02,  1.3259e-02,\n",
            "          2.0675e+01,  5.9415e-01,  7.5995e-01,  2.0127e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  2.4542e+01,  6.2100e-03,  6.1390e-05,\n",
            "          3.0900e-03,  3.0800e-03,  9.2600e-03,  2.2260e-02,  1.9400e-01,\n",
            "          8.6300e-03,  1.2830e-02,  2.5950e-02,  2.5890e-02,  2.5503e-02,\n",
            "          2.0296e+01,  6.7177e-01,  7.5655e-01,  2.4518e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.1647e+01,  1.2020e-02,  1.3361e-04,\n",
            "          5.8100e-03,  3.6300e-03,  1.7430e-02,  2.3030e-02,  2.3200e-01,\n",
            "          9.1500e-03,  1.1180e-02,  2.4270e-02,  2.7450e-02,  3.4481e-02,\n",
            "          1.8946e+01,  6.7538e-01,  7.4912e-01,  2.8504e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.8627e+01,  5.1400e-03,  5.2100e-05,\n",
            "          2.1500e-03,  2.7600e-03,  6.4600e-03,  1.5370e-02,  1.3500e-01,\n",
            "          6.4500e-03,  8.1300e-03,  1.6500e-02,  1.9350e-02,  2.1206e-02,\n",
            "          2.0235e+01,  5.8788e-01,  7.4177e-01,  2.5116e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  4.5665e+01,  6.4900e-03,  7.3700e-05,\n",
            "          2.9100e-03,  3.7300e-03,  8.7400e-03,  2.4520e-02,  2.1000e-01,\n",
            "          1.0030e-02,  1.3680e-02,  2.5910e-02,  3.0090e-02,  2.2898e-02,\n",
            "          1.8842e+01,  7.1051e-01,  7.4352e-01,  3.0064e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.2667e+01,  4.0300e-03,  4.3180e-05,\n",
            "          1.6500e-03,  2.1700e-03,  4.9500e-03,  1.1250e-02,  9.7000e-02,\n",
            "          5.7200e-03,  7.2000e-03,  1.1700e-02,  1.7160e-02,  1.8590e-02,\n",
            "          2.1508e+01,  5.8345e-01,  7.4248e-01,  2.5119e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.7823e+01,  8.1900e-03,  7.6770e-05,\n",
            "          3.6700e-03,  4.3100e-03,  1.1020e-02,  2.0740e-02,  2.3700e-01,\n",
            "          7.2900e-03,  1.0340e-02,  2.3370e-02,  2.1880e-02,  3.3643e-02,\n",
            "          2.1796e+01,  5.9734e-01,  7.5113e-01,  2.0550e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  6.6660e+01,  5.1200e-03,  4.8460e-05,\n",
            "          2.2200e-03,  2.5700e-03,  6.6700e-03,  2.2030e-02,  2.0000e-01,\n",
            "          6.9200e-03,  1.0680e-02,  2.9190e-02,  2.0760e-02,  1.5395e-02,\n",
            "          2.3201e+01,  6.2636e-01,  7.2702e-01,  2.4603e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  7.3653e+01,  7.5500e-03,  8.2880e-05,\n",
            "          3.0400e-03,  2.7100e-03,  9.1100e-03,  1.3740e-02,  1.3400e-01,\n",
            "          5.4800e-03,  7.9800e-03,  1.5750e-02,  1.6440e-02,  2.8524e-02,\n",
            "          1.8879e+01,  6.8131e-01,  7.5055e-01,  2.3117e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.0602e+01,  9.3000e-03,  9.1870e-05,\n",
            "          5.0000e-03,  5.2300e-03,  1.5010e-02,  1.9570e-02,  2.2600e-01,\n",
            "          6.5100e-03,  9.7700e-03,  2.3340e-02,  1.9520e-02,  1.9516e-02,\n",
            "          2.3890e+01,  6.4220e-01,  7.3615e-01,  2.6424e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.7586e+01,  5.1600e-03,  5.4640e-05,\n",
            "          2.1600e-03,  1.9000e-03,  6.4700e-03,  1.3020e-02,  1.1400e-01,\n",
            "          5.2300e-03,  6.8700e-03,  1.3540e-02,  1.5680e-02,  2.0210e-02,\n",
            "          2.0484e+01,  6.2739e-01,  7.4116e-01,  2.0541e-01]])\n",
            "expected: tensor([[22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3940],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [29.2910],\n",
            "        [28.7120],\n",
            "        [28.0700],\n",
            "        [27.4550],\n",
            "        [26.8420],\n",
            "        [26.2180],\n",
            "        [25.6040],\n",
            "        [24.9860],\n",
            "        [24.3700],\n",
            "        [23.9170],\n",
            "        [23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000]])\n",
            "prediction tensor([[24.4573],\n",
            "        [24.7303],\n",
            "        [23.9567],\n",
            "        [24.5766],\n",
            "        [24.6644],\n",
            "        [24.3688],\n",
            "        [24.6430],\n",
            "        [24.5913],\n",
            "        [24.7981],\n",
            "        [24.7731],\n",
            "        [24.8084],\n",
            "        [23.7239],\n",
            "        [24.2200],\n",
            "        [24.5933],\n",
            "        [24.6997],\n",
            "        [24.8082],\n",
            "        [24.7229],\n",
            "        [24.9823],\n",
            "        [24.8400],\n",
            "        [25.2251],\n",
            "        [25.2578],\n",
            "        [25.4716],\n",
            "        [24.7524],\n",
            "        [25.3982],\n",
            "        [24.7598]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(5.3898, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[ 5.9000e+01,  0.0000e+00,  9.4527e+01,  3.9400e-03,  3.9720e-05,\n",
            "          1.8400e-03,  2.3900e-03,  5.5100e-03,  1.6420e-02,  1.4200e-01,\n",
            "          7.5500e-03,  9.4600e-03,  1.7960e-02,  2.2640e-02,  7.7480e-03,\n",
            "          2.2938e+01,  5.4767e-01,  7.4588e-01,  2.0242e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0159e+02,  8.4400e-03,  8.5920e-05,\n",
            "          3.0900e-03,  4.2200e-03,  9.2800e-03,  2.0190e-02,  1.8000e-01,\n",
            "          7.1100e-03,  1.0260e-02,  2.2800e-02,  2.1330e-02,  2.3418e-02,\n",
            "          2.0723e+01,  6.9898e-01,  7.4562e-01,  3.1697e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0855e+02,  5.2600e-03,  5.5980e-05,\n",
            "          2.3000e-03,  2.9000e-03,  6.8900e-03,  2.3690e-02,  2.0400e-01,\n",
            "          1.2370e-02,  1.3120e-02,  2.0430e-02,  3.7120e-02,  2.3648e-02,\n",
            "          1.9325e+01,  5.6773e-01,  7.4352e-01,  2.2210e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.1567e+02,  1.9830e-02,  2.0548e-04,\n",
            "          1.0580e-02,  9.6600e-03,  3.1730e-02,  4.6730e-02,  4.5300e-01,\n",
            "          2.3760e-02,  2.4190e-02,  3.6460e-02,  7.1270e-02,  4.6910e-02,\n",
            "          1.7120e+01,  7.3959e-01,  7.5320e-01,  4.9651e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2255e+02,  7.7900e-03,  7.5960e-05,\n",
            "          4.0300e-03,  3.8200e-03,  1.2090e-02,  2.5500e-02,  2.2500e-01,\n",
            "          1.2060e-02,  1.5020e-02,  2.6160e-02,  3.6180e-02,  4.0798e-02,\n",
            "          1.7065e+01,  6.6709e-01,  6.9774e-01,  3.2528e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2953e+02,  5.0100e-03,  4.8380e-05,\n",
            "          2.3100e-03,  2.7000e-03,  6.9300e-03,  2.4010e-02,  2.1100e-01,\n",
            "          1.2360e-02,  1.4170e-02,  2.0390e-02,  3.7070e-02,  2.3906e-02,\n",
            "          1.9311e+01,  6.6565e-01,  7.1873e-01,  2.4396e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.3668e+02,  6.2900e-03,  6.2560e-05,\n",
            "          3.2000e-03,  3.5700e-03,  9.6000e-03,  1.6020e-02,  1.3700e-01,\n",
            "          7.4700e-03,  9.8300e-03,  1.7120e-02,  2.2400e-02,  2.2685e-02,\n",
            "          1.8186e+01,  7.1677e-01,  7.2648e-01,  2.9679e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.4361e+02,  1.0040e-02,  8.2390e-05,\n",
            "          4.9500e-03,  5.5800e-03,  1.4850e-02,  3.1370e-02,  3.0300e-01,\n",
            "          1.6050e-02,  2.2590e-02,  2.8650e-02,  4.8150e-02,  6.4765e-02,\n",
            "          1.8367e+01,  6.5605e-01,  6.8978e-01,  3.4043e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5058e+02,  4.8300e-03,  4.6460e-05,\n",
            "          2.3300e-03,  1.8700e-03,  7.0000e-03,  1.2370e-02,  1.1400e-01,\n",
            "          5.3200e-03,  6.7500e-03,  1.1700e-02,  1.5970e-02,  8.2760e-03,\n",
            "          2.5965e+01,  6.8397e-01,  7.3899e-01,  1.9809e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5765e+02,  4.4300e-03,  4.1190e-05,\n",
            "          2.0500e-03,  2.5400e-03,  6.1500e-03,  1.6280e-02,  1.4100e-01,\n",
            "          6.7800e-03,  9.4700e-03,  1.8720e-02,  2.0340e-02,  1.4363e-02,\n",
            "          2.0694e+01,  5.2038e-01,  7.3640e-01,  2.3150e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.6460e+02,  5.5500e-03,  5.9810e-05,\n",
            "          2.5300e-03,  2.8700e-03,  7.6000e-03,  2.2330e-02,  1.9600e-01,\n",
            "          9.9200e-03,  1.1570e-02,  2.2480e-02,  2.9760e-02,  2.1108e-02,\n",
            "          1.9890e+01,  6.5524e-01,  7.1847e-01,  2.9946e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7152e+02,  4.8700e-03,  4.9430e-05,\n",
            "          2.1100e-03,  2.2800e-03,  6.3300e-03,  1.5530e-02,  1.3400e-01,\n",
            "          6.1000e-03,  8.3800e-03,  1.6710e-02,  1.8290e-02,  1.7049e-02,\n",
            "          2.1685e+01,  6.0503e-01,  7.5036e-01,  2.2225e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7868e+02,  4.4600e-03,  4.5150e-05,\n",
            "          1.7300e-03,  2.5500e-03,  5.1900e-03,  1.6320e-02,  1.4200e-01,\n",
            "          6.4700e-03,  9.0600e-03,  1.9370e-02,  1.9410e-02,  1.7503e-02,\n",
            "          2.0639e+01,  6.1503e-01,  7.4034e-01,  2.1153e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00, -3.3097e+00,  3.5300e-03,  2.8190e-05,\n",
            "          1.5900e-03,  1.8000e-03,  4.7800e-03,  3.9190e-02,  3.6600e-01,\n",
            "          2.0350e-02,  2.3400e-02,  2.9630e-02,  6.1050e-02,  1.6998e-02,\n",
            "          2.2557e+01,  5.3959e-01,  6.3769e-01,  1.4206e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.2778e+00,  3.5400e-03,  3.0240e-05,\n",
            "          1.6900e-03,  2.1200e-03,  5.0600e-03,  1.8310e-02,  1.5800e-01,\n",
            "          8.6600e-03,  1.0220e-02,  1.7100e-02,  2.5980e-02,  1.1534e-02,\n",
            "          2.3018e+01,  6.0393e-01,  7.0029e-01,  1.7470e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0584e+01,  4.2000e-03,  3.5380e-05,\n",
            "          2.2100e-03,  2.1000e-03,  6.6300e-03,  2.1850e-02,  1.9400e-01,\n",
            "          1.0160e-02,  1.1540e-02,  2.1610e-02,  3.0490e-02,  2.2307e-02,\n",
            "          2.1917e+01,  6.0891e-01,  6.6121e-01,  1.3675e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7579e+01,  3.0500e-03,  2.6230e-05,\n",
            "          1.4600e-03,  1.7400e-03,  4.3900e-03,  2.1680e-02,  1.9000e-01,\n",
            "          1.1880e-02,  1.3700e-02,  1.6940e-02,  3.5630e-02,  1.3200e-02,\n",
            "          2.0742e+01,  5.2119e-01,  6.7184e-01,  1.4244e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  2.4542e+01,  6.5600e-03,  6.0970e-05,\n",
            "          2.5500e-03,  2.3900e-03,  7.6500e-03,  1.7420e-02,  1.7200e-01,\n",
            "          7.0900e-03,  8.3200e-03,  1.7520e-02,  2.1260e-02,  4.5062e-02,\n",
            "          1.7999e+01,  6.6206e-01,  7.3742e-01,  1.7973e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.1647e+01,  4.0400e-03,  3.9990e-05,\n",
            "          1.9000e-03,  2.1900e-03,  5.7000e-03,  1.8030e-02,  1.5700e-01,\n",
            "          8.7600e-03,  9.9700e-03,  1.6690e-02,  2.6290e-02,  1.5325e-02,\n",
            "          2.1001e+01,  6.9538e-01,  6.9505e-01,  1.7463e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.8628e+01,  5.4000e-03,  4.7180e-05,\n",
            "          2.3500e-03,  2.9100e-03,  7.0500e-03,  2.4730e-02,  2.2100e-01,\n",
            "          1.2220e-02,  1.2850e-02,  1.9060e-02,  3.6670e-02,  2.8546e-02,\n",
            "          1.7638e+01,  6.0961e-01,  7.1385e-01,  2.3976e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  4.5665e+01,  4.8400e-03,  5.1540e-05,\n",
            "          2.0200e-03,  2.8000e-03,  6.0600e-03,  2.4940e-02,  2.1700e-01,\n",
            "          1.3320e-02,  1.5530e-02,  2.3160e-02,  3.9970e-02,  3.3333e-02,\n",
            "          1.6594e+01,  6.9692e-01,  7.0666e-01,  2.4259e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.2667e+01,  6.1300e-03,  6.2870e-05,\n",
            "          2.7900e-03,  3.1000e-03,  8.3600e-03,  2.1000e-02,  1.8500e-01,\n",
            "          1.1220e-02,  1.3300e-02,  1.7870e-02,  3.3650e-02,  3.5457e-02,\n",
            "          1.7179e+01,  7.1298e-01,  7.1812e-01,  2.2832e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.7824e+01,  7.0200e-03,  6.5200e-05,\n",
            "          3.5000e-03,  2.7300e-03,  1.0490e-02,  1.6320e-02,  1.4800e-01,\n",
            "          7.5600e-03,  9.2400e-03,  1.4810e-02,  2.2670e-02,  1.7811e-02,\n",
            "          2.1398e+01,  5.9596e-01,  7.0973e-01,  2.1852e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  6.6661e+01,  4.5200e-03,  4.0710e-05,\n",
            "          1.9000e-03,  2.1600e-03,  5.7000e-03,  1.6490e-02,  1.4700e-01,\n",
            "          7.9600e-03,  8.8800e-03,  1.4290e-02,  2.3890e-02,  1.0969e-02,\n",
            "          2.2876e+01,  6.5359e-01,  6.8025e-01,  1.7429e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  7.3653e+01,  7.1300e-03,  7.5310e-05,\n",
            "          3.2200e-03,  4.0400e-03,  9.6500e-03,  1.7000e-02,  1.5000e-01,\n",
            "          8.5500e-03,  1.0020e-02,  1.5590e-02,  2.5640e-02,  2.1345e-02,\n",
            "          1.8903e+01,  7.2500e-01,  7.1680e-01,  2.9673e-01]])\n",
            "expected: tensor([[21.2330],\n",
            "        [21.6980],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [29.2910],\n",
            "        [28.7120],\n",
            "        [28.0700],\n",
            "        [27.4550],\n",
            "        [26.8420],\n",
            "        [26.2180],\n",
            "        [25.6040],\n",
            "        [24.9850],\n",
            "        [24.3700],\n",
            "        [23.9170],\n",
            "        [23.1400],\n",
            "        [22.5250]])\n",
            "prediction tensor([[25.0777],\n",
            "        [24.5966],\n",
            "        [24.2657],\n",
            "        [23.9282],\n",
            "        [23.8865],\n",
            "        [24.1458],\n",
            "        [23.9763],\n",
            "        [23.9677],\n",
            "        [24.9140],\n",
            "        [24.2281],\n",
            "        [24.2132],\n",
            "        [24.4911],\n",
            "        [24.4971],\n",
            "        [24.4917],\n",
            "        [24.8522],\n",
            "        [24.9309],\n",
            "        [24.9161],\n",
            "        [24.6990],\n",
            "        [25.1894],\n",
            "        [24.7774],\n",
            "        [24.6663],\n",
            "        [24.7229],\n",
            "        [25.3292],\n",
            "        [25.5407],\n",
            "        [24.8519]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(4.6849, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[ 5.9000e+01,  0.0000e+00,  8.0602e+01,  5.2700e-03,  4.8480e-05,\n",
            "          2.1100e-03,  2.0700e-03,  6.3300e-03,  1.5360e-02,  1.3900e-01,\n",
            "          7.1600e-03,  8.4800e-03,  1.2960e-02,  2.1470e-02,  1.7824e-02,\n",
            "          2.2529e+01,  6.1451e-01,  7.2084e-01,  2.0556e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  8.7586e+01,  3.2000e-03,  3.1380e-05,\n",
            "          1.2700e-03,  1.8200e-03,  3.8200e-03,  1.2800e-02,  1.1100e-01,\n",
            "          6.5000e-03,  7.6100e-03,  1.1760e-02,  1.9490e-02,  7.0870e-03,\n",
            "          2.3081e+01,  6.4772e-01,  7.1209e-01,  1.7394e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  9.4528e+01,  3.5100e-03,  3.3520e-05,\n",
            "          1.6400e-03,  2.0800e-03,  4.9100e-03,  1.6420e-02,  1.4400e-01,\n",
            "          8.9200e-03,  9.5000e-03,  1.4160e-02,  2.6760e-02,  6.2240e-03,\n",
            "          2.3946e+01,  5.5494e-01,  7.3780e-01,  1.7145e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0159e+02,  5.7000e-03,  5.4530e-05,\n",
            "          2.4500e-03,  2.8400e-03,  7.3500e-03,  1.7760e-02,  1.5700e-01,\n",
            "          8.4600e-03,  1.0520e-02,  1.4640e-02,  2.5370e-02,  2.0353e-02,\n",
            "          1.8882e+01,  6.5792e-01,  7.3125e-01,  2.5512e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0855e+02,  5.8800e-03,  6.1540e-05,\n",
            "          2.6300e-03,  3.3800e-03,  7.9000e-03,  2.3420e-02,  2.0300e-01,\n",
            "          1.1560e-02,  1.3400e-02,  2.5080e-02,  3.4670e-02,  1.6259e-02,\n",
            "          2.0099e+01,  7.1954e-01,  7.3604e-01,  2.8325e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.1567e+02,  5.9900e-03,  5.8750e-05,\n",
            "          2.3300e-03,  3.3600e-03,  6.9900e-03,  1.5190e-02,  1.3300e-01,\n",
            "          6.8800e-03,  8.2800e-03,  1.5660e-02,  2.0640e-02,  2.0056e-02,\n",
            "          2.0741e+01,  6.5292e-01,  7.1798e-01,  2.6799e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2255e+02,  5.5700e-03,  5.1890e-05,\n",
            "          2.6500e-03,  2.9400e-03,  7.9600e-03,  1.9020e-02,  1.7000e-01,\n",
            "          9.7700e-03,  1.2100e-02,  1.9050e-02,  2.9310e-02,  3.9428e-02,\n",
            "          1.7154e+01,  7.2162e-01,  6.8865e-01,  3.0327e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.2953e+02,  6.1600e-03,  5.7270e-05,\n",
            "          2.7100e-03,  3.1600e-03,  8.1400e-03,  1.8010e-02,  1.5800e-01,\n",
            "          8.1700e-03,  1.0190e-02,  1.7420e-02,  2.4520e-02,  1.8016e-02,\n",
            "          2.0349e+01,  7.0713e-01,  7.2635e-01,  2.8498e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.3668e+02,  5.5100e-03,  5.2700e-05,\n",
            "          2.7300e-03,  3.1500e-03,  8.2000e-03,  1.9680e-02,  1.7800e-01,\n",
            "          8.5200e-03,  1.0930e-02,  1.7660e-02,  2.5560e-02,  1.8959e-02,\n",
            "          2.0041e+01,  6.6710e-01,  7.2209e-01,  2.5591e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.4361e+02,  4.5600e-03,  3.8390e-05,\n",
            "          2.1600e-03,  2.4000e-03,  6.4800e-03,  1.8400e-02,  1.5700e-01,\n",
            "          8.6300e-03,  1.0320e-02,  1.6690e-02,  2.5890e-02,  2.0863e-02,\n",
            "          2.1428e+01,  6.7290e-01,  6.9836e-01,  2.3114e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5058e+02,  5.7300e-03,  5.4120e-05,\n",
            "          2.5800e-03,  3.0000e-03,  7.7400e-03,  1.6020e-02,  1.4200e-01,\n",
            "          7.8800e-03,  9.6200e-03,  1.4040e-02,  2.3640e-02,  1.7752e-02,\n",
            "          1.9871e+01,  6.5541e-01,  7.3012e-01,  2.6461e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.5765e+02,  4.8900e-03,  4.3200e-05,\n",
            "          2.6400e-03,  2.6900e-03,  7.9300e-03,  2.3650e-02,  2.0600e-01,\n",
            "          1.2580e-02,  1.5370e-02,  2.2760e-02,  3.7750e-02,  2.4440e-02,\n",
            "          1.7195e+01,  6.5945e-01,  7.2647e-01,  2.0725e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.6460e+02,  6.2700e-03,  5.9440e-05,\n",
            "          2.8800e-03,  2.6900e-03,  8.6300e-03,  1.9610e-02,  1.6900e-01,\n",
            "          9.4600e-03,  1.0480e-02,  1.7400e-02,  2.8370e-02,  3.2149e-02,\n",
            "          1.8991e+01,  6.3843e-01,  6.9985e-01,  3.1426e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7152e+02,  5.6100e-03,  5.3390e-05,\n",
            "          2.1000e-03,  2.4700e-03,  6.3000e-03,  1.5530e-02,  1.3500e-01,\n",
            "          6.5600e-03,  9.0500e-03,  1.5550e-02,  1.9680e-02,  1.2520e-02,\n",
            "          2.3317e+01,  6.5474e-01,  7.3630e-01,  2.0163e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7868e+02,  4.2600e-03,  3.7870e-05,\n",
            "          1.8300e-03,  1.9100e-03,  5.4900e-03,  1.4240e-02,  1.2200e-01,\n",
            "          6.4200e-03,  7.5800e-03,  1.1870e-02,  1.9260e-02,  1.5640e-02,\n",
            "          2.3179e+01,  6.4703e-01,  7.0442e-01,  2.5561e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00, -3.3097e+00,  2.6600e-03,  1.8740e-05,\n",
            "          1.3400e-03,  1.5800e-03,  4.0300e-03,  3.4040e-02,  3.1400e-01,\n",
            "          1.7760e-02,  1.9850e-02,  2.5860e-02,  5.3280e-02,  1.1116e-02,\n",
            "          2.4287e+01,  5.3466e-01,  6.0263e-01,  1.4682e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.2778e+00,  2.3200e-03,  1.7560e-05,\n",
            "          9.3000e-04,  1.2300e-03,  2.7900e-03,  1.7810e-02,  1.4600e-01,\n",
            "          8.6300e-03,  1.0530e-02,  1.5250e-02,  2.5880e-02,  4.9300e-03,\n",
            "          2.5723e+01,  5.8038e-01,  6.5096e-01,  1.2731e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.0585e+01,  4.4500e-03,  3.4360e-05,\n",
            "          2.3500e-03,  1.9600e-03,  7.0500e-03,  2.1430e-02,  1.9100e-01,\n",
            "          1.1500e-02,  1.1300e-02,  1.4600e-02,  3.4500e-02,  2.0209e-02,\n",
            "          2.2503e+01,  5.1994e-01,  6.3597e-01,  1.6143e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  1.7580e+01,  3.9500e-03,  3.0350e-05,\n",
            "          1.6700e-03,  1.5700e-03,  5.0000e-03,  1.8070e-02,  1.5800e-01,\n",
            "          7.8200e-03,  9.6500e-03,  1.5050e-02,  2.3470e-02,  2.3300e-02,\n",
            "          2.1215e+01,  6.4070e-01,  6.5228e-01,  1.9218e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  2.4543e+01,  3.7600e-03,  3.2780e-05,\n",
            "          1.8000e-03,  2.1800e-03,  5.3900e-03,  2.3000e-02,  2.0700e-01,\n",
            "          1.1710e-02,  1.3550e-02,  1.8250e-02,  3.5130e-02,  2.5435e-02,\n",
            "          1.9189e+01,  6.5015e-01,  6.9931e-01,  1.7607e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.1648e+01,  2.8400e-03,  2.4010e-05,\n",
            "          1.2800e-03,  1.6700e-03,  3.8500e-03,  3.1620e-02,  2.7100e-01,\n",
            "          1.6560e-02,  1.9290e-02,  2.5690e-02,  4.9670e-02,  1.0208e-02,\n",
            "          2.1914e+01,  6.2470e-01,  6.4482e-01,  1.4782e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  3.8628e+01,  3.7700e-03,  3.3430e-05,\n",
            "          1.5500e-03,  1.9800e-03,  4.6600e-03,  1.8500e-02,  1.6000e-01,\n",
            "          9.3200e-03,  1.0420e-02,  1.6160e-02,  2.7960e-02,  1.2449e-02,\n",
            "          2.0982e+01,  6.1047e-01,  6.8934e-01,  1.7419e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  4.5666e+01,  5.5200e-03,  5.3110e-05,\n",
            "          2.1200e-03,  2.5100e-03,  6.3700e-03,  2.7020e-02,  2.3500e-01,\n",
            "          1.3380e-02,  1.6820e-02,  2.7690e-02,  4.0130e-02,  1.9541e-02,\n",
            "          1.9567e+01,  6.9461e-01,  6.8915e-01,  2.2106e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.2668e+01,  5.3600e-03,  5.3120e-05,\n",
            "          2.1300e-03,  2.9500e-03,  6.3800e-03,  1.8410e-02,  1.6300e-01,\n",
            "          8.0100e-03,  1.0190e-02,  1.7390e-02,  2.4020e-02,  2.0834e-02,\n",
            "          1.9402e+01,  7.2329e-01,  7.0813e-01,  2.4521e-01],\n",
            "        [ 5.9000e+01,  0.0000e+00,  5.7824e+01,  4.4500e-03,  3.7320e-05,\n",
            "          2.2300e-03,  2.2900e-03,  6.7000e-03,  1.6380e-02,  1.4300e-01,\n",
            "          8.9400e-03,  9.6200e-03,  1.3650e-02,  2.6820e-02,  1.6109e-02,\n",
            "          2.2964e+01,  5.5525e-01,  6.9413e-01,  1.8019e-01]])\n",
            "expected: tensor([[21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6980],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [29.2910],\n",
            "        [28.7120],\n",
            "        [28.0690],\n",
            "        [27.4550],\n",
            "        [26.8420],\n",
            "        [26.2180],\n",
            "        [25.6040],\n",
            "        [24.9850],\n",
            "        [24.3700],\n",
            "        [23.9170]])\n",
            "prediction tensor([[25.5720],\n",
            "        [25.5259],\n",
            "        [25.5200],\n",
            "        [24.5876],\n",
            "        [24.6578],\n",
            "        [24.6959],\n",
            "        [24.1743],\n",
            "        [24.5645],\n",
            "        [24.4884],\n",
            "        [24.6406],\n",
            "        [24.4208],\n",
            "        [24.1708],\n",
            "        [24.4219],\n",
            "        [24.9582],\n",
            "        [25.0489],\n",
            "        [25.1025],\n",
            "        [25.5607],\n",
            "        [25.3582],\n",
            "        [25.3316],\n",
            "        [25.1935],\n",
            "        [25.6446],\n",
            "        [25.5900],\n",
            "        [25.4133],\n",
            "        [25.3654],\n",
            "        [25.8756]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(5.0807, grad_fn=<MseLossBackward>)\n",
            "x: tensor([[5.9000e+01, 0.0000e+00, 6.6661e+01, 5.4700e-03, 4.7940e-05, 1.7100e-03,\n",
            "         2.3800e-03, 5.1400e-03, 1.8660e-02, 1.6400e-01, 9.3700e-03, 9.6000e-03,\n",
            "         1.3720e-02, 2.8120e-02, 1.5524e-02, 2.1410e+01, 7.0355e-01, 6.8991e-01,\n",
            "         2.0356e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 7.3654e+01, 5.6500e-03, 5.6670e-05, 1.9000e-03,\n",
            "         2.9400e-03, 5.7000e-03, 1.2300e-02, 1.0800e-01, 5.4300e-03, 7.1100e-03,\n",
            "         1.2590e-02, 1.6290e-02, 1.8622e-02, 2.2047e+01, 7.0303e-01, 7.0495e-01,\n",
            "         2.2503e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 8.0603e+01, 3.0000e-03, 2.5480e-05, 1.2600e-03,\n",
            "         1.7100e-03, 3.7800e-03, 1.5720e-02, 1.3600e-01, 8.1600e-03, 9.4200e-03,\n",
            "         1.2290e-02, 2.4490e-02, 9.7920e-03, 2.1647e+01, 6.5861e-01, 6.7650e-01,\n",
            "         1.4428e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 8.7587e+01, 5.9900e-03, 5.6540e-05, 2.7300e-03,\n",
            "         2.9100e-03, 8.1800e-03, 1.8770e-02, 2.2100e-01, 8.5400e-03, 1.1850e-02,\n",
            "         1.7190e-02, 2.5610e-02, 2.4505e-02, 2.1852e+01, 7.0375e-01, 6.9900e-01,\n",
            "         2.4886e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 9.4528e+01, 3.7300e-03, 3.2260e-05, 1.9100e-03,\n",
            "         2.0200e-03, 5.7400e-03, 1.9980e-02, 1.7800e-01, 1.1180e-02, 1.1320e-02,\n",
            "         1.4520e-02, 3.3550e-02, 8.5530e-03, 2.2510e+01, 6.0771e-01, 6.9142e-01,\n",
            "         1.4241e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.0159e+02, 5.1900e-03, 4.6770e-05, 2.2100e-03,\n",
            "         2.9700e-03, 6.6200e-03, 1.7600e-02, 1.5500e-01, 9.4300e-03, 1.0290e-02,\n",
            "         1.4820e-02, 2.8290e-02, 2.3934e-02, 1.8847e+01, 6.9347e-01, 7.1936e-01,\n",
            "         2.3256e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.0855e+02, 8.7300e-03, 8.6300e-05, 2.4400e-03,\n",
            "         4.2500e-03, 7.3200e-03, 1.9580e-02, 1.7800e-01, 9.5000e-03, 1.1620e-02,\n",
            "         1.8230e-02, 2.8500e-02, 2.8437e-02, 1.8409e+01, 7.5064e-01, 7.0893e-01,\n",
            "         3.0609e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.1567e+02, 7.5600e-03, 7.2550e-05, 2.5800e-03,\n",
            "         3.9100e-03, 7.7500e-03, 1.8200e-02, 1.6400e-01, 8.6400e-03, 1.0900e-02,\n",
            "         1.8030e-02, 2.5930e-02, 2.6156e-02, 1.9978e+01, 7.0959e-01, 7.1244e-01,\n",
            "         3.0167e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.2255e+02, 5.8500e-03, 5.1000e-05, 2.4600e-03,\n",
            "         2.6700e-03, 7.3700e-03, 2.7070e-02, 2.3600e-01, 1.4840e-02, 1.5510e-02,\n",
            "         2.3170e-02, 4.4520e-02, 2.8849e-02, 1.8370e+01, 6.4327e-01, 6.7311e-01,\n",
            "         2.7541e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.2953e+02, 3.5900e-03, 2.8790e-05, 1.5400e-03,\n",
            "         2.0100e-03, 4.6100e-03, 2.9500e-02, 2.5500e-01, 1.6090e-02, 1.8920e-02,\n",
            "         2.4060e-02, 4.8260e-02, 2.2148e-02, 1.7790e+01, 6.1806e-01, 6.7793e-01,\n",
            "         1.7885e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.3668e+02, 4.8500e-03, 4.4940e-05, 1.9000e-03,\n",
            "         2.9200e-03, 5.6900e-03, 1.9380e-02, 1.7200e-01, 9.6600e-03, 1.1050e-02,\n",
            "         1.6660e-02, 2.8990e-02, 2.2546e-02, 1.8070e+01, 6.9038e-01, 7.2021e-01,\n",
            "         2.4436e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.4362e+02, 3.7400e-03, 2.9410e-05, 1.4000e-03,\n",
            "         1.8200e-03, 4.1900e-03, 2.1070e-02, 1.8400e-01, 1.0610e-02, 1.3450e-02,\n",
            "         2.0710e-02, 3.1830e-02, 1.8116e-02, 1.9444e+01, 6.6824e-01, 6.8491e-01,\n",
            "         1.9140e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.5058e+02, 3.2100e-03, 2.6930e-05, 1.3500e-03,\n",
            "         1.7900e-03, 4.0500e-03, 1.0860e-02, 9.4000e-02, 4.5200e-03, 5.6900e-03,\n",
            "         1.0300e-02, 1.3560e-02, 8.2530e-03, 2.3418e+01, 6.2234e-01, 7.0035e-01,\n",
            "         1.5338e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.5765e+02, 4.8300e-03, 4.0900e-05, 2.4500e-03,\n",
            "         2.3100e-03, 7.3400e-03, 1.4220e-02, 1.2600e-01, 6.5500e-03, 8.2100e-03,\n",
            "         1.3840e-02, 1.9650e-02, 2.0072e-02, 2.2098e+01, 6.1753e-01, 7.0599e-01,\n",
            "         2.6018e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.6460e+02, 4.9400e-03, 4.6360e-05, 2.2300e-03,\n",
            "         2.0100e-03, 6.7000e-03, 1.8720e-02, 1.6600e-01, 1.0160e-02, 9.4400e-03,\n",
            "         1.3940e-02, 3.0480e-02, 2.8051e-02, 2.1483e+01, 6.2971e-01, 6.8422e-01,\n",
            "         1.7127e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.7152e+02, 5.9500e-03, 5.1570e-05, 2.9700e-03,\n",
            "         3.1500e-03, 8.9100e-03, 3.6840e-02, 3.3900e-01, 1.8460e-02, 2.3810e-02,\n",
            "         3.0220e-02, 5.5380e-02, 2.4870e-02, 2.0254e+01, 6.1237e-01, 7.4212e-01,\n",
            "         2.5331e-01],\n",
            "        [5.9000e+01, 0.0000e+00, 1.7868e+02, 4.4800e-03, 4.1730e-05, 1.8100e-03,\n",
            "         2.0900e-03, 5.4400e-03, 1.4230e-02, 1.2400e-01, 7.4700e-03, 8.5400e-03,\n",
            "         1.2870e-02, 2.2400e-02, 8.9220e-03, 2.3815e+01, 6.9882e-01, 7.2342e-01,\n",
            "         1.8301e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 6.4403e+00, 5.1200e-03, 3.3280e-05, 1.8600e-03,\n",
            "         2.4400e-03, 5.5800e-03, 2.6400e-02, 2.6300e-01, 1.2510e-02, 1.5700e-02,\n",
            "         2.1840e-02, 3.7540e-02, 1.1883e-02, 2.1893e+01, 4.6061e-01, 7.3700e-01,\n",
            "         2.7803e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 1.3419e+01, 4.7000e-03, 2.8410e-05, 2.2500e-03,\n",
            "         2.6900e-03, 6.7400e-03, 3.7230e-02, 3.4600e-01, 1.8340e-02, 2.2800e-02,\n",
            "         3.3860e-02, 5.5010e-02, 1.1965e-02, 2.2070e+01, 4.8570e-01, 7.0976e-01,\n",
            "         2.3407e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 2.0426e+01, 1.5570e-02, 8.5990e-05, 7.6000e-03,\n",
            "         9.3400e-03, 2.2810e-02, 9.2770e-02, 9.5700e-01, 4.4930e-02, 6.1170e-02,\n",
            "         9.3150e-02, 1.3478e-01, 4.7830e-02, 1.5564e+01, 6.5589e-01, 7.4151e-01,\n",
            "         5.1206e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 2.7442e+01, 7.0300e-03, 4.7490e-05, 3.3700e-03,\n",
            "         3.9200e-03, 1.0100e-02, 3.9810e-02, 3.5000e-01, 1.9300e-02, 2.2440e-02,\n",
            "         3.6510e-02, 5.7900e-02, 2.0758e-02, 1.9030e+01, 5.1885e-01, 7.9579e-01,\n",
            "         2.9903e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 3.4420e+01, 5.7300e-03, 4.1770e-05, 2.6100e-03,\n",
            "         3.4200e-03, 7.8200e-03, 3.3790e-02, 3.1900e-01, 1.4830e-02, 2.0140e-02,\n",
            "         3.1610e-02, 4.4480e-02, 1.5681e-02, 2.1686e+01, 5.6657e-01, 7.4196e-01,\n",
            "         2.7543e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 4.1460e+01, 7.2800e-03, 5.3330e-05, 2.8400e-03,\n",
            "         3.8100e-03, 8.5300e-03, 2.9960e-02, 2.7100e-01, 1.2590e-02, 1.7730e-02,\n",
            "         2.9640e-02, 3.7770e-02, 1.6838e-02, 1.9871e+01, 5.2689e-01, 7.7790e-01,\n",
            "         3.2150e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 4.8422e+01, 6.5100e-03, 4.5000e-05, 2.9600e-03,\n",
            "         3.5600e-03, 8.8800e-03, 7.4790e-02, 6.6500e-01, 3.9490e-02, 4.9160e-02,\n",
            "         5.6290e-02, 1.1846e-01, 2.8663e-02, 1.6591e+01, 5.7284e-01, 7.5259e-01,\n",
            "         2.7509e-01],\n",
            "        [7.1000e+01, 0.0000e+00, 4.8886e+01, 5.2100e-03, 3.9390e-05, 2.0600e-03,\n",
            "         2.6600e-03, 6.1800e-03, 2.9940e-02, 2.8600e-01, 1.2900e-02, 1.7570e-02,\n",
            "         3.0840e-02, 3.8690e-02, 1.0916e-02, 2.2345e+01, 5.4795e-01, 7.2784e-01,\n",
            "         2.1694e-01]])\n",
            "expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "prediction tensor([[25.1986],\n",
            "        [25.1818],\n",
            "        [24.9687],\n",
            "        [24.8436],\n",
            "        [24.7821],\n",
            "        [24.0589],\n",
            "        [23.8746],\n",
            "        [24.0384],\n",
            "        [23.7632],\n",
            "        [23.6356],\n",
            "        [23.6337],\n",
            "        [23.7648],\n",
            "        [24.2267],\n",
            "        [24.0335],\n",
            "        [24.0312],\n",
            "        [24.0030],\n",
            "        [24.4497],\n",
            "        [29.3200],\n",
            "        [29.5234],\n",
            "        [28.7215],\n",
            "        [29.3393],\n",
            "        [29.7603],\n",
            "        [29.5434],\n",
            "        [29.0745],\n",
            "        [29.9381]], grad_fn=<AddmmBackward>)\n",
            "loss: tensor(18.4010, grad_fn=<MseLossBackward>)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[32.5423],\n",
            "        [32.6323],\n",
            "        [31.8611],\n",
            "        [32.5781],\n",
            "        [32.2749],\n",
            "        [32.1550],\n",
            "        [31.2756],\n",
            "        [31.3244],\n",
            "        [31.0059],\n",
            "        [31.7649],\n",
            "        [31.0131],\n",
            "        [31.7164],\n",
            "        [31.5447],\n",
            "        [31.6762],\n",
            "        [31.4973],\n",
            "        [31.1831],\n",
            "        [31.6047],\n",
            "        [31.3197],\n",
            "        [31.7765],\n",
            "        [32.2698],\n",
            "        [32.2724],\n",
            "        [31.5327],\n",
            "        [32.4944],\n",
            "        [32.4555],\n",
            "        [32.8533]])\n",
            "test loss: tensor(17.4488)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[32.4961],\n",
            "        [32.7036],\n",
            "        [32.8866],\n",
            "        [32.6158],\n",
            "        [31.9287],\n",
            "        [32.4840],\n",
            "        [32.2883],\n",
            "        [32.1950],\n",
            "        [31.5726],\n",
            "        [31.7573],\n",
            "        [31.0959],\n",
            "        [31.5136],\n",
            "        [31.1151],\n",
            "        [31.1973],\n",
            "        [31.4724],\n",
            "        [31.1520],\n",
            "        [31.4252],\n",
            "        [31.2876],\n",
            "        [31.2537],\n",
            "        [31.5398],\n",
            "        [31.3207],\n",
            "        [31.5897],\n",
            "        [32.0959],\n",
            "        [32.5014],\n",
            "        [31.9781]])\n",
            "test loss: tensor(17.3834)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[32.5517],\n",
            "        [32.5444],\n",
            "        [32.7182],\n",
            "        [32.5513],\n",
            "        [32.6914],\n",
            "        [32.8420],\n",
            "        [32.9311],\n",
            "        [32.1745],\n",
            "        [32.3767],\n",
            "        [32.2487],\n",
            "        [32.2108],\n",
            "        [31.5181],\n",
            "        [31.6635],\n",
            "        [31.4320],\n",
            "        [31.2661],\n",
            "        [31.2876],\n",
            "        [31.4021],\n",
            "        [31.5663],\n",
            "        [31.2053],\n",
            "        [31.3264],\n",
            "        [31.2947],\n",
            "        [31.2774],\n",
            "        [31.1379],\n",
            "        [31.4161],\n",
            "        [31.5721]])\n",
            "test loss: tensor(17.0029)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[32.0885],\n",
            "        [31.7519],\n",
            "        [32.4588],\n",
            "        [32.4129],\n",
            "        [32.7311],\n",
            "        [32.6785],\n",
            "        [32.4818],\n",
            "        [32.6400],\n",
            "        [32.2510],\n",
            "        [32.3026],\n",
            "        [31.9694],\n",
            "        [32.8171],\n",
            "        [31.7649],\n",
            "        [31.6132],\n",
            "        [31.5718],\n",
            "        [31.7336],\n",
            "        [30.7541],\n",
            "        [31.0928],\n",
            "        [31.3685],\n",
            "        [31.1888],\n",
            "        [31.7680],\n",
            "        [31.6078],\n",
            "        [31.2191],\n",
            "        [31.1050],\n",
            "        [31.5342]])\n",
            "test loss: tensor(17.6390)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.6565],\n",
            "        [31.9640],\n",
            "        [31.0130],\n",
            "        [31.8748],\n",
            "        [31.4886],\n",
            "        [32.7484],\n",
            "        [32.5194],\n",
            "        [32.5807],\n",
            "        [33.1333],\n",
            "        [32.6277],\n",
            "        [32.5087],\n",
            "        [32.4806],\n",
            "        [32.5764],\n",
            "        [32.2639],\n",
            "        [32.5080],\n",
            "        [31.8954],\n",
            "        [31.9912],\n",
            "        [31.5239],\n",
            "        [31.7098],\n",
            "        [31.1603],\n",
            "        [31.3276],\n",
            "        [31.7470],\n",
            "        [31.2880],\n",
            "        [31.2689],\n",
            "        [31.2900]])\n",
            "test loss: tensor(17.8466)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.4122],\n",
            "        [31.3774],\n",
            "        [31.4814],\n",
            "        [31.6302],\n",
            "        [32.2532],\n",
            "        [31.7383],\n",
            "        [31.6228],\n",
            "        [32.1433],\n",
            "        [32.5592],\n",
            "        [32.6393],\n",
            "        [32.5330],\n",
            "        [32.9352],\n",
            "        [32.5245],\n",
            "        [32.6255],\n",
            "        [32.5710],\n",
            "        [32.7693],\n",
            "        [32.4855],\n",
            "        [32.3643],\n",
            "        [31.8244],\n",
            "        [31.8310],\n",
            "        [31.5547],\n",
            "        [31.4629],\n",
            "        [31.1594],\n",
            "        [31.2441],\n",
            "        [31.5949]])\n",
            "test loss: tensor(16.8831)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.6854],\n",
            "        [31.3173],\n",
            "        [31.2032],\n",
            "        [31.0207],\n",
            "        [31.4982],\n",
            "        [31.5928],\n",
            "        [31.5668],\n",
            "        [25.4692],\n",
            "        [25.9657],\n",
            "        [26.3739],\n",
            "        [26.4414],\n",
            "        [26.5260],\n",
            "        [27.4840],\n",
            "        [26.8751],\n",
            "        [26.9203],\n",
            "        [27.0893],\n",
            "        [26.7051],\n",
            "        [26.2864],\n",
            "        [25.9672],\n",
            "        [26.2059],\n",
            "        [26.0942],\n",
            "        [25.6379],\n",
            "        [25.6396],\n",
            "        [25.5065],\n",
            "        [26.4476]])\n",
            "test loss: tensor(12.1556)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.2732],\n",
            "        [25.9254],\n",
            "        [25.7557],\n",
            "        [26.2579],\n",
            "        [25.6574],\n",
            "        [25.8083],\n",
            "        [25.8979],\n",
            "        [25.7277],\n",
            "        [26.7698],\n",
            "        [27.2208],\n",
            "        [26.3784],\n",
            "        [26.8488],\n",
            "        [26.4927],\n",
            "        [26.2913],\n",
            "        [25.8330],\n",
            "        [26.2867],\n",
            "        [26.9071],\n",
            "        [25.5300],\n",
            "        [26.2764],\n",
            "        [25.6639],\n",
            "        [25.9481],\n",
            "        [26.6194],\n",
            "        [25.8729],\n",
            "        [26.1967],\n",
            "        [25.9175]])\n",
            "test loss: tensor(11.7833)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.1403],\n",
            "        [26.3887],\n",
            "        [25.9152],\n",
            "        [26.3477],\n",
            "        [25.8747],\n",
            "        [27.6452],\n",
            "        [26.3262],\n",
            "        [26.2752],\n",
            "        [27.8313],\n",
            "        [26.9225],\n",
            "        [25.3754],\n",
            "        [27.1024],\n",
            "        [26.0747],\n",
            "        [25.4791],\n",
            "        [25.8416],\n",
            "        [26.5753],\n",
            "        [26.0719],\n",
            "        [26.1203],\n",
            "        [25.7418],\n",
            "        [26.1250],\n",
            "        [26.4147],\n",
            "        [26.2442],\n",
            "        [26.0780],\n",
            "        [26.5605],\n",
            "        [27.2746]])\n",
            "test loss: tensor(15.2323)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[27.2661],\n",
            "        [27.5669],\n",
            "        [27.8244],\n",
            "        [26.5100],\n",
            "        [27.0589],\n",
            "        [25.9308],\n",
            "        [26.3193],\n",
            "        [27.3171],\n",
            "        [26.6651],\n",
            "        [25.7167],\n",
            "        [26.7712],\n",
            "        [26.7385],\n",
            "        [26.7957],\n",
            "        [26.0964],\n",
            "        [25.8171],\n",
            "        [27.1536],\n",
            "        [26.3711],\n",
            "        [25.7434],\n",
            "        [26.1705],\n",
            "        [26.6232],\n",
            "        [27.7831],\n",
            "        [28.2715],\n",
            "        [27.8102],\n",
            "        [27.1441],\n",
            "        [26.8758]])\n",
            "test loss: tensor(15.4261)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[27.0912],\n",
            "        [26.2567],\n",
            "        [27.0702],\n",
            "        [25.8082],\n",
            "        [26.1160],\n",
            "        [25.8603],\n",
            "        [26.0135],\n",
            "        [26.0785],\n",
            "        [26.0092],\n",
            "        [26.1456],\n",
            "        [26.2080],\n",
            "        [26.5169],\n",
            "        [26.2691],\n",
            "        [27.0612],\n",
            "        [25.9576],\n",
            "        [26.5744],\n",
            "        [27.3762],\n",
            "        [26.9817],\n",
            "        [26.6990],\n",
            "        [26.8026],\n",
            "        [27.6128],\n",
            "        [27.3467],\n",
            "        [26.5911],\n",
            "        [26.2419],\n",
            "        [27.3573]])\n",
            "test loss: tensor(12.7355)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.6577],\n",
            "        [26.8449],\n",
            "        [26.5060],\n",
            "        [26.0015],\n",
            "        [26.2704],\n",
            "        [26.4476],\n",
            "        [26.3732],\n",
            "        [26.0330],\n",
            "        [26.2744],\n",
            "        [26.5500],\n",
            "        [27.1627],\n",
            "        [25.7463],\n",
            "        [24.8696],\n",
            "        [24.6788],\n",
            "        [25.6437],\n",
            "        [26.7524],\n",
            "        [25.6380],\n",
            "        [26.6782],\n",
            "        [26.8312],\n",
            "        [26.6529],\n",
            "        [25.6933],\n",
            "        [26.2760],\n",
            "        [26.6218],\n",
            "        [26.0274],\n",
            "        [25.0416]])\n",
            "test loss: tensor(12.3234)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[25.9842],\n",
            "        [25.6043],\n",
            "        [25.5001],\n",
            "        [25.6474],\n",
            "        [25.7274],\n",
            "        [25.7052],\n",
            "        [25.6302],\n",
            "        [25.8675],\n",
            "        [25.9421],\n",
            "        [25.6729],\n",
            "        [24.2971],\n",
            "        [26.5156],\n",
            "        [25.2480],\n",
            "        [26.4654],\n",
            "        [25.7506],\n",
            "        [26.7813],\n",
            "        [27.0218],\n",
            "        [26.3496],\n",
            "        [25.4080],\n",
            "        [26.7400],\n",
            "        [26.5931],\n",
            "        [25.6412],\n",
            "        [25.2840],\n",
            "        [25.8745],\n",
            "        [25.8966]])\n",
            "test loss: tensor(57.9793)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[25.9389],\n",
            "        [25.0466],\n",
            "        [25.8564],\n",
            "        [25.6783],\n",
            "        [25.9032],\n",
            "        [25.5287],\n",
            "        [26.0411],\n",
            "        [25.6555],\n",
            "        [25.2590],\n",
            "        [24.9234],\n",
            "        [24.9628],\n",
            "        [26.4846],\n",
            "        [25.5748],\n",
            "        [26.8652],\n",
            "        [27.1035],\n",
            "        [26.9523],\n",
            "        [24.4562],\n",
            "        [26.5290],\n",
            "        [26.1197],\n",
            "        [25.8060],\n",
            "        [24.9792],\n",
            "        [26.1634],\n",
            "        [26.2298],\n",
            "        [25.3510],\n",
            "        [25.5813]])\n",
            "test loss: tensor(60.0134)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.0986],\n",
            "        [26.0304],\n",
            "        [25.9933],\n",
            "        [26.0551],\n",
            "        [26.0473],\n",
            "        [25.8916],\n",
            "        [24.7094],\n",
            "        [26.3824],\n",
            "        [25.6322],\n",
            "        [27.2338],\n",
            "        [24.3927],\n",
            "        [27.1007],\n",
            "        [27.3288],\n",
            "        [27.2103],\n",
            "        [24.3155],\n",
            "        [26.4563],\n",
            "        [26.2669],\n",
            "        [26.1894],\n",
            "        [25.6054],\n",
            "        [25.8589],\n",
            "        [26.1398],\n",
            "        [25.5292],\n",
            "        [26.0931],\n",
            "        [25.2529],\n",
            "        [25.7757]])\n",
            "test loss: tensor(59.0393)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[25.8746],\n",
            "        [25.8514],\n",
            "        [26.1470],\n",
            "        [25.9495],\n",
            "        [25.2140],\n",
            "        [26.4121],\n",
            "        [26.1487],\n",
            "        [27.1324],\n",
            "        [26.9090],\n",
            "        [27.8308],\n",
            "        [27.9041],\n",
            "        [27.1966],\n",
            "        [26.2357],\n",
            "        [27.2210],\n",
            "        [27.0922],\n",
            "        [26.6688],\n",
            "        [26.4655],\n",
            "        [26.2007],\n",
            "        [26.3303],\n",
            "        [25.8994],\n",
            "        [25.7909],\n",
            "        [25.8480],\n",
            "        [25.7792],\n",
            "        [26.0301],\n",
            "        [26.5343]])\n",
            "test loss: tensor(56.5917)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.2776],\n",
            "        [26.1488],\n",
            "        [25.7362],\n",
            "        [25.2455],\n",
            "        [26.5844],\n",
            "        [25.2567],\n",
            "        [27.3069],\n",
            "        [26.4901],\n",
            "        [27.3214],\n",
            "        [27.3908],\n",
            "        [27.2779],\n",
            "        [26.7547],\n",
            "        [27.1055],\n",
            "        [26.8947],\n",
            "        [26.6776],\n",
            "        [26.1539],\n",
            "        [26.3188],\n",
            "        [25.9328],\n",
            "        [26.0454],\n",
            "        [26.5886],\n",
            "        [25.9802],\n",
            "        [25.8051],\n",
            "        [26.1369],\n",
            "        [25.8831],\n",
            "        [25.9683]])\n",
            "test loss: tensor(52.2875)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.3139],\n",
            "        [30.7113],\n",
            "        [30.9441],\n",
            "        [31.1112],\n",
            "        [30.8776],\n",
            "        [31.1490],\n",
            "        [30.8930],\n",
            "        [30.9293],\n",
            "        [30.2030],\n",
            "        [31.5783],\n",
            "        [30.7012],\n",
            "        [31.0961],\n",
            "        [31.0630],\n",
            "        [30.7870],\n",
            "        [30.4579],\n",
            "        [29.9459],\n",
            "        [29.3538],\n",
            "        [29.7278],\n",
            "        [30.0969],\n",
            "        [30.7078],\n",
            "        [30.1399],\n",
            "        [29.9444],\n",
            "        [29.4789],\n",
            "        [29.9391],\n",
            "        [29.9447]])\n",
            "test loss: tensor(115.9029)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[29.6455],\n",
            "        [30.9673],\n",
            "        [31.2352],\n",
            "        [30.8699],\n",
            "        [30.9915],\n",
            "        [31.0471],\n",
            "        [31.3473],\n",
            "        [31.0106],\n",
            "        [30.8296],\n",
            "        [31.6738],\n",
            "        [31.3089],\n",
            "        [31.0766],\n",
            "        [30.9596],\n",
            "        [30.5265],\n",
            "        [29.8353],\n",
            "        [30.0691],\n",
            "        [29.7919],\n",
            "        [29.3404],\n",
            "        [30.0950],\n",
            "        [30.1351],\n",
            "        [30.2921],\n",
            "        [29.3548],\n",
            "        [29.9393],\n",
            "        [29.9177],\n",
            "        [29.7440]])\n",
            "test loss: tensor(115.8391)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[29.4302],\n",
            "        [30.8483],\n",
            "        [30.4717],\n",
            "        [30.9738],\n",
            "        [30.0663],\n",
            "        [31.1734],\n",
            "        [31.2684],\n",
            "        [30.3904],\n",
            "        [30.7559],\n",
            "        [31.5742],\n",
            "        [31.0369],\n",
            "        [30.7515],\n",
            "        [31.1081],\n",
            "        [30.8840],\n",
            "        [30.4651],\n",
            "        [30.4602],\n",
            "        [30.0632],\n",
            "        [29.9569],\n",
            "        [30.8480],\n",
            "        [30.4545],\n",
            "        [30.4282],\n",
            "        [30.0743],\n",
            "        [30.1223],\n",
            "        [30.0168],\n",
            "        [29.8669]])\n",
            "test loss: tensor(116.6334)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.0757],\n",
            "        [30.3418],\n",
            "        [30.6503],\n",
            "        [31.1165],\n",
            "        [31.2082],\n",
            "        [30.7806],\n",
            "        [31.3345],\n",
            "        [30.7460],\n",
            "        [30.9422],\n",
            "        [30.3958],\n",
            "        [30.5754],\n",
            "        [31.3987],\n",
            "        [31.0311],\n",
            "        [30.0858],\n",
            "        [29.8577],\n",
            "        [30.1046],\n",
            "        [30.4361],\n",
            "        [29.8745],\n",
            "        [29.9778],\n",
            "        [30.2286],\n",
            "        [29.8897],\n",
            "        [30.0131],\n",
            "        [29.6307],\n",
            "        [29.7648],\n",
            "        [30.1397]])\n",
            "test loss: tensor(114.3970)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.0715],\n",
            "        [30.4755],\n",
            "        [30.7356],\n",
            "        [31.1117],\n",
            "        [30.8902],\n",
            "        [30.4209],\n",
            "        [31.2224],\n",
            "        [31.3462],\n",
            "        [31.1060],\n",
            "        [30.8864],\n",
            "        [31.5001],\n",
            "        [31.3771],\n",
            "        [30.5140],\n",
            "        [29.5698],\n",
            "        [30.5676],\n",
            "        [30.0077],\n",
            "        [29.9515],\n",
            "        [30.0889],\n",
            "        [30.1282],\n",
            "        [30.3342],\n",
            "        [29.1103],\n",
            "        [29.7388],\n",
            "        [29.9496],\n",
            "        [29.5532],\n",
            "        [29.8029]])\n",
            "test loss: tensor(114.4679)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.4563],\n",
            "        [30.8586],\n",
            "        [30.7244],\n",
            "        [31.0075],\n",
            "        [31.3905],\n",
            "        [31.0661],\n",
            "        [30.5391],\n",
            "        [30.3630],\n",
            "        [30.7888],\n",
            "        [30.8653],\n",
            "        [31.1174],\n",
            "        [30.5524],\n",
            "        [30.8694],\n",
            "        [29.9941],\n",
            "        [30.5413],\n",
            "        [29.6009],\n",
            "        [29.9288],\n",
            "        [30.1233],\n",
            "        [29.9633],\n",
            "        [29.9958],\n",
            "        [29.5840],\n",
            "        [29.3923],\n",
            "        [30.0534],\n",
            "        [29.6393],\n",
            "        [29.8017]])\n",
            "test loss: tensor(113.2037)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.3418],\n",
            "        [30.4019],\n",
            "        [30.7202],\n",
            "        [30.8245],\n",
            "        [31.0702],\n",
            "        [30.5652],\n",
            "        [30.8175],\n",
            "        [31.4101],\n",
            "        [29.9898],\n",
            "        [29.7540],\n",
            "        [27.9130],\n",
            "        [28.7104],\n",
            "        [30.4830],\n",
            "        [29.3039],\n",
            "        [30.2494],\n",
            "        [30.2573],\n",
            "        [30.6276],\n",
            "        [29.2175],\n",
            "        [28.2491],\n",
            "        [29.3248],\n",
            "        [29.1039],\n",
            "        [29.1686],\n",
            "        [30.0948],\n",
            "        [29.6068],\n",
            "        [30.4505]])\n",
            "test loss: tensor(11.8500)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.1284],\n",
            "        [30.8628],\n",
            "        [31.2222],\n",
            "        [31.3541],\n",
            "        [31.1310],\n",
            "        [31.8935],\n",
            "        [31.8367],\n",
            "        [30.7777],\n",
            "        [31.3087],\n",
            "        [31.2269],\n",
            "        [30.9022],\n",
            "        [31.2143],\n",
            "        [30.0497],\n",
            "        [30.4476],\n",
            "        [30.4711],\n",
            "        [29.3806],\n",
            "        [30.8755],\n",
            "        [30.0253],\n",
            "        [29.8853],\n",
            "        [30.0305],\n",
            "        [29.9710],\n",
            "        [30.1067],\n",
            "        [30.0577],\n",
            "        [30.3632],\n",
            "        [30.3199]])\n",
            "test loss: tensor(11.2915)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.4676],\n",
            "        [31.1325],\n",
            "        [31.3207],\n",
            "        [31.0962],\n",
            "        [31.4403],\n",
            "        [31.6642],\n",
            "        [31.2443],\n",
            "        [31.5389],\n",
            "        [31.3601],\n",
            "        [31.3498],\n",
            "        [30.3887],\n",
            "        [29.9967],\n",
            "        [30.2240],\n",
            "        [30.6387],\n",
            "        [30.1178],\n",
            "        [30.7265],\n",
            "        [29.8689],\n",
            "        [30.2763],\n",
            "        [30.4684],\n",
            "        [30.0694],\n",
            "        [29.7738],\n",
            "        [29.6205],\n",
            "        [27.9110],\n",
            "        [30.3091],\n",
            "        [30.8216]])\n",
            "test loss: tensor(10.2952)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[30.9256],\n",
            "        [30.9912],\n",
            "        [31.0228],\n",
            "        [30.3617],\n",
            "        [31.1785],\n",
            "        [30.9153],\n",
            "        [31.1621],\n",
            "        [30.6477],\n",
            "        [29.6917],\n",
            "        [31.0336],\n",
            "        [29.5346],\n",
            "        [28.3473],\n",
            "        [30.4336],\n",
            "        [29.6209],\n",
            "        [30.4958],\n",
            "        [29.5686],\n",
            "        [29.8653],\n",
            "        [28.4043],\n",
            "        [29.8000],\n",
            "        [28.5956],\n",
            "        [30.0551],\n",
            "        [30.4663],\n",
            "        [30.7329],\n",
            "        [30.8558],\n",
            "        [31.3617]])\n",
            "test loss: tensor(12.2430)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.1622],\n",
            "        [31.7545],\n",
            "        [31.5067],\n",
            "        [30.6338],\n",
            "        [31.2267],\n",
            "        [30.9804],\n",
            "        [31.2258],\n",
            "        [30.1932],\n",
            "        [30.6968],\n",
            "        [30.3605],\n",
            "        [30.6962],\n",
            "        [30.7308],\n",
            "        [30.3385],\n",
            "        [30.1892],\n",
            "        [30.2521],\n",
            "        [30.0082],\n",
            "        [29.9369],\n",
            "        [29.8205],\n",
            "        [29.8909],\n",
            "        [29.9708],\n",
            "        [30.7204],\n",
            "        [30.7778],\n",
            "        [31.2681],\n",
            "        [31.1298],\n",
            "        [31.2345]])\n",
            "test loss: tensor(10.6152)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.4278],\n",
            "        [31.5730],\n",
            "        [31.0796],\n",
            "        [31.6937],\n",
            "        [31.3544],\n",
            "        [31.1635],\n",
            "        [30.7783],\n",
            "        [31.0369],\n",
            "        [30.5856],\n",
            "        [30.7178],\n",
            "        [30.3775],\n",
            "        [29.7818],\n",
            "        [30.2519],\n",
            "        [30.1715],\n",
            "        [30.3705],\n",
            "        [30.0616],\n",
            "        [29.5876],\n",
            "        [29.7881],\n",
            "        [36.6357],\n",
            "        [37.6675],\n",
            "        [37.5937],\n",
            "        [37.3313],\n",
            "        [38.0343],\n",
            "        [38.3670],\n",
            "        [37.6166]])\n",
            "test loss: tensor(134.5049)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[37.9258],\n",
            "        [37.7205],\n",
            "        [37.9519],\n",
            "        [37.9159],\n",
            "        [38.1325],\n",
            "        [37.5944],\n",
            "        [36.4443],\n",
            "        [36.9257],\n",
            "        [36.9006],\n",
            "        [36.9873],\n",
            "        [37.4566],\n",
            "        [37.3614],\n",
            "        [36.9167],\n",
            "        [36.8888],\n",
            "        [36.3520],\n",
            "        [36.5583],\n",
            "        [37.2327],\n",
            "        [37.7409],\n",
            "        [37.8950],\n",
            "        [37.6266],\n",
            "        [38.3519],\n",
            "        [38.5077],\n",
            "        [38.2025],\n",
            "        [38.4953],\n",
            "        [37.3426]])\n",
            "test loss: tensor(438.0851)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[38.6126],\n",
            "        [38.5467],\n",
            "        [37.6870],\n",
            "        [38.0509],\n",
            "        [36.5550],\n",
            "        [37.5531],\n",
            "        [37.9159],\n",
            "        [37.1009],\n",
            "        [37.0395],\n",
            "        [37.2830],\n",
            "        [37.6301],\n",
            "        [36.8568],\n",
            "        [36.6583],\n",
            "        [36.8375],\n",
            "        [37.6876],\n",
            "        [37.8938],\n",
            "        [38.5351],\n",
            "        [37.9207],\n",
            "        [37.7652],\n",
            "        [38.4209],\n",
            "        [38.4719],\n",
            "        [38.4521],\n",
            "        [38.5142],\n",
            "        [38.5783],\n",
            "        [38.1051]])\n",
            "test loss: tensor(451.9042)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[36.3098],\n",
            "        [38.4419],\n",
            "        [37.9439],\n",
            "        [37.1126],\n",
            "        [38.0342],\n",
            "        [37.2883],\n",
            "        [37.3051],\n",
            "        [37.0975],\n",
            "        [37.2598],\n",
            "        [37.0086],\n",
            "        [37.3497],\n",
            "        [36.9859],\n",
            "        [36.8903],\n",
            "        [37.2666],\n",
            "        [37.2519],\n",
            "        [37.0343],\n",
            "        [38.0508],\n",
            "        [38.6814],\n",
            "        [38.2778],\n",
            "        [38.8187],\n",
            "        [37.4995],\n",
            "        [38.5265],\n",
            "        [37.5907],\n",
            "        [38.1084],\n",
            "        [38.2474]])\n",
            "test loss: tensor(444.1543)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[38.1622],\n",
            "        [37.9956],\n",
            "        [36.3530],\n",
            "        [37.8991],\n",
            "        [37.7264],\n",
            "        [37.1721],\n",
            "        [37.2253],\n",
            "        [37.2029],\n",
            "        [36.9900],\n",
            "        [36.9711],\n",
            "        [36.8368],\n",
            "        [36.5032],\n",
            "        [37.6391],\n",
            "        [38.1120],\n",
            "        [38.4298],\n",
            "        [38.5510],\n",
            "        [38.4307],\n",
            "        [38.3137],\n",
            "        [38.6468],\n",
            "        [38.0767],\n",
            "        [38.8889],\n",
            "        [38.1274],\n",
            "        [38.4656],\n",
            "        [38.1171],\n",
            "        [38.7885]])\n",
            "test loss: tensor(453.3566)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[37.8871],\n",
            "        [36.2184],\n",
            "        [38.0058],\n",
            "        [37.8321],\n",
            "        [37.3122],\n",
            "        [36.8865],\n",
            "        [36.9940],\n",
            "        [37.4966],\n",
            "        [37.1049],\n",
            "        [37.3308],\n",
            "        [36.8488],\n",
            "        [37.5751],\n",
            "        [38.0595],\n",
            "        [38.0724],\n",
            "        [37.7861],\n",
            "        [38.7501],\n",
            "        [38.3834],\n",
            "        [38.9795],\n",
            "        [38.4898],\n",
            "        [38.5090],\n",
            "        [38.5449],\n",
            "        [38.3776],\n",
            "        [38.7003],\n",
            "        [38.3634],\n",
            "        [38.1222]])\n",
            "test loss: tensor(455.4833)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[38.0757],\n",
            "        [38.0187],\n",
            "        [37.7019],\n",
            "        [37.6481],\n",
            "        [37.2739],\n",
            "        [36.5239],\n",
            "        [37.4478],\n",
            "        [37.3391],\n",
            "        [37.3988],\n",
            "        [36.9810],\n",
            "        [30.2796],\n",
            "        [30.2287],\n",
            "        [30.5655],\n",
            "        [31.0090],\n",
            "        [30.2080],\n",
            "        [30.7941],\n",
            "        [29.9942],\n",
            "        [30.0612],\n",
            "        [30.0578],\n",
            "        [29.9757],\n",
            "        [30.7397],\n",
            "        [31.6193],\n",
            "        [29.3788],\n",
            "        [30.9205],\n",
            "        [29.5953]])\n",
            "test loss: tensor(189.5087)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[29.5713],\n",
            "        [30.5872],\n",
            "        [29.8497],\n",
            "        [29.6427],\n",
            "        [29.8170],\n",
            "        [29.0107],\n",
            "        [29.7810],\n",
            "        [30.5754],\n",
            "        [30.3281],\n",
            "        [29.4646],\n",
            "        [30.3429],\n",
            "        [30.3830],\n",
            "        [30.2426],\n",
            "        [30.6468],\n",
            "        [30.9670],\n",
            "        [31.1174],\n",
            "        [31.5702],\n",
            "        [31.2379],\n",
            "        [31.2813],\n",
            "        [31.1001],\n",
            "        [31.2365],\n",
            "        [31.5289],\n",
            "        [30.5957],\n",
            "        [31.3646],\n",
            "        [31.2306]])\n",
            "test loss: tensor(22.0851)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[29.8378],\n",
            "        [29.7764],\n",
            "        [30.7967],\n",
            "        [30.7832],\n",
            "        [30.6153],\n",
            "        [30.1124],\n",
            "        [29.8846],\n",
            "        [29.6016],\n",
            "        [29.9147],\n",
            "        [30.3712],\n",
            "        [29.6134],\n",
            "        [29.7767],\n",
            "        [29.8734],\n",
            "        [30.1424],\n",
            "        [30.1676],\n",
            "        [30.0443],\n",
            "        [30.8340],\n",
            "        [30.8628],\n",
            "        [31.6318],\n",
            "        [31.2672],\n",
            "        [30.1036],\n",
            "        [31.5494],\n",
            "        [30.4839],\n",
            "        [31.5374],\n",
            "        [31.4441]])\n",
            "test loss: tensor(23.2753)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.1717],\n",
            "        [30.7899],\n",
            "        [30.5598],\n",
            "        [30.0333],\n",
            "        [31.4697],\n",
            "        [30.0761],\n",
            "        [30.6855],\n",
            "        [29.9086],\n",
            "        [30.3479],\n",
            "        [29.3237],\n",
            "        [29.6333],\n",
            "        [30.0403],\n",
            "        [29.2131],\n",
            "        [29.6039],\n",
            "        [30.4273],\n",
            "        [29.8465],\n",
            "        [30.3336],\n",
            "        [30.6059],\n",
            "        [30.2649],\n",
            "        [30.9692],\n",
            "        [30.8102],\n",
            "        [31.0987],\n",
            "        [30.7391],\n",
            "        [30.7812],\n",
            "        [31.7183]])\n",
            "test loss: tensor(24.3540)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.3881],\n",
            "        [30.4698],\n",
            "        [31.1779],\n",
            "        [30.0864],\n",
            "        [31.1928],\n",
            "        [30.8224],\n",
            "        [30.9710],\n",
            "        [30.2028],\n",
            "        [30.1296],\n",
            "        [30.1089],\n",
            "        [30.3941],\n",
            "        [30.4687],\n",
            "        [29.8075],\n",
            "        [30.1095],\n",
            "        [29.7081],\n",
            "        [29.5620],\n",
            "        [29.9716],\n",
            "        [30.1299],\n",
            "        [30.3650],\n",
            "        [30.4487],\n",
            "        [31.1119],\n",
            "        [30.5402],\n",
            "        [31.0825],\n",
            "        [31.2751],\n",
            "        [31.3813]])\n",
            "test loss: tensor(24.9036)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.6344],\n",
            "        [31.2728],\n",
            "        [31.7722],\n",
            "        [32.2543],\n",
            "        [31.9619],\n",
            "        [29.6639],\n",
            "        [30.7142],\n",
            "        [31.3338],\n",
            "        [30.8280],\n",
            "        [29.7197],\n",
            "        [30.4132],\n",
            "        [30.7999],\n",
            "        [30.6997],\n",
            "        [30.4950],\n",
            "        [30.2805],\n",
            "        [29.7691],\n",
            "        [30.5509],\n",
            "        [30.8264],\n",
            "        [29.9329],\n",
            "        [29.3046],\n",
            "        [30.2935],\n",
            "        [30.1656],\n",
            "        [29.7663],\n",
            "        [31.0702],\n",
            "        [31.2536]])\n",
            "test loss: tensor(24.5703)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[31.4616],\n",
            "        [31.3909],\n",
            "        [31.5566],\n",
            "        [31.6012],\n",
            "        [31.6025],\n",
            "        [31.2929],\n",
            "        [32.2839],\n",
            "        [31.9626],\n",
            "        [31.3019],\n",
            "        [31.6313],\n",
            "        [31.0713],\n",
            "        [30.4681],\n",
            "        [30.7356],\n",
            "        [30.0985],\n",
            "        [30.8173],\n",
            "        [30.2511],\n",
            "        [30.7176],\n",
            "        [30.0961],\n",
            "        [30.6567],\n",
            "        [30.1539],\n",
            "        [29.6597],\n",
            "        [29.7341],\n",
            "        [30.3547],\n",
            "        [29.5891],\n",
            "        [30.2315]])\n",
            "test loss: tensor(21.6265)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[26.0664],\n",
            "        [28.1295],\n",
            "        [26.7828],\n",
            "        [27.5677],\n",
            "        [28.2860],\n",
            "        [28.5405],\n",
            "        [28.7045],\n",
            "        [28.9039],\n",
            "        [29.0145],\n",
            "        [28.7344],\n",
            "        [27.4303],\n",
            "        [28.6558],\n",
            "        [28.2699],\n",
            "        [28.4958],\n",
            "        [27.9949],\n",
            "        [27.7659],\n",
            "        [27.8206],\n",
            "        [27.8547],\n",
            "        [27.4381],\n",
            "        [27.7352],\n",
            "        [27.3622],\n",
            "        [26.8537],\n",
            "        [27.6454],\n",
            "        [27.3743],\n",
            "        [27.6650]])\n",
            "test loss: tensor(27.9771)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[27.5881],\n",
            "        [27.7115],\n",
            "        [28.4257],\n",
            "        [28.4087],\n",
            "        [27.4659],\n",
            "        [29.1713],\n",
            "        [28.6860],\n",
            "        [29.0602],\n",
            "        [29.1540],\n",
            "        [28.4595],\n",
            "        [28.8525],\n",
            "        [28.6841],\n",
            "        [28.3461],\n",
            "        [28.4264],\n",
            "        [28.1102],\n",
            "        [28.2644],\n",
            "        [27.7187],\n",
            "        [27.6505],\n",
            "        [28.0035],\n",
            "        [28.1280],\n",
            "        [27.8762],\n",
            "        [27.2689],\n",
            "        [27.8400],\n",
            "        [27.5659],\n",
            "        [27.8021]])\n",
            "test loss: tensor(31.4292)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[28.1168],\n",
            "        [28.1938],\n",
            "        [28.4634],\n",
            "        [28.8058],\n",
            "        [29.1087],\n",
            "        [29.0353],\n",
            "        [28.4756],\n",
            "        [28.9771],\n",
            "        [28.0641],\n",
            "        [28.8789],\n",
            "        [29.0365],\n",
            "        [29.0492],\n",
            "        [28.3617],\n",
            "        [28.0871],\n",
            "        [28.2196],\n",
            "        [28.2252],\n",
            "        [28.0234],\n",
            "        [27.1955],\n",
            "        [28.1143],\n",
            "        [27.7408],\n",
            "        [28.0156],\n",
            "        [27.8662],\n",
            "        [27.7294],\n",
            "        [28.0159],\n",
            "        [27.9620]])\n",
            "test loss: tensor(33.2986)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[27.7144],\n",
            "        [28.2605],\n",
            "        [28.1675],\n",
            "        [28.6682],\n",
            "        [27.5767],\n",
            "        [29.1317],\n",
            "        [28.7385],\n",
            "        [28.8606],\n",
            "        [29.1354],\n",
            "        [28.9273],\n",
            "        [28.8059],\n",
            "        [28.6101],\n",
            "        [28.3943],\n",
            "        [28.6397],\n",
            "        [27.6778],\n",
            "        [28.2358],\n",
            "        [27.9273],\n",
            "        [27.5418],\n",
            "        [27.6745],\n",
            "        [28.0624],\n",
            "        [28.0094],\n",
            "        [27.5883],\n",
            "        [27.7381],\n",
            "        [27.4867],\n",
            "        [27.6403]])\n",
            "test loss: tensor(31.8096)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[27.9826],\n",
            "        [27.8107],\n",
            "        [28.7062],\n",
            "        [28.9166],\n",
            "        [28.7558],\n",
            "        [28.8048],\n",
            "        [29.0473],\n",
            "        [29.0675],\n",
            "        [29.2334],\n",
            "        [28.7875],\n",
            "        [29.0057],\n",
            "        [28.6714],\n",
            "        [29.3357],\n",
            "        [28.3798],\n",
            "        [28.1766],\n",
            "        [28.3498],\n",
            "        [28.3298],\n",
            "        [27.8964],\n",
            "        [27.9078],\n",
            "        [27.9492],\n",
            "        [27.7436],\n",
            "        [28.0669],\n",
            "        [27.7748],\n",
            "        [27.9118],\n",
            "        [28.0303]])\n",
            "test loss: tensor(34.1348)\n",
            "test expected: tensor([[23.1400],\n",
            "        [22.5250],\n",
            "        [21.9140],\n",
            "        [21.3000],\n",
            "        [21.2330],\n",
            "        [21.6990],\n",
            "        [22.1570],\n",
            "        [22.6270],\n",
            "        [23.0800],\n",
            "        [23.5410],\n",
            "        [24.0120],\n",
            "        [24.4690],\n",
            "        [24.9280],\n",
            "        [25.3950],\n",
            "        [25.8520],\n",
            "        [26.3090],\n",
            "        [26.7810],\n",
            "        [36.0730],\n",
            "        [36.1520],\n",
            "        [36.2320],\n",
            "        [36.3120],\n",
            "        [36.3910],\n",
            "        [36.4710],\n",
            "        [36.5500],\n",
            "        [36.5560]])\n",
            "test prediction tensor([[28.0882],\n",
            "        [27.5179],\n",
            "        [28.8910],\n",
            "        [29.0325],\n",
            "        [28.4654],\n",
            "        [29.3973],\n",
            "        [29.1305],\n",
            "        [29.0555],\n",
            "        [29.2175],\n",
            "        [29.0753],\n",
            "        [29.1061],\n",
            "        [28.6772],\n",
            "        [29.3193],\n",
            "        [28.6358],\n",
            "        [28.3243],\n",
            "        [28.3721],\n",
            "        [27.6250],\n",
            "        [27.5057],\n",
            "        [28.1334],\n",
            "        [27.8863],\n",
            "        [27.6456],\n",
            "        [27.6857],\n",
            "        [27.9577],\n",
            "        [27.8777],\n",
            "        [    nan]])\n",
            "test loss: tensor(nan)\n",
            "Epoch: 0, loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-5b01e0f71b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbase_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-53a8f1f3b2ad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, testloader, epoch_num, lr, momentum, tol, test_freq, plot_graph, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mepoch_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtest_freq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: NaN loss"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F-Pyu06mqRI",
        "outputId": "dc72a761-4aea-4706-85e3-d316ef75939d"
      },
      "source": [
        "for p in base.named_parameters():\n",
        "  print(p)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('l1.weight', Parameter containing:\n",
            "tensor([[-0.2305,  0.0561,  0.2116,  ..., -0.0111,  0.1623,  0.1774],\n",
            "        [-0.2295, -0.2010,  0.2114,  ...,  0.2211, -0.0428, -0.1895],\n",
            "        [-0.1171, -0.0013, -0.0850,  ...,  0.0404,  0.2272, -0.0272],\n",
            "        ...,\n",
            "        [-0.1248,  0.0464, -0.1367,  ..., -0.1224,  0.0336, -0.1898],\n",
            "        [-0.1577,  0.0690,  0.0345,  ..., -0.1355,  0.0745,  0.0126],\n",
            "        [ 0.1123,  0.1623, -0.1969,  ..., -0.0824,  0.2142,  0.0762]],\n",
            "       requires_grad=True))\n",
            "('l1.bias', Parameter containing:\n",
            "tensor([ 0.1895, -0.1712,  0.1061, -0.0497, -0.0556, -0.1739,  0.0275, -0.0263,\n",
            "         0.0454, -0.1601,  0.0046, -0.1335,  0.0515,  0.1383,  0.1537,  0.1521,\n",
            "        -0.0854, -0.2223,  0.0323,  0.1695,  0.1489,  0.1152,  0.0583, -0.1971,\n",
            "         0.1765, -0.2289,  0.1102,  0.0730,  0.2028,  0.1968,  0.1341, -0.1068,\n",
            "        -0.1890,  0.1113,  0.2056,  0.0235, -0.2026, -0.1819, -0.0987,  0.1165,\n",
            "        -0.0713, -0.1972,  0.2206, -0.0421, -0.2199,  0.1513, -0.2251,  0.2129,\n",
            "        -0.0194,  0.1194, -0.1716, -0.2116,  0.0192,  0.0234,  0.2112,  0.0865,\n",
            "         0.2258, -0.0600, -0.0114,  0.0493,  0.1383,  0.1903, -0.1515,  0.1781,\n",
            "        -0.1585,  0.1618, -0.1065, -0.1002,  0.1758, -0.0832,  0.1077,  0.1352,\n",
            "        -0.0336,  0.1468,  0.1612, -0.2278,  0.1503,  0.0554,  0.0754,  0.0891,\n",
            "         0.2244,  0.1728,  0.1900,  0.0648,  0.0893, -0.2035, -0.0497, -0.1321,\n",
            "         0.1449,  0.1061,  0.2019,  0.1135, -0.2066,  0.0341,  0.1505, -0.0766,\n",
            "         0.0422, -0.1307,  0.0170, -0.0375, -0.0940, -0.1516, -0.0774, -0.2035,\n",
            "         0.1936,  0.2133,  0.2073, -0.1588,  0.1402, -0.0775, -0.1019, -0.1551,\n",
            "        -0.0762,  0.0743,  0.1028, -0.0617,  0.1583,  0.2233,  0.1890, -0.1597,\n",
            "         0.1374, -0.0547, -0.0016,  0.0508, -0.1808,  0.1540,  0.1112,  0.0433,\n",
            "        -0.0820, -0.1521, -0.1623, -0.2035,  0.1991, -0.0809,  0.1593,  0.1795,\n",
            "         0.1185,  0.1286,  0.1789,  0.1802,  0.1389,  0.1359,  0.2265,  0.0513,\n",
            "         0.1602, -0.1222, -0.1676,  0.0731, -0.2005, -0.0354,  0.2208,  0.2120,\n",
            "         0.2079, -0.2149,  0.1930, -0.2099,  0.1102, -0.0077,  0.0707,  0.0994,\n",
            "        -0.0751, -0.2017,  0.1857,  0.1413,  0.0391, -0.0669,  0.1019,  0.0519,\n",
            "         0.1261, -0.2073, -0.1829,  0.1819, -0.2061, -0.0976,  0.0459, -0.1778,\n",
            "         0.0879, -0.0580, -0.1324, -0.0874, -0.1770,  0.0915, -0.0557, -0.2263,\n",
            "        -0.1888,  0.0408,  0.0471,  0.1665,  0.0831,  0.1297,  0.2097, -0.0795,\n",
            "         0.1974,  0.1324,  0.0032,  0.1695,  0.0839,  0.0286, -0.0824,  0.0905],\n",
            "       requires_grad=True))\n",
            "('l2.weight', Parameter containing:\n",
            "tensor([[ 0.0110, -0.0390,  0.0089,  ..., -0.0248,  0.0503,  0.0366],\n",
            "        [-0.0127, -0.0165, -0.0632,  ...,  0.0618,  0.0053, -0.0045],\n",
            "        [ 0.0034,  0.0588, -0.0589,  ..., -0.0081, -0.0497, -0.0206],\n",
            "        ...,\n",
            "        [ 0.0054, -0.0568, -0.0241,  ...,  0.0231, -0.0402,  0.0384],\n",
            "        [ 0.0391, -0.0701, -0.0253,  ..., -0.0052, -0.0110,  0.0354],\n",
            "        [ 0.0579,  0.0660, -0.0447,  ...,  0.0064, -0.0357,  0.0624]],\n",
            "       requires_grad=True))\n",
            "('l2.bias', Parameter containing:\n",
            "tensor([ 0.0411, -0.0465, -0.0616, -0.0330,  0.0446, -0.0243, -0.0379, -0.0207,\n",
            "        -0.0448, -0.0360,  0.0155, -0.0703, -0.0219, -0.0481, -0.0360, -0.0494,\n",
            "        -0.0623, -0.0664,  0.0040, -0.0335, -0.0342, -0.0407,  0.0337, -0.0097,\n",
            "        -0.0592,  0.0668,  0.0426, -0.0305, -0.0169,  0.0430, -0.0139,  0.0538,\n",
            "        -0.0481,  0.0615, -0.0302,  0.0367, -0.0700,  0.0445,  0.0195,  0.0021,\n",
            "        -0.0047,  0.0096,  0.0394,  0.0135, -0.0240, -0.0431, -0.0388, -0.0573,\n",
            "         0.0660,  0.0302,  0.0003, -0.0681, -0.0637, -0.0525,  0.0340,  0.0436,\n",
            "        -0.0114, -0.0161,  0.0089, -0.0651, -0.0430, -0.0471,  0.0008,  0.0373,\n",
            "        -0.0355,  0.0652,  0.0232,  0.0549,  0.0672,  0.0030, -0.0159,  0.0270,\n",
            "        -0.0554, -0.0509, -0.0220, -0.0352, -0.0450,  0.0149,  0.0253, -0.0063,\n",
            "        -0.0585, -0.0577,  0.0307, -0.0649,  0.0236,  0.0166,  0.0321, -0.0393,\n",
            "        -0.0418, -0.0390, -0.0014,  0.0446, -0.0244, -0.0311, -0.0304, -0.0362,\n",
            "        -0.0145,  0.0346, -0.0037, -0.0178, -0.0193,  0.0584,  0.0567,  0.0391,\n",
            "        -0.0137,  0.0008, -0.0414,  0.0336, -0.0466, -0.0158,  0.0244,  0.0463,\n",
            "         0.0143, -0.0430, -0.0302, -0.0119, -0.0258, -0.0489,  0.0667,  0.0154,\n",
            "         0.0315, -0.0378,  0.0306, -0.0631,  0.0335,  0.0576,  0.0174, -0.0671,\n",
            "        -0.0264, -0.0153, -0.0462, -0.0421, -0.0377, -0.0079, -0.0158, -0.0061,\n",
            "        -0.0207, -0.0322,  0.0478, -0.0446, -0.0344,  0.0569, -0.0281, -0.0389,\n",
            "         0.0686,  0.0507, -0.0304, -0.0286,  0.0531, -0.0667,  0.0176, -0.0165,\n",
            "        -0.0483,  0.0373, -0.0700, -0.0158, -0.0097,  0.0042,  0.0303,  0.0506,\n",
            "         0.0505, -0.0113, -0.0385,  0.0092, -0.0351, -0.0414, -0.0212,  0.0491,\n",
            "         0.0305, -0.0158,  0.0594,  0.0207, -0.0526, -0.0020, -0.0439, -0.0282,\n",
            "        -0.0157,  0.0261,  0.0186, -0.0028, -0.0023,  0.0449,  0.0021,  0.0387,\n",
            "         0.0626,  0.0676,  0.0460,  0.0161,  0.0508,  0.0208,  0.0158, -0.0549,\n",
            "         0.0536, -0.0251, -0.0613,  0.0117,  0.0470,  0.0160, -0.0442,  0.0261,\n",
            "         0.0008, -0.0607,  0.0379,  0.0600,  0.0482,  0.0296, -0.0557,  0.0183,\n",
            "         0.0024, -0.0310, -0.0262,  0.0347,  0.0464,  0.0271, -0.0390, -0.0515,\n",
            "        -0.0312,  0.0066,  0.0566,  0.0373, -0.0304, -0.0495, -0.0536,  0.0137,\n",
            "        -0.0255, -0.0055,  0.0193,  0.0514,  0.0022, -0.0515, -0.0213, -0.0379,\n",
            "         0.0462, -0.0142, -0.0241,  0.0088,  0.0201,  0.0399,  0.0107,  0.0139,\n",
            "        -0.0352, -0.0473, -0.0092,  0.0045, -0.0349,  0.0427, -0.0466, -0.0089,\n",
            "        -0.0517,  0.0609, -0.0014,  0.0294, -0.0163, -0.0327,  0.0329, -0.0200,\n",
            "        -0.0131,  0.0241, -0.0329, -0.0302,  0.0508, -0.0301,  0.0148,  0.0327,\n",
            "        -0.0011,  0.0074,  0.0591, -0.0348, -0.0535, -0.0344,  0.0427, -0.0534,\n",
            "         0.0558,  0.0519, -0.0207,  0.0124,  0.0065, -0.0238,  0.0020,  0.0067,\n",
            "         0.0200, -0.0393,  0.0176, -0.0454,  0.0164, -0.0508,  0.0401,  0.0173,\n",
            "         0.0310, -0.0101, -0.0049,  0.0273, -0.0436,  0.0288,  0.0257,  0.0153,\n",
            "         0.0176, -0.0062, -0.0037,  0.0306, -0.0420, -0.0245, -0.0391, -0.0170,\n",
            "         0.0582, -0.0085,  0.0518,  0.0346, -0.0103, -0.0689, -0.0584, -0.0397,\n",
            "         0.0361,  0.0573, -0.0058,  0.0383, -0.0056,  0.0686, -0.0119, -0.0185,\n",
            "         0.0412,  0.0093,  0.0651, -0.0234, -0.0408,  0.0531,  0.0274, -0.0589,\n",
            "        -0.0605,  0.0226, -0.0585,  0.0140, -0.0265,  0.0117, -0.0029,  0.0242,\n",
            "        -0.0684, -0.0483, -0.0631,  0.0666, -0.0555,  0.0485,  0.0142,  0.0540,\n",
            "        -0.0101,  0.0524, -0.0194, -0.0557,  0.0287, -0.0246,  0.0320,  0.0235,\n",
            "         0.0146,  0.0350,  0.0163, -0.0141, -0.0546, -0.0169,  0.0324,  0.0206,\n",
            "         0.0291, -0.0662, -0.0617, -0.0157, -0.0327, -0.0053,  0.0651, -0.0211,\n",
            "        -0.0258,  0.0482,  0.0581,  0.0411, -0.0219, -0.0535,  0.0384,  0.0210,\n",
            "        -0.0287,  0.0367,  0.0467, -0.0550,  0.0289,  0.0426,  0.0444,  0.0490,\n",
            "        -0.0269,  0.0412, -0.0005,  0.0004, -0.0662,  0.0464, -0.0316,  0.0414,\n",
            "        -0.0434, -0.0273, -0.0013,  0.0184, -0.0361,  0.0553, -0.0460,  0.0699,\n",
            "        -0.0291,  0.0629,  0.0672,  0.0257,  0.0219,  0.0693, -0.0160,  0.0571,\n",
            "        -0.0442,  0.0248, -0.0456,  0.0272, -0.0213,  0.0492, -0.0603,  0.0306,\n",
            "         0.0466, -0.0627,  0.0396, -0.0628,  0.0668, -0.0640, -0.0390,  0.0151,\n",
            "        -0.0376,  0.0229,  0.0695,  0.0067, -0.0290,  0.0128, -0.0498,  0.0518,\n",
            "         0.0426, -0.0517,  0.0591,  0.0239, -0.0103,  0.0256, -0.0518, -0.0686,\n",
            "        -0.0335, -0.0443, -0.0320, -0.0275,  0.0309,  0.0080, -0.0698,  0.0253,\n",
            "         0.0610,  0.0031,  0.0524, -0.0306,  0.0358, -0.0563, -0.0267,  0.0204,\n",
            "         0.0646,  0.0230, -0.0188, -0.0233, -0.0619, -0.0422, -0.0009, -0.0311,\n",
            "        -0.0361,  0.0229, -0.0013, -0.0495,  0.0554,  0.0669,  0.0090,  0.0574,\n",
            "         0.0611, -0.0349, -0.0002, -0.0421, -0.0029, -0.0167,  0.0611,  0.0216,\n",
            "        -0.0269, -0.0665,  0.0068,  0.0099,  0.0320,  0.0193,  0.0153, -0.0353,\n",
            "        -0.0332, -0.0132, -0.0356, -0.0134, -0.0458,  0.0597, -0.0501,  0.0457,\n",
            "        -0.0033,  0.0389,  0.0429, -0.0544], requires_grad=True))\n",
            "('l3.weight', Parameter containing:\n",
            "tensor([[ 0.0281,  0.0060,  0.0289,  ...,  0.0343, -0.0202,  0.0412],\n",
            "        [ 0.0158, -0.0205, -0.0225,  ..., -0.0405,  0.0362,  0.0369],\n",
            "        [ 0.0359,  0.0079, -0.0340,  ..., -0.0003, -0.0211, -0.0430],\n",
            "        ...,\n",
            "        [-0.0105,  0.0203, -0.0107,  ...,  0.0190,  0.0363, -0.0316],\n",
            "        [-0.0062, -0.0194, -0.0058,  ..., -0.0273, -0.0230,  0.0119],\n",
            "        [ 0.0261,  0.0375, -0.0421,  ..., -0.0335, -0.0204, -0.0136]],\n",
            "       requires_grad=True))\n",
            "('l3.bias', Parameter containing:\n",
            "tensor([-0.0133, -0.0407,  0.0075,  0.0210,  0.0390,  0.0291, -0.0024, -0.0005,\n",
            "         0.0019, -0.0047, -0.0355,  0.0109,  0.0110,  0.0387, -0.0267, -0.0146,\n",
            "         0.0016,  0.0329,  0.0151,  0.0289,  0.0256,  0.0109, -0.0408,  0.0124,\n",
            "         0.0192, -0.0205, -0.0259, -0.0345,  0.0255, -0.0287, -0.0283,  0.0282,\n",
            "        -0.0186, -0.0178, -0.0354,  0.0123, -0.0308,  0.0106,  0.0121, -0.0365,\n",
            "         0.0387, -0.0236, -0.0353, -0.0032,  0.0006,  0.0297,  0.0078, -0.0359,\n",
            "         0.0408,  0.0444, -0.0330, -0.0258, -0.0414,  0.0084, -0.0268,  0.0120,\n",
            "        -0.0209,  0.0400, -0.0062, -0.0267,  0.0062, -0.0053,  0.0120, -0.0006,\n",
            "        -0.0279,  0.0046,  0.0417, -0.0015,  0.0439,  0.0082, -0.0272,  0.0358,\n",
            "        -0.0289,  0.0099, -0.0267,  0.0006,  0.0440,  0.0103, -0.0293, -0.0058,\n",
            "        -0.0018,  0.0445,  0.0137,  0.0310, -0.0345, -0.0312, -0.0161, -0.0166,\n",
            "        -0.0426, -0.0415,  0.0154, -0.0129, -0.0425, -0.0107,  0.0224,  0.0283,\n",
            "         0.0413, -0.0369, -0.0405,  0.0316,  0.0187,  0.0148,  0.0049, -0.0090,\n",
            "         0.0065, -0.0360, -0.0203,  0.0325,  0.0417, -0.0129, -0.0215,  0.0359,\n",
            "         0.0258, -0.0117, -0.0058, -0.0109,  0.0272, -0.0049,  0.0173, -0.0398,\n",
            "         0.0322, -0.0150, -0.0325,  0.0401,  0.0438,  0.0008, -0.0033, -0.0151,\n",
            "         0.0429, -0.0351,  0.0092, -0.0056, -0.0183, -0.0302,  0.0426, -0.0181,\n",
            "         0.0080, -0.0075,  0.0227,  0.0278, -0.0256, -0.0419, -0.0128,  0.0148,\n",
            "        -0.0396, -0.0316,  0.0070, -0.0078, -0.0365, -0.0052, -0.0052,  0.0106,\n",
            "         0.0335,  0.0238,  0.0297,  0.0205, -0.0273,  0.0277,  0.0248, -0.0325,\n",
            "         0.0215,  0.0140,  0.0378, -0.0431, -0.0237, -0.0067,  0.0201,  0.0091,\n",
            "        -0.0403, -0.0381,  0.0181, -0.0352,  0.0332,  0.0281,  0.0201, -0.0418,\n",
            "        -0.0221, -0.0089,  0.0103, -0.0438, -0.0243,  0.0059,  0.0192, -0.0261,\n",
            "        -0.0051,  0.0014, -0.0054,  0.0280,  0.0395, -0.0332,  0.0262,  0.0302,\n",
            "        -0.0024,  0.0249, -0.0202, -0.0223, -0.0393,  0.0166,  0.0265,  0.0076],\n",
            "       requires_grad=True))\n",
            "('l4.weight', Parameter containing:\n",
            "tensor([[ 0.0266, -0.0357, -0.0306,  ..., -0.0281, -0.0337,  0.0690],\n",
            "        [ 0.0363,  0.0128,  0.0068,  ..., -0.0252,  0.0125,  0.0178],\n",
            "        [-0.0625,  0.0103,  0.0181,  ..., -0.0254,  0.0284,  0.0370],\n",
            "        ...,\n",
            "        [-0.0466,  0.0273,  0.0128,  ..., -0.0075, -0.0160,  0.0269],\n",
            "        [ 0.0554, -0.0453, -0.0236,  ...,  0.0372,  0.0070, -0.0223],\n",
            "        [ 0.0101,  0.0485,  0.0435,  ...,  0.0114,  0.0617, -0.0069]],\n",
            "       requires_grad=True))\n",
            "('l4.bias', Parameter containing:\n",
            "tensor([ 0.0609, -0.0278, -0.0266, -0.0110, -0.0108,  0.0005, -0.0172,  0.0309,\n",
            "        -0.0588,  0.0044,  0.0158,  0.0277,  0.0561,  0.0436,  0.0079,  0.0616,\n",
            "        -0.0459,  0.0647, -0.0132,  0.0303], requires_grad=True))\n",
            "('l5.weight', Parameter containing:\n",
            "tensor([[-0.1954,  0.0429,  0.3808, -0.2021, -0.0010, -0.0601, -0.0781, -0.0878,\n",
            "         -0.1890, -0.0736,  0.2082,  0.1165,  0.0565, -0.0123,  0.1580,  0.0141,\n",
            "         -0.1977,  0.1654,  0.4556,  0.1048]], requires_grad=True))\n",
            "('l5.bias', Parameter containing:\n",
            "tensor([0.1379], requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5vVv-LlhHGd"
      },
      "source": [
        "parallel = ParallelRegression(BaseRegression)\n",
        "parallel.to(device)\n",
        "parallel_losses, parallel_time = train(parallel, train_loader, test_loader, epoches, name=\"parallel\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akufQWlsSOnY"
      },
      "source": [
        "#first = BaseRegression()\n",
        "#first.to(device)\n",
        "#agg_time = train(first, train_loader, test_loader, epoches, name=\"first\")[1]\n",
        "second = BaseRegression()\n",
        "second.to(device)\n",
        "agg_time = train(second, train_loader, test_loader, epoches, name=\"second\")[1]\n",
        "agg = AggregationRegression(base, second)\n",
        "agg.to(device)\n",
        "agg_losses, dt = train(agg, train_loader, test_loader, epoches, name=\"aggregation\")\n",
        "agg_time += dt + base_time\n",
        "print('Total time:', agg_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acC3phBJujho"
      },
      "source": [
        "star = StarRegression(base, BaseRegression)\n",
        "star.to(device)\n",
        "star_losses, star_time = train(star, train_loader, test_loader, epoches, name=\"star\")\n",
        "print('Total time:', star_time + base_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhIyfyYFhFeo"
      },
      "source": [
        "if enable_triple:\n",
        "    triple = StarRegression(star, BaseRegression) # star of star and base\n",
        "    triple_losses = train(triple, train_loader, test_loader, epoches, name=\"triple\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vKWgUF7uqDs"
      },
      "source": [
        "for p in star.l.named_parameters():\n",
        "  print(p) # weights of neural networks in star\n",
        "if enable_triple:\n",
        "    for p in triple.l.named_parameters():\n",
        "      print(p) # weights of neural networks in triple star"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fjFfTPHvfYd"
      },
      "source": [
        "# Let's plot true values and predictions of our models for test dataset\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "(x, y) = test_set.getall()\n",
        "x = x.reshape((test_size, 1))\n",
        "plt.scatter(x, f(x), c='black', label='true')\n",
        "\n",
        "y = base(x)\n",
        "plt.scatter(x, y.detach().numpy(), c='r', label='base')\n",
        "\n",
        "y = parallel(x)\n",
        "plt.scatter(x, y.detach().numpy(), c='g', label='parallel')\n",
        "\n",
        "y = agg(x)\n",
        "plt.scatter(x, y.detach().numpy(), c='violet', label='aggregation')\n",
        "\n",
        "y = star(x)\n",
        "plt.scatter(x, y.detach().numpy(), c='b', label='star')\n",
        "\n",
        "if enable_triple:\n",
        "    y = triple(x)\n",
        "    plt.scatter(x, y.detach().numpy(), c='orange', label='triple')\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# And let's plot losses of corresponding models\n",
        "\n",
        "indexes = [i for i in range(0, epoches, 2)]\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(indexes, base_losses, c='r', label='base')\n",
        "plt.plot(indexes, parallel_losses, c='g', label='parallel')\n",
        "plt.plot(indexes, agg_losses, c='violet', label='aggregation')\n",
        "plt.plot(indexes, star_losses, c='b', label='star')\n",
        "if enable_triple:\n",
        "    plt.plot(indexes, triple_losses, c='orange', label='triple')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}